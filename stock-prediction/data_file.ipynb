{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from fredapi import Fred\n",
    "import datetime\n",
    "\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = False\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = True\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.1\n",
    "# features to use\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ema100\"]\n",
    "FEATURE_COLUMNS = [\"close\"\n",
    "    # , \"volume\", \"open\", \"high\", \"low\"\n",
    "                    # ,\"ma7\",\"ma21\"\n",
    "                    #   ,\"ma100\",\"ma50\"\n",
    "                    #   ,\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"\n",
    "                   ] \\\n",
    "                  # + series_ids\n",
    "\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "### training parameters\n",
    "\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 700\n",
    "\n",
    "# Amazon stock market\n",
    "ticker = \"^GSPC\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def get_technical_indicators(dataset):\n",
    "    # Create 7 and 21 days Moving Average\n",
    "    dataset['ma7'] = dataset['close'].rolling(window=7).mean()\n",
    "    dataset['ma21'] = dataset['close'].rolling(window=21).mean()\n",
    "    dataset['ma100'] = dataset['close'].rolling(window=100).mean()\n",
    "    dataset['ma50'] = dataset['close'].rolling(window=50).mean()\n",
    "\n",
    "    # Create MACD\n",
    "\t# candles['ema20'] = pd.Series.ewm(candles['<CLOSE>'], span=20).mean()\n",
    "    dataset['26ema'] = pd.Series.ewm(dataset['close'], span=26).mean()\n",
    "    dataset['12ema'] = pd.Series.ewm(dataset['close'], span=12).mean()\n",
    "    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])\n",
    "\n",
    "    # Create Bollinger Bands\n",
    "    # dataset['20sd'] = pd.stats.moments.rolling_std(dataset['GS'],20)\n",
    "    # dataset['upper_band'] = dataset['ma21'] + (dataset['20sd']*2)\n",
    "    # dataset['lower_band'] = dataset['ma21'] - (dataset['20sd']*2)\n",
    "\n",
    "    # Create Exponential moving average\n",
    "    dataset['ema'] = dataset['close'].ewm(com=0.5).mean()\n",
    "\n",
    "    # Create Momentum\n",
    "    dataset['momentum'] = dataset['close']-1\n",
    "\n",
    "    dataset.replace('', np.nan, inplace=True)\n",
    "    dataset = dataset.dropna()\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def load_data(ticker, n_steps=N_STEPS, scale=True, shuffle=True, lookup_step=LOOKUP_STEP, split_by_date=True,\n",
    "#                 test_size=0.2, feature_columns=['close', 'volume', 'open', 'high', 'low']):\n",
    "n_steps=N_STEPS\n",
    "scale= SCALE\n",
    "shuffle=True\n",
    "lookup_step=LOOKUP_STEP\n",
    "split_by_date=True\n",
    "test_size=0.2\n",
    "feature_columns=FEATURE_COLUMNS\n",
    "\n",
    "\"\"\"\n",
    "Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "Params:\n",
    "    ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "    n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "    scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "    shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "    lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "    split_by_date (bool): whether we split the dataset into training/testing by date, setting it\n",
    "        to False will split datasets in a random way\n",
    "    test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "    feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "\"\"\"\n",
    "\n",
    "# see if ticker is already a loaded stock from yahoo finance\n",
    "if isinstance(ticker, str):\n",
    "    # load it from yahoo_fin library\n",
    "    # df = si.get_data(ticker)\n",
    "    # df = si.get_data(ticker,start_date = '2000-01-01', end_date = None, index_as_date = True, interval= \"1mo\")\n",
    "    df = si.get_data(ticker,start_date = '2000-01-01')\n",
    "    # get_data(ticker, start_date = None, end_date = None, index_as_date = True, interval = “1d”)\n",
    "elif isinstance(ticker, pd.DataFrame):\n",
    "    # already loaded, use it directly\n",
    "    df = ticker\n",
    "else:\n",
    "    raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "df = get_technical_indicators(df)\n",
    "# df_fred = get_fred()\n",
    "# df = pd.concat([df_fred , df], axis=1)\n",
    "\n",
    "df.replace('', np.nan, inplace=True)\n",
    "df = df.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# print(df.tail)\n",
    "# this will contain all the elements we want to return from this function\n",
    "result = {}\n",
    "# we will also return the original dataframe itself\n",
    "result['df'] = df.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# make sure that the passed feature_columns exist in the dataframe\n",
    "for col in feature_columns:\n",
    "    assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "\n",
    "# add date as a column\n",
    "if \"date\" not in df.columns:\n",
    "    df[\"date\"] = df.index\n",
    "\n",
    "if scale:\n",
    "    column_scaler = {}\n",
    "    # scale the data (prices) from 0 to 1\n",
    "    for column in feature_columns:\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "        column_scaler[column] = scaler\n",
    "\n",
    "    # add the MinMaxScaler instances to the result returned\n",
    "    result[\"column_scaler\"] = column_scaler\n",
    "\n",
    "# add the target column (label) by shifting by `lookup_step`\n",
    "df['future'] = df['close'].shift(-lookup_step)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1399.050048828125, Timestamp('2000-05-24 00:00:00')],\n       [1381.52001953125, Timestamp('2000-05-25 00:00:00')],\n       [1378.02001953125, Timestamp('2000-05-26 00:00:00')],\n       ...,\n       [4701.4599609375, Timestamp('2021-11-24 00:00:00')],\n       [4594.6201171875, Timestamp('2021-11-26 00:00:00')],\n       [4655.27001953125, Timestamp('2021-11-29 00:00:00')]], dtype=object)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[feature_columns + [\"date\"]].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# last `lookup_step` columns contains NaN in future column\n",
    "# get them before droping NaNs\n",
    "last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "\n",
    "# drop NaNs\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "sequence_data = []\n",
    "sequences = deque(maxlen=n_steps)\n",
    "\n",
    "for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "    sequences.append(entry)\n",
    "    if len(sequences) == n_steps:\n",
    "        sequence_data.append([np.array(sequences), target])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "# for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "# this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "# add to result\n",
    "result['last_sequence'] = last_sequence\n",
    "\n",
    "# construct the X's and y's\n",
    "X, y = [], []\n",
    "for seq, target in sequence_data:\n",
    "    X.append(seq)\n",
    "    y.append(target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# import datetime\n",
    "#\n",
    "# # train_samples = int((1 - test_size) * len(X))\n",
    "# train_samples = len(X) - (datetime.date.today() - datetime.date(2021, 1, 1)).days\n",
    "# print(len(X))\n",
    "# train_samples\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# import datetime\n",
    "\n",
    "# print((datetime.date.today() - datetime.date(2021, 1, 1)).days)\n",
    "\n",
    "# train_samples = (datetime.date.today() - datetime.date(2021, 1, 1)).days\n",
    "# train_samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "if split_by_date:\n",
    "    # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "    # train_samples = int((1 - test_size) * len(X))\n",
    "    train_samples = len(X) - len(result['df'].loc['2021-01-01':])\n",
    "    result[\"X_train\"] = X[:train_samples]\n",
    "    result[\"y_train\"] = y[:train_samples]\n",
    "    result[\"X_test\"]  = X[train_samples:]\n",
    "    result[\"y_test\"]  = y[train_samples:]\n",
    "    if shuffle:\n",
    "        # shuffle the datasets for training (if shuffle parameter is set)\n",
    "        shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "        shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "else:\n",
    "    # split the dataset randomly\n",
    "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y,\n",
    "                                                                            test_size=test_size, shuffle=shuffle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1436.1099853515625 Timestamp('2007-03-23 00:00:00')]\n",
      "  [1437.5 Timestamp('2007-03-26 00:00:00')]\n",
      "  [1428.6099853515625 Timestamp('2007-03-27 00:00:00')]\n",
      "  ...\n",
      "  [1530.6199951171875 Timestamp('2007-05-31 00:00:00')]\n",
      "  [1536.3399658203125 Timestamp('2007-06-01 00:00:00')]\n",
      "  [1539.1800537109375 Timestamp('2007-06-04 00:00:00')]]\n",
      "\n",
      " [[887.3400268554688 Timestamp('2003-01-23 00:00:00')]\n",
      "  [861.4000244140625 Timestamp('2003-01-24 00:00:00')]\n",
      "  [847.47998046875 Timestamp('2003-01-27 00:00:00')]\n",
      "  ...\n",
      "  [858.47998046875 Timestamp('2003-04-01 00:00:00')]\n",
      "  [880.9000244140625 Timestamp('2003-04-02 00:00:00')]\n",
      "  [876.4500122070312 Timestamp('2003-04-03 00:00:00')]]\n",
      "\n",
      " [[1313.0 Timestamp('2006-09-12 00:00:00')]\n",
      "  [1318.0699462890625 Timestamp('2006-09-13 00:00:00')]\n",
      "  [1316.280029296875 Timestamp('2006-09-14 00:00:00')]\n",
      "  ...\n",
      "  [1399.760009765625 Timestamp('2006-11-16 00:00:00')]\n",
      "  [1401.199951171875 Timestamp('2006-11-17 00:00:00')]\n",
      "  [1400.5 Timestamp('2006-11-20 00:00:00')]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[4204.10986328125 Timestamp('2021-05-28 00:00:00')]\n",
      "  [4202.0400390625 Timestamp('2021-06-01 00:00:00')]\n",
      "  [4208.1201171875 Timestamp('2021-06-02 00:00:00')]\n",
      "  ...\n",
      "  [4429.10009765625 Timestamp('2021-08-05 00:00:00')]\n",
      "  [4436.52001953125 Timestamp('2021-08-06 00:00:00')]\n",
      "  [4432.35009765625 Timestamp('2021-08-09 00:00:00')]]\n",
      "\n",
      " [[3809.840087890625 Timestamp('2021-01-13 00:00:00')]\n",
      "  [3795.5400390625 Timestamp('2021-01-14 00:00:00')]\n",
      "  [3768.25 Timestamp('2021-01-15 00:00:00')]\n",
      "  ...\n",
      "  [3910.52001953125 Timestamp('2021-03-23 00:00:00')]\n",
      "  [3889.139892578125 Timestamp('2021-03-24 00:00:00')]\n",
      "  [3909.52001953125 Timestamp('2021-03-25 00:00:00')]]\n",
      "\n",
      " [[4167.58984375 Timestamp('2021-05-05 00:00:00')]\n",
      "  [4201.6201171875 Timestamp('2021-05-06 00:00:00')]\n",
      "  [4232.60009765625 Timestamp('2021-05-07 00:00:00')]\n",
      "  ...\n",
      "  [4369.2099609375 Timestamp('2021-07-13 00:00:00')]\n",
      "  [4374.2998046875 Timestamp('2021-07-14 00:00:00')]\n",
      "  [4360.02978515625 Timestamp('2021-07-15 00:00:00')]]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# result[\"X_train\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# get the list of test set dates\n",
    "dates = result[\"X_test\"][:, -1, -1]\n",
    "# retrieve test features from the original dataframe\n",
    "result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "# remove duplicated dates in the testing dataframe\n",
    "result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "# remove dates from the training/testing sets & convert to float32\n",
    "result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "                   open         high          low        close     adjclose  \\\n2021-01-04  3764.610107  3769.989990  3662.709961  3700.649902  3700.649902   \n2021-01-05  3698.020020  3737.830078  3695.070068  3726.860107  3726.860107   \n2021-01-06  3712.199951  3783.040039  3705.340088  3748.139893  3748.139893   \n2021-01-07  3764.709961  3811.550049  3764.709961  3803.790039  3803.790039   \n2021-01-08  3815.050049  3826.689941  3783.600098  3824.679932  3824.679932   \n...                 ...          ...          ...          ...          ...   \n2021-11-22  4712.000000  4743.830078  4682.169922  4682.939941  4682.939941   \n2021-11-23  4678.479980  4699.390137  4652.660156  4690.700195  4690.700195   \n2021-11-24  4675.779785  4702.870117  4659.890137  4701.459961  4701.459961   \n2021-11-26  4664.629883  4664.629883  4585.430176  4594.620117  4594.620117   \n2021-11-29  4628.750000  4672.950195  4625.259766  4655.270020  4655.270020   \n\n                volume ticker          ma7         ma21        ma100  \\\n2021-01-04  5006680000  ^GSPC  3720.604318  3698.381441  3497.669902   \n2021-01-05  4582620000  ^GSPC  3725.868617  3701.245257  3501.135002   \n2021-01-06  6049970000  ^GSPC  3732.308594  3703.579532  3504.882102   \n2021-01-07  5080870000  ^GSPC  3742.084298  3708.904774  3509.191501   \n2021-01-08  4764180000  ^GSPC  3756.032854  3714.734770  3513.618401   \n...                ...    ...          ...          ...          ...   \n2021-11-22  3206280000  ^GSPC  4691.522810  4652.419968  4471.426069   \n2021-11-23  3428780000  ^GSPC  4692.644252  4658.335217  4474.809673   \n2021-11-24  2464040000  ^GSPC  4695.309989  4664.367118  4478.388872   \n2021-11-26  2676740000  ^GSPC  4680.127162  4666.411877  4480.753774   \n2021-11-29  3471380000  ^GSPC  4675.355748  4669.214262  4484.098276   \n\n                   ma50        26ema        12ema       MACD          ema  \\\n2021-01-04  3590.778994  3676.304286  3710.918349  34.614063  3716.220706   \n2021-01-05  3596.246396  3680.049162  3713.370928  33.321766  3723.313640   \n2021-01-06  3601.901396  3685.092920  3718.719999  33.627079  3739.864475   \n2021-01-07  3609.957798  3693.885299  3731.807698  37.922399  3782.481518   \n2021-01-08  3618.637798  3703.573790  3746.095734  42.521943  3810.613794   \n...                 ...          ...          ...        ...          ...   \n2021-11-22  4515.723359  4624.065500  4674.788751  50.723251  4688.152938   \n2021-11-23  4520.676367  4629.001403  4677.236665  48.235262  4689.851110   \n2021-11-24  4525.091562  4634.368704  4680.963326  46.594622  4697.590344   \n2021-11-26  4527.508965  4631.424364  4667.679756  36.255392  4628.943526   \n2021-11-29  4531.954561  4633.190709  4665.770565  32.579857  4646.494522   \n\n               momentum  \n2021-01-04  3699.649902  \n2021-01-05  3725.860107  \n2021-01-06  3747.139893  \n2021-01-07  3802.790039  \n2021-01-08  3823.679932  \n...                 ...  \n2021-11-22  4681.939941  \n2021-11-23  4689.700195  \n2021-11-24  4700.459961  \n2021-11-26  4593.620117  \n2021-11-29  4654.270020  \n\n[229 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adjclose</th>\n      <th>volume</th>\n      <th>ticker</th>\n      <th>ma7</th>\n      <th>ma21</th>\n      <th>ma100</th>\n      <th>ma50</th>\n      <th>26ema</th>\n      <th>12ema</th>\n      <th>MACD</th>\n      <th>ema</th>\n      <th>momentum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-01-04</th>\n      <td>3764.610107</td>\n      <td>3769.989990</td>\n      <td>3662.709961</td>\n      <td>3700.649902</td>\n      <td>3700.649902</td>\n      <td>5006680000</td>\n      <td>^GSPC</td>\n      <td>3720.604318</td>\n      <td>3698.381441</td>\n      <td>3497.669902</td>\n      <td>3590.778994</td>\n      <td>3676.304286</td>\n      <td>3710.918349</td>\n      <td>34.614063</td>\n      <td>3716.220706</td>\n      <td>3699.649902</td>\n    </tr>\n    <tr>\n      <th>2021-01-05</th>\n      <td>3698.020020</td>\n      <td>3737.830078</td>\n      <td>3695.070068</td>\n      <td>3726.860107</td>\n      <td>3726.860107</td>\n      <td>4582620000</td>\n      <td>^GSPC</td>\n      <td>3725.868617</td>\n      <td>3701.245257</td>\n      <td>3501.135002</td>\n      <td>3596.246396</td>\n      <td>3680.049162</td>\n      <td>3713.370928</td>\n      <td>33.321766</td>\n      <td>3723.313640</td>\n      <td>3725.860107</td>\n    </tr>\n    <tr>\n      <th>2021-01-06</th>\n      <td>3712.199951</td>\n      <td>3783.040039</td>\n      <td>3705.340088</td>\n      <td>3748.139893</td>\n      <td>3748.139893</td>\n      <td>6049970000</td>\n      <td>^GSPC</td>\n      <td>3732.308594</td>\n      <td>3703.579532</td>\n      <td>3504.882102</td>\n      <td>3601.901396</td>\n      <td>3685.092920</td>\n      <td>3718.719999</td>\n      <td>33.627079</td>\n      <td>3739.864475</td>\n      <td>3747.139893</td>\n    </tr>\n    <tr>\n      <th>2021-01-07</th>\n      <td>3764.709961</td>\n      <td>3811.550049</td>\n      <td>3764.709961</td>\n      <td>3803.790039</td>\n      <td>3803.790039</td>\n      <td>5080870000</td>\n      <td>^GSPC</td>\n      <td>3742.084298</td>\n      <td>3708.904774</td>\n      <td>3509.191501</td>\n      <td>3609.957798</td>\n      <td>3693.885299</td>\n      <td>3731.807698</td>\n      <td>37.922399</td>\n      <td>3782.481518</td>\n      <td>3802.790039</td>\n    </tr>\n    <tr>\n      <th>2021-01-08</th>\n      <td>3815.050049</td>\n      <td>3826.689941</td>\n      <td>3783.600098</td>\n      <td>3824.679932</td>\n      <td>3824.679932</td>\n      <td>4764180000</td>\n      <td>^GSPC</td>\n      <td>3756.032854</td>\n      <td>3714.734770</td>\n      <td>3513.618401</td>\n      <td>3618.637798</td>\n      <td>3703.573790</td>\n      <td>3746.095734</td>\n      <td>42.521943</td>\n      <td>3810.613794</td>\n      <td>3823.679932</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-11-22</th>\n      <td>4712.000000</td>\n      <td>4743.830078</td>\n      <td>4682.169922</td>\n      <td>4682.939941</td>\n      <td>4682.939941</td>\n      <td>3206280000</td>\n      <td>^GSPC</td>\n      <td>4691.522810</td>\n      <td>4652.419968</td>\n      <td>4471.426069</td>\n      <td>4515.723359</td>\n      <td>4624.065500</td>\n      <td>4674.788751</td>\n      <td>50.723251</td>\n      <td>4688.152938</td>\n      <td>4681.939941</td>\n    </tr>\n    <tr>\n      <th>2021-11-23</th>\n      <td>4678.479980</td>\n      <td>4699.390137</td>\n      <td>4652.660156</td>\n      <td>4690.700195</td>\n      <td>4690.700195</td>\n      <td>3428780000</td>\n      <td>^GSPC</td>\n      <td>4692.644252</td>\n      <td>4658.335217</td>\n      <td>4474.809673</td>\n      <td>4520.676367</td>\n      <td>4629.001403</td>\n      <td>4677.236665</td>\n      <td>48.235262</td>\n      <td>4689.851110</td>\n      <td>4689.700195</td>\n    </tr>\n    <tr>\n      <th>2021-11-24</th>\n      <td>4675.779785</td>\n      <td>4702.870117</td>\n      <td>4659.890137</td>\n      <td>4701.459961</td>\n      <td>4701.459961</td>\n      <td>2464040000</td>\n      <td>^GSPC</td>\n      <td>4695.309989</td>\n      <td>4664.367118</td>\n      <td>4478.388872</td>\n      <td>4525.091562</td>\n      <td>4634.368704</td>\n      <td>4680.963326</td>\n      <td>46.594622</td>\n      <td>4697.590344</td>\n      <td>4700.459961</td>\n    </tr>\n    <tr>\n      <th>2021-11-26</th>\n      <td>4664.629883</td>\n      <td>4664.629883</td>\n      <td>4585.430176</td>\n      <td>4594.620117</td>\n      <td>4594.620117</td>\n      <td>2676740000</td>\n      <td>^GSPC</td>\n      <td>4680.127162</td>\n      <td>4666.411877</td>\n      <td>4480.753774</td>\n      <td>4527.508965</td>\n      <td>4631.424364</td>\n      <td>4667.679756</td>\n      <td>36.255392</td>\n      <td>4628.943526</td>\n      <td>4593.620117</td>\n    </tr>\n    <tr>\n      <th>2021-11-29</th>\n      <td>4628.750000</td>\n      <td>4672.950195</td>\n      <td>4625.259766</td>\n      <td>4655.270020</td>\n      <td>4655.270020</td>\n      <td>3471380000</td>\n      <td>^GSPC</td>\n      <td>4675.355748</td>\n      <td>4669.214262</td>\n      <td>4484.098276</td>\n      <td>4531.954561</td>\n      <td>4633.190709</td>\n      <td>4665.770565</td>\n      <td>32.579857</td>\n      <td>4646.494522</td>\n      <td>4654.270020</td>\n    </tr>\n  </tbody>\n</table>\n<p>229 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['df'].loc['2021-01-01':]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "result[\"test_df\"].to_excel(\"test_df_2.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}