{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "collab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {
    "id": "xYGjzHPFp4j4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if collab:\n",
    "    !pip3 install tensorflow pandas numpy matplotlib yahoo_fin sklearn fredapi openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1638181329593,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "9Bw7pGTHp4j8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from fredapi import Fred\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders(folders):\n",
    "    for dir in folders:\n",
    "        if not os.path.isdir(dir):\n",
    "            os.mkdir(dir)\n",
    "\n",
    "def delete_folders(folders):\n",
    "    for dir in folders:\n",
    "        if os.path.exists(dir):          \n",
    "            shutil.rmtree(dir, ignore_errors=True)\n",
    "            \n",
    "# delete_folders([\"2000_test2021_ema100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_ids = [\n",
    "    'CHNCPIALLMINMEI','USACPIALLMINMEI','BRACPIALLMINMEI','INDCPIALLMINMEI','BRAPROINDMISMEI'\n",
    "    ,'USAPROINDMISMEI','PCUOMFGOMFG','RUSCPIALLMINMEI','PIEATI02RUM661N','RUSPROMANMISMEI'\n",
    "    ,'UNRATENSA','GS10','M2NS','INTDSRUSM193N','TOTALNSA','MABMM301USM189S','ALTSALES','RSXFSN'\n",
    "    ,'HTRUCKSSA','M2REAL','M1NS','BUSLOANS','MCOILWTICO','DAUPNSA','FRGSHPUSM649NCIS','PCU33443344'\n",
    "    ,'AISRSA' ,'M1REAL','TRUCKD11','RAILFRTCARLOADS','MNFCTRIRNSA','DAUTOSAAR'\n",
    "    ,'LTOTALNSA','MVMTD027MNFRBDAL','USEPUINDXM','CEU4348400001','CEU1021100001'\n",
    "    ,'IPG3361T3S','TRESEGUSM052N','LAUTONSA','WPU114','RSGASSN','CMRMT','NATURALGAS'\n",
    "    ,'EMVOVERALLEMV','PCU483111483111','WPU101706','GASREGCOVM','WPU11','PCU48214821'\n",
    "    ,'WPU1413','MRTSIR441USN','U36SNO','PCU21112111','IPB53122N','IPB54100N','EXUSEU'\n",
    "    ,'PCU4841214841212','GASDESM','EXCHUS','IPN213111N','PCU21212121','WPU012'\n",
    "    # ,'M1109BUSM293NNBR','PCU484484','IC131','JTU2300JOL','WPU801104','WPU3011','PCU33613361'\n",
    "]\n",
    "new_ticker = ['DX-Y.NYB']\n",
    "\n",
    "# KBE:SPX XLF:SPX IYT:XLU XLU:XLP DBC:TLT IGE:XLP GDL:TLT GDX:GLD GDX:SPY QQQ:IVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1638181329593,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "DByat8cXpHf8",
    "outputId": "5e391f55-82dd-4b58-c292-8c5ce15c40f6"
   },
   "outputs": [],
   "source": [
    "# 27%\n",
    "# new_results = \"2000_test2021_close_nstep100\"\n",
    "# FEATURE_COLUMNS = [\"close\"]\n",
    "\n",
    "# 26%\n",
    "# new_results = \"1976_test2021_ema100_nstep100\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "\n",
    "# 20%\n",
    "# new_results = \"2000_test2021_close_nstep25\"\n",
    "# FEATURE_COLUMNS = [\"close\"]\n",
    "\n",
    "# 16%\n",
    "# new_results = \"2000_test2021_close_nstep10\"\n",
    "# FEATURE_COLUMNS = [\"close\"]\n",
    "\n",
    "# 22%\n",
    "# new_results = \"2000_test2021_close_nstep5\"\n",
    "# FEATURE_COLUMNS = [\"close\"]\n",
    "\n",
    "# 26%\n",
    "# new_results = \"2000_test2021_close\"\n",
    "# FEATURE_COLUMNS = [\"close\"]\n",
    "\n",
    "# 23%\n",
    "# new_results = \"2000_test2021_close_body\"\n",
    "# FEATURE_COLUMNS = [\"close\",\"body\"]\n",
    "\n",
    "# 19% интересный результат\n",
    "# new_results = \"2000_test2021_close_body_abs\"\n",
    "# FEATURE_COLUMNS = [\"close\",\"body_abs\"]\n",
    "\n",
    "# 24%\n",
    "# new_results = \"2000_test2021_candles\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "\n",
    "# 30%\n",
    "# new_results = \"2000_test2021_ema100\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"]\n",
    "\n",
    "# 33%\n",
    "delete_folders([\"2000_test2021_ema100_ep300\"])\n",
    "new_results = \"2000_test2021_ema100_ep300\"\n",
    "FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"]\n",
    "\n",
    "# 26\n",
    "# delete_folders([\"2000_test2021_ema100_ep300_adds\"])\n",
    "# new_results = \"2000_test2021_ema100_ep300_adds\"\n",
    "# FEATURE_COLUMNS = [\"close\", \n",
    "#                    \"volume\", \n",
    "#                    \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"]\n",
    "# FEATURE_COLUMNS = FEATURE_COLUMNS + [\n",
    "# #                                     'KBE:^GSPC',\n",
    "#                                      'XLF:^GSPC',\n",
    "# #                                     'IYT:XLU',\n",
    "#                                     'XLU:XLP',\n",
    "# #                                     'DBC:TLT',\n",
    "# #                                     'IGE:XLP',\n",
    "# #                                     'GDL:TLT','GDX:^GSPC'\n",
    "#                                     ]\n",
    "\n",
    "# 23\n",
    "# new_results = \"2000_test2021_ema100_new_ticker\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] + new_ticker \n",
    "\n",
    "\n",
    "# 27%\n",
    "# new_results = \"2000_test2021_ema50\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "\n",
    "# 29%\n",
    "# new_results = \"1976_test2021_ema100\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "# 3year 83%\n",
    "# new_results = \"1976_test2019_ema100\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "# 3 years 83%\n",
    "# new_results = \"1976_test2019_ema100_ep1500\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "# 3 years 74%\n",
    "# new_results = \"1976_test2019_ema100_ep1500_Lookup_Stet10\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "# 3 years -17%\n",
    "# new_results = \"1976_test2019_ema100_ep700_Lookup_Stet5\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "# 3years 79%\n",
    "# new_results = \"1976_test2019_ema100_ep700_Lookup_Stet25\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "\n",
    "# 3years 56%\n",
    "# new_results = \"1976_test2019_ema100_ep700_Lookup_Stet75\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "# 3years 85%\n",
    "# new_results = \"1976_test2019_ema100_ep700_Lookup_Stet35\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "# 3years 85%\n",
    "# delete_folders([\"1976_test2019_ema100_ep700_Lookup_Stet35\"])\n",
    "# new_results = \"1976_test2019_ema100_ep700_Lookup_Stet35\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "\n",
    "# 3 years 79%\n",
    "# new_results = \"1976_test2019_ema100_ep700_Lookup_Stet45\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "\n",
    "# 16%\n",
    "# new_results = \"1976_test2021_candles\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "\n",
    "# 28%\n",
    "# new_results = \"1976_test2021_close\"\n",
    "# FEATURE_COLUMNS = [\"close\"]\n",
    "\n",
    "# 26% - интересно\n",
    "# new_results = \"1976_test2021_ema200\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma200\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "\n",
    "\n",
    "if collab:\n",
    "    # Для работы с google диском\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    import sys\n",
    "    sys.path.append('/content/gdrive/MyDrive/Python/Market/')\n",
    "    data_path = '/content/gdrive/MyDrive/Python/Market/Data/stock_predictions/'\n",
    "\n",
    "    data_path = data_path + new_results\n",
    "\n",
    "    create_folders([data_path, data_path + \"/results\", data_path + \"/logs\", data_path + \"/data\" ,data_path + \"/test-results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1638181329594,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "ImGDBs6yp4j9",
    "outputId": "0f9b9936-2713-47c2-982d-00e6c5d8a2de",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3090\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "\n",
      "GPU работает\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "if not collab:\n",
    "    '''\n",
    "    gpu_info = !nvidia-smi\n",
    "    gpu_info = '\\n'.join(gpu_info)\n",
    "    if gpu_info.find('failed') >= 0:\n",
    "      print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "      print('and then re-execute this cell.')\n",
    "    else:\n",
    "      print(gpu_info)\n",
    "    '''\n",
    "    \n",
    "    # Активируем GPU\n",
    "    import torch\n",
    "\n",
    "    # setting device on GPU if available, else CPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device:', device)\n",
    "    print()\n",
    "\n",
    "    #Additional Info when using cuda\n",
    "    if device.type == 'cuda':\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print()\n",
    "        print(\"GPU работает\")\n",
    "        print(tf.config.list_physical_devices('GPU'))\n",
    "    else:\n",
    "        print()\n",
    "        print(\"GPU не работает\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1638181330081,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "rBhT_-W6p4kE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fred = Fred(api_key='39fa3bd07f8f55540a93e075a5f97cc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1638181330082,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "SkbXMnfUp4kE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1638181330082,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "fvEoObgNp4kF"
   },
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1638181330083,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "ZPSM5YrAp4kG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# def load_params():\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 35\n",
    "\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = True\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ema100\"] + series_ids \n",
    "\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "### training parameters\n",
    "\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "# OPTIMIZER = \"adam\"\n",
    "OPTIMIZER = \"RMSProp\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1500\n",
    "\n",
    "# Amazon stock market\n",
    "ticker = \"^GSPC\"\n",
    "ticker_data_filename = os.path.join(new_results + \"/data\", f\"{ticker}_{date_now}\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\"\n",
    "        \n",
    "# load_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1638181330083,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "EnnrUj4yp4kG"
   },
   "outputs": [],
   "source": [
    "def get_technical_indicators(dataset):\n",
    "    # Create 7 and 21 days Moving Average\n",
    "    dataset['ma7'] = dataset['close'].rolling(window=7).mean()\n",
    "    dataset['ma21'] = dataset['close'].rolling(window=21).mean()\n",
    "    \n",
    "    dataset['ma100'] = dataset['close'].rolling(window=100).mean()\n",
    "    dataset['ma200'] = dataset['close'].rolling(window=200).mean()\n",
    "    dataset['ma50'] = dataset['close'].rolling(window=50).mean()\n",
    "\n",
    "    # Create MACD\n",
    "    dataset['26ema'] = pd.Series.ewm(dataset['close'], span=26).mean()\n",
    "    dataset['12ema'] = pd.Series.ewm(dataset['close'], span=12).mean()\n",
    "    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])\n",
    "\n",
    "    # Create Bollinger Bands\n",
    "    # dataset['20sd'] = pd.stats.moments.rolling_std(dataset['GS'],20)\n",
    "    # dataset['upper_band'] = dataset['ma21'] + (dataset['20sd']*2)\n",
    "    # dataset['lower_band'] = dataset['ma21'] - (dataset['20sd']*2)\n",
    "\n",
    "    # Create Exponential moving average\n",
    "    dataset['ema'] = dataset['close'].ewm(com=0.5).mean()\n",
    "\n",
    "    # Create Momentum\n",
    "    dataset['momentum'] = dataset['close']-1\n",
    "\n",
    "    dataset['body'] = dataset['close'] - dataset['open']\n",
    "    dataset['body_abs'] = abs(dataset['close'] - dataset['open'])\n",
    "\n",
    "    dataset.replace('', np.nan, inplace=True)\n",
    "    dataset = dataset.dropna()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_ticker(ticker_):\n",
    "#     new_ticker = pd.DataFrame()\n",
    "#     if not new_ticker.empty:\n",
    "#         new_ticker = new_ticker.iloc[0:0]\n",
    "    new_ticker = si.get_data(ticker_)\n",
    "    new_ticker.rename(columns={'close':ticker_}, inplace=True)\n",
    "    new_ticker.drop(['open', 'high','low','volume','ticker','adjclose'], axis='columns', inplace=True)\n",
    "#     dataset = pd.concat([new_ticker , dataset], axis=1)\n",
    "    \n",
    "#     dataset.replace('', np.nan, inplace=True)\n",
    "#     dataset = dataset.dropna()\n",
    "    \n",
    "    return new_ticker\n",
    "\n",
    "def ratio_tickers(tickers_list):\n",
    "    df_ticker = pd.DataFrame()\n",
    "    for tickers in tickers_list:\n",
    "        ticker = tickers.split(':')\n",
    "        \n",
    "        if not df_ticker.empty:\n",
    "            df_ticker = pd.concat([df_ticker, get_new_ticker(ticker[0])  , get_new_ticker(ticker[1]) ], axis=1)\n",
    "        else:\n",
    "            df_ticker = pd.concat([get_new_ticker(ticker[0])  , get_new_ticker(ticker[1]) ], axis=1)\n",
    "\n",
    "        df_ticker[tickers] = df_ticker[ticker[0]] / df_ticker[ticker[1]]   \n",
    "\n",
    "        df_ticker.drop([ticker[0], ticker[1]], axis='columns', inplace=True)\n",
    "#         if not sum_fickers.empty:\n",
    "#             sum_tickers = pd.concat([sum_tickers,df_ticker], axis=1)\n",
    "#         else:\n",
    "#         sum_tickers = df_ticker.copy(deep=True)\n",
    "#     df_ticker.to_excel(\"tickers.xlsx\")\n",
    "    \n",
    "#     print(df_ticker)\n",
    "    return df_ticker\n",
    "\n",
    "#     ratio_tickers(['KBE:^GSPC','XLF:^GSPC','IYT:XLU','XLU:XLP','DBC:TLT','IGE:XLP','GDL:TLT','GDX:^GSPC',\n",
    "# #                'QQQ:IVM'\n",
    "#               ])\n",
    "    \n",
    "\n",
    "\n",
    "# KBE:SPX XLF:SPX IYT:XLU XLU:XLP DBC:TLT IGE:XLP GDL:TLT GDX:GLD GDX:SPY QQQ:IVM\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df = si.get_data(ticker,start_date = '2000-01-01')\n",
    "# new_ticker = si.get_data(ticker)\n",
    "# new_ticker.rename(columns={'close':'close_'+ ticker}, inplace=True)\n",
    "# new_ticker.drop(['open', 'high','low','volume','ticker','adjclose'], axis='columns', inplace=True)\n",
    "# dataset = pd.concat([new_ticker , df], axis=1)\n",
    "# dataset.replace('', np.nan, inplace=True)\n",
    "# dataset = new_ticker.dropna()\n",
    "# for nT in new_ticker:\n",
    "#     df = get_new_ticker(df,nT)\n",
    "# dataset\n",
    "# df = get_technical_indicators(df)\n",
    "# print('KBE/^SPX'.split('/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_4 = pd.DataFrame()\n",
    "# dt = get_new_ticker(dataset_4, 'KBE/^SPX')\n",
    "# dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1638181330084,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "LAEXFedTp4kH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['close', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    if not df.empty:\n",
    "        df = df.iloc[0:0]\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "#         df = si.get_data(ticker)\n",
    "        df = si.get_data(ticker,start_date = '2000-01-01')\n",
    "#         df = si.get_data(ticker,start_date = '2000-01-01', end_date = None, index_as_date = True, interval= \"1mo\")\n",
    "#         df = si.get_data(ticker,start_date = '2000-01-01')\n",
    "        # get_data(ticker, start_date = None, end_date = None, index_as_date = True, interval = “1d”)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    \n",
    "#     for nT in new_ticker:\n",
    "#         df = get_new_ticker(df,nT)\n",
    "#     df_ratio = ratio_tickers(['KBE:^GSPC','XLF:^GSPC','IYT:XLU','XLU:XLP','DBC:TLT','IGE:XLP','GDL:TLT','GDX:^GSPC',\n",
    "# #                'QQQ:IVM'\n",
    "#               ])\n",
    "    \n",
    "#     df = pd.concat([ df_ratio  , df ], axis=1)\n",
    "    \n",
    "    df = get_technical_indicators(df)\n",
    "    \n",
    "#     df_fred = get_fred()\n",
    "#     df = pd.concat([df_fred , df], axis=1)\n",
    "\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # print(df.tail)\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['close'].shift(-lookup_step)\n",
    "\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    \n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    \n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        # train_samples = int((1 - test_size) * len(X))\n",
    "        train_samples = len(X) - len(result['df'].loc['2021-01-01':])\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1638181330084,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "QtLaz_wsp4kI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_fred():\n",
    "    data_ = {}\n",
    "    for series_id in series_ids:\n",
    "        data_[series_id] = fred.get_series(series_id, observation_start='1/1/2000')\n",
    "    dataset_ = pd.concat(data_, axis=1)\n",
    "\n",
    "    # заполняем\n",
    "    dataset_.replace('', np.nan, inplace=True)\n",
    "\n",
    "    # заполняем пропуски в данных средним значением за последние 10 периодов\n",
    "    dataset_=dataset_.fillna(dataset_[-10:].mean())\n",
    "    return dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1638181330327,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "pXBjQ_oKp4kL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "executionInfo": {
     "elapsed": 4983,
     "status": "ok",
     "timestamp": 1638181335305,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "bvWXUYX9p4kL",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# def compile_model():\n",
    "# create these folders if they does not exist\n",
    "create_folders([new_results, new_results + \"/results\", new_results + \"/logs\", new_results + \"/data\", new_results + \"/test-results\"])\n",
    "\n",
    "# load the data\n",
    "data = pd.DataFrame()\n",
    "if not data.empty:\n",
    "    data = data.iloc[0:0]\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename + \".csv\")\n",
    "# data[\"df\"].to_excel(\"view.xlsx\")\n",
    "data[\"df\"].to_excel(ticker_data_filename + \".xlsx\")\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "executionInfo": {
     "elapsed": 2670,
     "status": "ok",
     "timestamp": 1638181337962,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "QWsK_pe6p4kM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data[\"df\"].to_excel(\"view_start.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2005743,
     "status": "ok",
     "timestamp": 1638183343691,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "9Bsl1LKup4kM",
    "outputId": "af9586eb-5c94-4629-e9b7-c3095e59d31e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создаем новую модель2000_test2021_ema100_ep300\n",
      "Epoch 1/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 0.0171 - mean_absolute_error: 0.0747\n",
      "Epoch 00001: val_loss improved from inf to 0.04379, saving model to 2000_test2021_ema100_ep300/results\\2021-12-04_^GSPC-sh-1-sc-1-sbd-1-huber_loss-RMSProp-LSTM-seq-50-step-35-layers-2-units-256.h5\n",
      "79/79 [==============================] - 5s 34ms/step - loss: 0.0169 - mean_absolute_error: 0.0745 - val_loss: 0.0438 - val_mean_absolute_error: 0.2948\n",
      "Epoch 2/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0487\n",
      "Epoch 00002: val_loss did not improve from 0.04379\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0023 - mean_absolute_error: 0.0488 - val_loss: 0.0732 - val_mean_absolute_error: 0.3809\n",
      "Epoch 3/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0402\n",
      "Epoch 00003: val_loss improved from 0.04379 to 0.00023, saving model to 2000_test2021_ema100_ep300/results\\2021-12-04_^GSPC-sh-1-sc-1-sbd-1-huber_loss-RMSProp-LSTM-seq-50-step-35-layers-2-units-256.h5\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0016 - mean_absolute_error: 0.0402 - val_loss: 2.3026e-04 - val_mean_absolute_error: 0.0177\n",
      "Epoch 4/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0370\n",
      "Epoch 00004: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0014 - mean_absolute_error: 0.0370 - val_loss: 0.0019 - val_mean_absolute_error: 0.0579\n",
      "Epoch 5/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0345\n",
      "Epoch 00005: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0012 - mean_absolute_error: 0.0345 - val_loss: 0.0036 - val_mean_absolute_error: 0.0819\n",
      "Epoch 6/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0322\n",
      "Epoch 00006: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0011 - mean_absolute_error: 0.0322 - val_loss: 0.0093 - val_mean_absolute_error: 0.1344\n",
      "Epoch 7/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.9887e-04 - mean_absolute_error: 0.0309\n",
      "Epoch 00007: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.9887e-04 - mean_absolute_error: 0.0309 - val_loss: 6.1592e-04 - val_mean_absolute_error: 0.0290\n",
      "Epoch 8/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.0992e-04 - mean_absolute_error: 0.0297\n",
      "Epoch 00008: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.0992e-04 - mean_absolute_error: 0.0297 - val_loss: 0.0082 - val_mean_absolute_error: 0.1259\n",
      "Epoch 9/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.2359e-04 - mean_absolute_error: 0.0294\n",
      "Epoch 00009: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.2105e-04 - mean_absolute_error: 0.0294 - val_loss: 0.0020 - val_mean_absolute_error: 0.0582\n",
      "Epoch 10/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.1044e-04 - mean_absolute_error: 0.0279\n",
      "Epoch 00010: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.1044e-04 - mean_absolute_error: 0.0279 - val_loss: 0.0066 - val_mean_absolute_error: 0.1108\n",
      "Epoch 11/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.0587e-04 - mean_absolute_error: 0.0281\n",
      "Epoch 00011: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.0041e-04 - mean_absolute_error: 0.0280 - val_loss: 0.0106 - val_mean_absolute_error: 0.1425\n",
      "Epoch 12/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.3627e-04 - mean_absolute_error: 0.0268\n",
      "Epoch 00012: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 7.3558e-04 - mean_absolute_error: 0.0268 - val_loss: 0.0130 - val_mean_absolute_error: 0.1574\n",
      "Epoch 13/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.3302e-04 - mean_absolute_error: 0.0267\n",
      "Epoch 00013: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.2908e-04 - mean_absolute_error: 0.0266 - val_loss: 0.0040 - val_mean_absolute_error: 0.0824\n",
      "Epoch 14/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.3071e-04 - mean_absolute_error: 0.0262\n",
      "Epoch 00014: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 7.3184e-04 - mean_absolute_error: 0.0263 - val_loss: 0.0157 - val_mean_absolute_error: 0.1745\n",
      "Epoch 15/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.8691e-04 - mean_absolute_error: 0.0254\n",
      "Epoch 00015: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8582e-04 - mean_absolute_error: 0.0254 - val_loss: 0.0086 - val_mean_absolute_error: 0.1262\n",
      "Epoch 16/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.7229e-04 - mean_absolute_error: 0.0251\n",
      "Epoch 00016: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.7179e-04 - mean_absolute_error: 0.0251 - val_loss: 0.0141 - val_mean_absolute_error: 0.1646\n",
      "Epoch 17/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5421e-04 - mean_absolute_error: 0.0250\n",
      "Epoch 00017: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 6.5421e-04 - mean_absolute_error: 0.0250 - val_loss: 0.0125 - val_mean_absolute_error: 0.1545\n",
      "Epoch 18/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.2561e-04 - mean_absolute_error: 0.0243\n",
      "Epoch 00018: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 6.2498e-04 - mean_absolute_error: 0.0243 - val_loss: 0.0092 - val_mean_absolute_error: 0.1308\n",
      "Epoch 19/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2177e-04 - mean_absolute_error: 0.0242\n",
      "Epoch 00019: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 6.2177e-04 - mean_absolute_error: 0.0242 - val_loss: 0.0163 - val_mean_absolute_error: 0.1776\n",
      "Epoch 20/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.0485e-04 - mean_absolute_error: 0.0242\n",
      "Epoch 00020: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 6.1050e-04 - mean_absolute_error: 0.0243 - val_loss: 0.0035 - val_mean_absolute_error: 0.0753\n",
      "Epoch 21/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.1191e-04 - mean_absolute_error: 0.0237\n",
      "Epoch 00021: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1146e-04 - mean_absolute_error: 0.0237 - val_loss: 0.0100 - val_mean_absolute_error: 0.1374\n",
      "Epoch 22/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.8561e-04 - mean_absolute_error: 0.0240\n",
      "Epoch 00022: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 5.8543e-04 - mean_absolute_error: 0.0240 - val_loss: 0.0185 - val_mean_absolute_error: 0.1885\n",
      "Epoch 23/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.1469e-04 - mean_absolute_error: 0.0239\n",
      "Epoch 00023: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 6.1270e-04 - mean_absolute_error: 0.0239 - val_loss: 0.0118 - val_mean_absolute_error: 0.1492\n",
      "Epoch 24/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.8387e-04 - mean_absolute_error: 0.0234\n",
      "Epoch 00024: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 5.8701e-04 - mean_absolute_error: 0.0235 - val_loss: 0.0028 - val_mean_absolute_error: 0.0692\n",
      "Epoch 25/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.8380e-04 - mean_absolute_error: 0.0232\n",
      "Epoch 00025: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 5.8168e-04 - mean_absolute_error: 0.0232 - val_loss: 0.0178 - val_mean_absolute_error: 0.1852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.5460e-04 - mean_absolute_error: 0.0230\n",
      "Epoch 00026: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 5.5561e-04 - mean_absolute_error: 0.0230 - val_loss: 0.0079 - val_mean_absolute_error: 0.1180\n",
      "Epoch 27/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.7057e-04 - mean_absolute_error: 0.0231\n",
      "Epoch 00027: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.7057e-04 - mean_absolute_error: 0.0231 - val_loss: 0.0104 - val_mean_absolute_error: 0.1399\n",
      "Epoch 28/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.4601e-04 - mean_absolute_error: 0.0227\n",
      "Epoch 00028: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.4569e-04 - mean_absolute_error: 0.0227 - val_loss: 0.0158 - val_mean_absolute_error: 0.1737\n",
      "Epoch 29/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.2866e-04 - mean_absolute_error: 0.0224\n",
      "Epoch 00029: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.2820e-04 - mean_absolute_error: 0.0224 - val_loss: 0.0100 - val_mean_absolute_error: 0.1364\n",
      "Epoch 30/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.6034e-04 - mean_absolute_error: 0.0225\n",
      "Epoch 00030: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.6034e-04 - mean_absolute_error: 0.0225 - val_loss: 0.0045 - val_mean_absolute_error: 0.0869\n",
      "Epoch 31/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.5010e-04 - mean_absolute_error: 0.0227\n",
      "Epoch 00031: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 5.5010e-04 - mean_absolute_error: 0.0227 - val_loss: 0.0061 - val_mean_absolute_error: 0.1035\n",
      "Epoch 32/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.5180e-04 - mean_absolute_error: 0.0226\n",
      "Epoch 00032: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 5.4965e-04 - mean_absolute_error: 0.0225 - val_loss: 0.0026 - val_mean_absolute_error: 0.0617\n",
      "Epoch 33/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.5051e-04 - mean_absolute_error: 0.0224\n",
      "Epoch 00033: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 5.4837e-04 - mean_absolute_error: 0.0224 - val_loss: 0.0121 - val_mean_absolute_error: 0.1516\n",
      "Epoch 34/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.1744e-04 - mean_absolute_error: 0.0220\n",
      "Epoch 00034: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 5.1853e-04 - mean_absolute_error: 0.0221 - val_loss: 0.0224 - val_mean_absolute_error: 0.2092\n",
      "Epoch 35/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.2045e-04 - mean_absolute_error: 0.0218\n",
      "Epoch 00035: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 5.2066e-04 - mean_absolute_error: 0.0218 - val_loss: 0.0158 - val_mean_absolute_error: 0.1738\n",
      "Epoch 36/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.1972e-04 - mean_absolute_error: 0.0219\n",
      "Epoch 00036: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 5.1766e-04 - mean_absolute_error: 0.0219 - val_loss: 0.0153 - val_mean_absolute_error: 0.1712\n",
      "Epoch 37/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.1654e-04 - mean_absolute_error: 0.0219\n",
      "Epoch 00037: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 5.1604e-04 - mean_absolute_error: 0.0219 - val_loss: 0.0076 - val_mean_absolute_error: 0.1188\n",
      "Epoch 38/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.1403e-04 - mean_absolute_error: 0.0220\n",
      "Epoch 00038: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.1403e-04 - mean_absolute_error: 0.0220 - val_loss: 0.0050 - val_mean_absolute_error: 0.0939\n",
      "Epoch 39/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.0928e-04 - mean_absolute_error: 0.0218\n",
      "Epoch 00039: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 5.0928e-04 - mean_absolute_error: 0.0218 - val_loss: 0.0126 - val_mean_absolute_error: 0.1548\n",
      "Epoch 40/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.8364e-04 - mean_absolute_error: 0.0214\n",
      "Epoch 00040: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.8111e-04 - mean_absolute_error: 0.0214 - val_loss: 0.0100 - val_mean_absolute_error: 0.1362\n",
      "Epoch 41/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.9984e-04 - mean_absolute_error: 0.0215\n",
      "Epoch 00041: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.9935e-04 - mean_absolute_error: 0.0215 - val_loss: 0.0035 - val_mean_absolute_error: 0.0758\n",
      "Epoch 42/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.2465e-04 - mean_absolute_error: 0.0219\n",
      "Epoch 00042: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.2465e-04 - mean_absolute_error: 0.0219 - val_loss: 0.0082 - val_mean_absolute_error: 0.1245\n",
      "Epoch 43/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.8956e-04 - mean_absolute_error: 0.0212\n",
      "Epoch 00043: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.8933e-04 - mean_absolute_error: 0.0212 - val_loss: 0.0098 - val_mean_absolute_error: 0.1349\n",
      "Epoch 44/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.8020e-04 - mean_absolute_error: 0.0215\n",
      "Epoch 00044: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.8020e-04 - mean_absolute_error: 0.0215 - val_loss: 0.0134 - val_mean_absolute_error: 0.1575\n",
      "Epoch 45/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.7562e-04 - mean_absolute_error: 0.0211\n",
      "Epoch 00045: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.7562e-04 - mean_absolute_error: 0.0211 - val_loss: 0.0085 - val_mean_absolute_error: 0.1233\n",
      "Epoch 46/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.0256e-04 - mean_absolute_error: 0.0212\n",
      "Epoch 00046: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.0286e-04 - mean_absolute_error: 0.0212 - val_loss: 0.0021 - val_mean_absolute_error: 0.0552\n",
      "Epoch 47/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.7468e-04 - mean_absolute_error: 0.0209\n",
      "Epoch 00047: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.7468e-04 - mean_absolute_error: 0.0209 - val_loss: 0.0048 - val_mean_absolute_error: 0.0879\n",
      "Epoch 48/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.5539e-04 - mean_absolute_error: 0.0210\n",
      "Epoch 00048: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.5539e-04 - mean_absolute_error: 0.0210 - val_loss: 0.0066 - val_mean_absolute_error: 0.1095\n",
      "Epoch 49/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.7961e-04 - mean_absolute_error: 0.0211\n",
      "Epoch 00049: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.7717e-04 - mean_absolute_error: 0.0210 - val_loss: 0.0078 - val_mean_absolute_error: 0.1198\n",
      "Epoch 50/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.5828e-04 - mean_absolute_error: 0.0208\n",
      "Epoch 00050: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 4.5828e-04 - mean_absolute_error: 0.0208 - val_loss: 0.0068 - val_mean_absolute_error: 0.1043\n",
      "Epoch 51/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.5096e-04 - mean_absolute_error: 0.0207\n",
      "Epoch 00051: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 4.4754e-04 - mean_absolute_error: 0.0207 - val_loss: 0.0151 - val_mean_absolute_error: 0.1692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 4.5318e-04 - mean_absolute_error: 0.0207\n",
      "Epoch 00052: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.5306e-04 - mean_absolute_error: 0.0207 - val_loss: 0.0068 - val_mean_absolute_error: 0.1076\n",
      "Epoch 53/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.7034e-04 - mean_absolute_error: 0.0209\n",
      "Epoch 00053: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 4.7034e-04 - mean_absolute_error: 0.0209 - val_loss: 0.0104 - val_mean_absolute_error: 0.1355\n",
      "Epoch 54/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 4.7196e-04 - mean_absolute_error: 0.0209\n",
      "Epoch 00054: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.7153e-04 - mean_absolute_error: 0.0209 - val_loss: 0.0091 - val_mean_absolute_error: 0.1277\n",
      "Epoch 55/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 4.3041e-04 - mean_absolute_error: 0.0202\n",
      "Epoch 00055: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.2662e-04 - mean_absolute_error: 0.0201 - val_loss: 0.0110 - val_mean_absolute_error: 0.1410\n",
      "Epoch 56/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 4.7460e-04 - mean_absolute_error: 0.0207\n",
      "Epoch 00056: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.7436e-04 - mean_absolute_error: 0.0207 - val_loss: 0.0123 - val_mean_absolute_error: 0.1491\n",
      "Epoch 57/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 4.6176e-04 - mean_absolute_error: 0.0207\n",
      "Epoch 00057: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.6098e-04 - mean_absolute_error: 0.0206 - val_loss: 0.0119 - val_mean_absolute_error: 0.1475\n",
      "Epoch 58/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.3785e-04 - mean_absolute_error: 0.0203\n",
      "Epoch 00058: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 4.3828e-04 - mean_absolute_error: 0.0203 - val_loss: 0.0142 - val_mean_absolute_error: 0.1646\n",
      "Epoch 59/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.5877e-04 - mean_absolute_error: 0.0205\n",
      "Epoch 00059: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.5801e-04 - mean_absolute_error: 0.0205 - val_loss: 0.0159 - val_mean_absolute_error: 0.1719\n",
      "Epoch 60/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.5553e-04 - mean_absolute_error: 0.0205\n",
      "Epoch 00060: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.5257e-04 - mean_absolute_error: 0.0205 - val_loss: 0.0038 - val_mean_absolute_error: 0.0785\n",
      "Epoch 61/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.5628e-04 - mean_absolute_error: 0.0206\n",
      "Epoch 00061: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.5627e-04 - mean_absolute_error: 0.0206 - val_loss: 0.0160 - val_mean_absolute_error: 0.1712\n",
      "Epoch 62/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.7004e-04 - mean_absolute_error: 0.0208\n",
      "Epoch 00062: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.7004e-04 - mean_absolute_error: 0.0208 - val_loss: 0.0060 - val_mean_absolute_error: 0.0963\n",
      "Epoch 63/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.2646e-04 - mean_absolute_error: 0.0201\n",
      "Epoch 00063: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.2690e-04 - mean_absolute_error: 0.0201 - val_loss: 0.0125 - val_mean_absolute_error: 0.1500\n",
      "Epoch 64/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.5846e-04 - mean_absolute_error: 0.0207\n",
      "Epoch 00064: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.5492e-04 - mean_absolute_error: 0.0206 - val_loss: 0.0119 - val_mean_absolute_error: 0.1448\n",
      "Epoch 65/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 4.5244e-04 - mean_absolute_error: 0.0204\n",
      "Epoch 00065: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.5304e-04 - mean_absolute_error: 0.0204 - val_loss: 0.0170 - val_mean_absolute_error: 0.1792\n",
      "Epoch 66/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.1873e-04 - mean_absolute_error: 0.0202\n",
      "Epoch 00066: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.1873e-04 - mean_absolute_error: 0.0202 - val_loss: 0.0083 - val_mean_absolute_error: 0.1196\n",
      "Epoch 67/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.3706e-04 - mean_absolute_error: 0.0202\n",
      "Epoch 00067: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.3706e-04 - mean_absolute_error: 0.0202 - val_loss: 0.0100 - val_mean_absolute_error: 0.1296\n",
      "Epoch 68/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 4.2420e-04 - mean_absolute_error: 0.0200\n",
      "Epoch 00068: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.2387e-04 - mean_absolute_error: 0.0200 - val_loss: 0.0121 - val_mean_absolute_error: 0.1461\n",
      "Epoch 69/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.2056e-04 - mean_absolute_error: 0.0201\n",
      "Epoch 00069: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 4.2112e-04 - mean_absolute_error: 0.0201 - val_loss: 0.0138 - val_mean_absolute_error: 0.1592\n",
      "Epoch 70/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.3613e-04 - mean_absolute_error: 0.0200\n",
      "Epoch 00070: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.3567e-04 - mean_absolute_error: 0.0200 - val_loss: 0.0203 - val_mean_absolute_error: 0.1936\n",
      "Epoch 71/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.0286e-04 - mean_absolute_error: 0.0198\n",
      "Epoch 00071: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 4.0286e-04 - mean_absolute_error: 0.0198 - val_loss: 0.0127 - val_mean_absolute_error: 0.1485\n",
      "Epoch 72/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 4.0244e-04 - mean_absolute_error: 0.0194\n",
      "Epoch 00072: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 4.0235e-04 - mean_absolute_error: 0.0194 - val_loss: 0.0157 - val_mean_absolute_error: 0.1660\n",
      "Epoch 73/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.7531e-04 - mean_absolute_error: 0.0192\n",
      "Epoch 00073: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.7531e-04 - mean_absolute_error: 0.0192 - val_loss: 0.0130 - val_mean_absolute_error: 0.1466\n",
      "Epoch 74/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.8074e-04 - mean_absolute_error: 0.0192\n",
      "Epoch 00074: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.8027e-04 - mean_absolute_error: 0.0192 - val_loss: 0.0201 - val_mean_absolute_error: 0.1899\n",
      "Epoch 75/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 4.2181e-04 - mean_absolute_error: 0.0199\n",
      "Epoch 00075: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.1925e-04 - mean_absolute_error: 0.0199 - val_loss: 0.0298 - val_mean_absolute_error: 0.2351\n",
      "Epoch 76/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.8347e-04 - mean_absolute_error: 0.0193\n",
      "Epoch 00076: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.8347e-04 - mean_absolute_error: 0.0193 - val_loss: 0.0203 - val_mean_absolute_error: 0.1904\n",
      "Epoch 77/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.1873e-04 - mean_absolute_error: 0.0199\n",
      "Epoch 00077: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.1873e-04 - mean_absolute_error: 0.0199 - val_loss: 0.0182 - val_mean_absolute_error: 0.1860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.9870e-04 - mean_absolute_error: 0.0194\n",
      "Epoch 00078: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.9903e-04 - mean_absolute_error: 0.0194 - val_loss: 0.0158 - val_mean_absolute_error: 0.1650\n",
      "Epoch 79/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.8194e-04 - mean_absolute_error: 0.0193\n",
      "Epoch 00079: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.7949e-04 - mean_absolute_error: 0.0192 - val_loss: 0.0172 - val_mean_absolute_error: 0.1707\n",
      "Epoch 80/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 4.0524e-04 - mean_absolute_error: 0.0196\n",
      "Epoch 00080: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 4.0524e-04 - mean_absolute_error: 0.0196 - val_loss: 0.0240 - val_mean_absolute_error: 0.2066\n",
      "Epoch 81/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.7347e-04 - mean_absolute_error: 0.0193\n",
      "Epoch 00081: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 3.7347e-04 - mean_absolute_error: 0.0193 - val_loss: 0.0254 - val_mean_absolute_error: 0.2124\n",
      "Epoch 82/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.6994e-04 - mean_absolute_error: 0.0191\n",
      "Epoch 00082: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.6994e-04 - mean_absolute_error: 0.0191 - val_loss: 0.0212 - val_mean_absolute_error: 0.1909\n",
      "Epoch 83/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.7356e-04 - mean_absolute_error: 0.0191\n",
      "Epoch 00083: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.7356e-04 - mean_absolute_error: 0.0191 - val_loss: 0.0214 - val_mean_absolute_error: 0.1920\n",
      "Epoch 84/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.7387e-04 - mean_absolute_error: 0.0190\n",
      "Epoch 00084: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.7312e-04 - mean_absolute_error: 0.0190 - val_loss: 0.0146 - val_mean_absolute_error: 0.1567\n",
      "Epoch 85/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.6860e-04 - mean_absolute_error: 0.0189\n",
      "Epoch 00085: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.6860e-04 - mean_absolute_error: 0.0189 - val_loss: 0.0176 - val_mean_absolute_error: 0.1739\n",
      "Epoch 86/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.6457e-04 - mean_absolute_error: 0.0188\n",
      "Epoch 00086: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.6457e-04 - mean_absolute_error: 0.0188 - val_loss: 0.0232 - val_mean_absolute_error: 0.2028\n",
      "Epoch 87/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.5941e-04 - mean_absolute_error: 0.0189\n",
      "Epoch 00087: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.5941e-04 - mean_absolute_error: 0.0189 - val_loss: 0.0269 - val_mean_absolute_error: 0.2184\n",
      "Epoch 88/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.4522e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 00088: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.4522e-04 - mean_absolute_error: 0.0186 - val_loss: 0.0339 - val_mean_absolute_error: 0.2532\n",
      "Epoch 89/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.8873e-04 - mean_absolute_error: 0.0192\n",
      "Epoch 00089: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 3.8873e-04 - mean_absolute_error: 0.0192 - val_loss: 0.0252 - val_mean_absolute_error: 0.2142\n",
      "Epoch 90/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.4856e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 00090: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.5190e-04 - mean_absolute_error: 0.0187 - val_loss: 0.0234 - val_mean_absolute_error: 0.2046\n",
      "Epoch 91/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.6710e-04 - mean_absolute_error: 0.0188\n",
      "Epoch 00091: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.6703e-04 - mean_absolute_error: 0.0188 - val_loss: 0.0152 - val_mean_absolute_error: 0.1580\n",
      "Epoch 92/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.5176e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 00092: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.5176e-04 - mean_absolute_error: 0.0186 - val_loss: 0.0227 - val_mean_absolute_error: 0.2025\n",
      "Epoch 93/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.4266e-04 - mean_absolute_error: 0.0188\n",
      "Epoch 00093: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.4254e-04 - mean_absolute_error: 0.0188 - val_loss: 0.0167 - val_mean_absolute_error: 0.1689\n",
      "Epoch 94/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.3635e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 00094: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.3720e-04 - mean_absolute_error: 0.0184 - val_loss: 0.0227 - val_mean_absolute_error: 0.2051\n",
      "Epoch 95/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.4013e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 00095: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.3884e-04 - mean_absolute_error: 0.0186 - val_loss: 0.0180 - val_mean_absolute_error: 0.1769\n",
      "Epoch 96/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.3132e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 00096: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.3157e-04 - mean_absolute_error: 0.0183 - val_loss: 0.0134 - val_mean_absolute_error: 0.1460\n",
      "Epoch 97/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.4619e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 00097: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.4598e-04 - mean_absolute_error: 0.0184 - val_loss: 0.0238 - val_mean_absolute_error: 0.2079\n",
      "Epoch 98/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.3954e-04 - mean_absolute_error: 0.0188\n",
      "Epoch 00098: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.3772e-04 - mean_absolute_error: 0.0187 - val_loss: 0.0191 - val_mean_absolute_error: 0.1794\n",
      "Epoch 99/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.3860e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 00099: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 3.3836e-04 - mean_absolute_error: 0.0186 - val_loss: 0.0176 - val_mean_absolute_error: 0.1753\n",
      "Epoch 100/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.6423e-04 - mean_absolute_error: 0.0190\n",
      "Epoch 00100: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.6408e-04 - mean_absolute_error: 0.0190 - val_loss: 0.0332 - val_mean_absolute_error: 0.2473\n",
      "Epoch 101/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.3100e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 00101: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.3213e-04 - mean_absolute_error: 0.0185 - val_loss: 0.0306 - val_mean_absolute_error: 0.2347\n",
      "Epoch 102/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.2809e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 00102: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.2892e-04 - mean_absolute_error: 0.0185 - val_loss: 0.0341 - val_mean_absolute_error: 0.2526\n",
      "Epoch 103/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.4157e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 00103: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.4227e-04 - mean_absolute_error: 0.0186 - val_loss: 0.0295 - val_mean_absolute_error: 0.2289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.4109e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 00104: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.4109e-04 - mean_absolute_error: 0.0185 - val_loss: 0.0211 - val_mean_absolute_error: 0.1895\n",
      "Epoch 105/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.0865e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 00105: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.0835e-04 - mean_absolute_error: 0.0180 - val_loss: 0.0249 - val_mean_absolute_error: 0.2076\n",
      "Epoch 106/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.2485e-04 - mean_absolute_error: 0.0181\n",
      "Epoch 00106: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.2353e-04 - mean_absolute_error: 0.0181 - val_loss: 0.0161 - val_mean_absolute_error: 0.1582\n",
      "Epoch 107/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 3.3507e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 00107: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 3.3393e-04 - mean_absolute_error: 0.0183 - val_loss: 0.0252 - val_mean_absolute_error: 0.2089\n",
      "Epoch 108/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.1267e-04 - mean_absolute_error: 0.0181\n",
      "Epoch 00108: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.1267e-04 - mean_absolute_error: 0.0181 - val_loss: 0.0255 - val_mean_absolute_error: 0.2125\n",
      "Epoch 109/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.1065e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 00109: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.0971e-04 - mean_absolute_error: 0.0179 - val_loss: 0.0257 - val_mean_absolute_error: 0.2142\n",
      "Epoch 110/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.0976e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 00110: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.0970e-04 - mean_absolute_error: 0.0179 - val_loss: 0.0286 - val_mean_absolute_error: 0.2259\n",
      "Epoch 111/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.1522e-04 - mean_absolute_error: 0.0181\n",
      "Epoch 00111: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.1513e-04 - mean_absolute_error: 0.0181 - val_loss: 0.0260 - val_mean_absolute_error: 0.2128\n",
      "Epoch 112/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 3.1777e-04 - mean_absolute_error: 0.0181\n",
      "Epoch 00112: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.1686e-04 - mean_absolute_error: 0.0181 - val_loss: 0.0247 - val_mean_absolute_error: 0.2047\n",
      "Epoch 113/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 3.0304e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 00113: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.0198e-04 - mean_absolute_error: 0.0179 - val_loss: 0.0273 - val_mean_absolute_error: 0.2214\n",
      "Epoch 114/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 3.0740e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 00114: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.0732e-04 - mean_absolute_error: 0.0179 - val_loss: 0.0317 - val_mean_absolute_error: 0.2456\n",
      "Epoch 115/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.2018e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 00115: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.2018e-04 - mean_absolute_error: 0.0179 - val_loss: 0.0193 - val_mean_absolute_error: 0.1854\n",
      "Epoch 116/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.0989e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 00116: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.0989e-04 - mean_absolute_error: 0.0179 - val_loss: 0.0139 - val_mean_absolute_error: 0.1507\n",
      "Epoch 117/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.2336e-04 - mean_absolute_error: 0.0181\n",
      "Epoch 00117: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 3.2336e-04 - mean_absolute_error: 0.0181 - val_loss: 0.0163 - val_mean_absolute_error: 0.1649\n",
      "Epoch 118/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.1415e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 00118: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.1415e-04 - mean_absolute_error: 0.0177 - val_loss: 0.0259 - val_mean_absolute_error: 0.2186\n",
      "Epoch 119/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 3.0195e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 00119: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.0140e-04 - mean_absolute_error: 0.0179 - val_loss: 0.0265 - val_mean_absolute_error: 0.2212\n",
      "Epoch 120/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.9816e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 00120: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.9692e-04 - mean_absolute_error: 0.0175 - val_loss: 0.0202 - val_mean_absolute_error: 0.1895\n",
      "Epoch 121/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.7784e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 00121: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.7784e-04 - mean_absolute_error: 0.0174 - val_loss: 0.0245 - val_mean_absolute_error: 0.2120\n",
      "Epoch 122/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.9915e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 00122: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.9915e-04 - mean_absolute_error: 0.0174 - val_loss: 0.0128 - val_mean_absolute_error: 0.1515\n",
      "Epoch 123/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.0803e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 00123: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 3.0803e-04 - mean_absolute_error: 0.0178 - val_loss: 0.0234 - val_mean_absolute_error: 0.2067\n",
      "Epoch 124/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.7877e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 00124: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.7839e-04 - mean_absolute_error: 0.0171 - val_loss: 0.0203 - val_mean_absolute_error: 0.1881\n",
      "Epoch 125/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.8104e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 00125: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.8104e-04 - mean_absolute_error: 0.0171 - val_loss: 0.0252 - val_mean_absolute_error: 0.2176\n",
      "Epoch 126/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.8260e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 00126: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.8735e-04 - mean_absolute_error: 0.0174 - val_loss: 0.0240 - val_mean_absolute_error: 0.2119\n",
      "Epoch 127/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.7931e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 00127: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.7896e-04 - mean_absolute_error: 0.0171 - val_loss: 0.0198 - val_mean_absolute_error: 0.1883\n",
      "Epoch 128/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.9398e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 00128: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.9273e-04 - mean_absolute_error: 0.0172 - val_loss: 0.0173 - val_mean_absolute_error: 0.1745\n",
      "Epoch 129/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.7655e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 00129: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.7743e-04 - mean_absolute_error: 0.0172 - val_loss: 0.0198 - val_mean_absolute_error: 0.1843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.7125e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 00130: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.7143e-04 - mean_absolute_error: 0.0170 - val_loss: 0.0158 - val_mean_absolute_error: 0.1685\n",
      "Epoch 131/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.6917e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 00131: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.6917e-04 - mean_absolute_error: 0.0171 - val_loss: 0.0244 - val_mean_absolute_error: 0.2123\n",
      "Epoch 132/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.7339e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 00132: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.7341e-04 - mean_absolute_error: 0.0170 - val_loss: 0.0140 - val_mean_absolute_error: 0.1521\n",
      "Epoch 133/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.8921e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 00133: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.8899e-04 - mean_absolute_error: 0.0174 - val_loss: 0.0215 - val_mean_absolute_error: 0.1966\n",
      "Epoch 134/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.7207e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 00134: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.7207e-04 - mean_absolute_error: 0.0171 - val_loss: 0.0173 - val_mean_absolute_error: 0.1710\n",
      "Epoch 135/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.6186e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 00135: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.6159e-04 - mean_absolute_error: 0.0168 - val_loss: 0.0179 - val_mean_absolute_error: 0.1766\n",
      "Epoch 136/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.7177e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 00136: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.7177e-04 - mean_absolute_error: 0.0170 - val_loss: 0.0224 - val_mean_absolute_error: 0.1993\n",
      "Epoch 137/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.8626e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 00137: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.8546e-04 - mean_absolute_error: 0.0175 - val_loss: 0.0156 - val_mean_absolute_error: 0.1681\n",
      "Epoch 138/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.6733e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 00138: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 2.6652e-04 - mean_absolute_error: 0.0166 - val_loss: 0.0188 - val_mean_absolute_error: 0.1824\n",
      "Epoch 139/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.6011e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 00139: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.6008e-04 - mean_absolute_error: 0.0169 - val_loss: 0.0113 - val_mean_absolute_error: 0.1386\n",
      "Epoch 140/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.8132e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 00140: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.7939e-04 - mean_absolute_error: 0.0170 - val_loss: 0.0152 - val_mean_absolute_error: 0.1641\n",
      "Epoch 141/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.5203e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 00141: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.5169e-04 - mean_absolute_error: 0.0167 - val_loss: 0.0125 - val_mean_absolute_error: 0.1478\n",
      "Epoch 142/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.6609e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 00142: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.6533e-04 - mean_absolute_error: 0.0167 - val_loss: 0.0137 - val_mean_absolute_error: 0.1554\n",
      "Epoch 143/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.5703e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 00143: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.5682e-04 - mean_absolute_error: 0.0167 - val_loss: 0.0188 - val_mean_absolute_error: 0.1852\n",
      "Epoch 144/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.6970e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 00144: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.6942e-04 - mean_absolute_error: 0.0169 - val_loss: 0.0292 - val_mean_absolute_error: 0.2332\n",
      "Epoch 145/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.6239e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 00145: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.6118e-04 - mean_absolute_error: 0.0168 - val_loss: 0.0158 - val_mean_absolute_error: 0.1681\n",
      "Epoch 146/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.6195e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 00146: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.6195e-04 - mean_absolute_error: 0.0168 - val_loss: 0.0148 - val_mean_absolute_error: 0.1572\n",
      "Epoch 147/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.4838e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 00147: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.4933e-04 - mean_absolute_error: 0.0164 - val_loss: 0.0124 - val_mean_absolute_error: 0.1468\n",
      "Epoch 148/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.5362e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 00148: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.5362e-04 - mean_absolute_error: 0.0167 - val_loss: 0.0135 - val_mean_absolute_error: 0.1548\n",
      "Epoch 149/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.5504e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 00149: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.5493e-04 - mean_absolute_error: 0.0166 - val_loss: 0.0106 - val_mean_absolute_error: 0.1337\n",
      "Epoch 150/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.5933e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 00150: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.5988e-04 - mean_absolute_error: 0.0167 - val_loss: 0.0163 - val_mean_absolute_error: 0.1703\n",
      "Epoch 151/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.6359e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 00151: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.6359e-04 - mean_absolute_error: 0.0168 - val_loss: 0.0237 - val_mean_absolute_error: 0.2077\n",
      "Epoch 152/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.4849e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 00152: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 2.4852e-04 - mean_absolute_error: 0.0164 - val_loss: 0.0155 - val_mean_absolute_error: 0.1656\n",
      "Epoch 153/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.5324e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 00153: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.5324e-04 - mean_absolute_error: 0.0167 - val_loss: 0.0164 - val_mean_absolute_error: 0.1709\n",
      "Epoch 154/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.6609e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 00154: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.6580e-04 - mean_absolute_error: 0.0166 - val_loss: 0.0171 - val_mean_absolute_error: 0.1759\n",
      "Epoch 155/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.5587e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 00155: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 2.5620e-04 - mean_absolute_error: 0.0165 - val_loss: 0.0061 - val_mean_absolute_error: 0.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.4488e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 00156: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.4457e-04 - mean_absolute_error: 0.0161 - val_loss: 0.0118 - val_mean_absolute_error: 0.1439\n",
      "Epoch 157/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.4268e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 00157: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.4268e-04 - mean_absolute_error: 0.0163 - val_loss: 0.0121 - val_mean_absolute_error: 0.1448\n",
      "Epoch 158/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.3479e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 00158: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.3821e-04 - mean_absolute_error: 0.0163 - val_loss: 0.0123 - val_mean_absolute_error: 0.1453\n",
      "Epoch 159/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.4140e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 00159: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.4154e-04 - mean_absolute_error: 0.0162 - val_loss: 0.0137 - val_mean_absolute_error: 0.1557\n",
      "Epoch 160/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.5092e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 00160: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.5088e-04 - mean_absolute_error: 0.0166 - val_loss: 0.0117 - val_mean_absolute_error: 0.1426\n",
      "Epoch 161/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.4290e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 00161: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.4285e-04 - mean_absolute_error: 0.0163 - val_loss: 0.0076 - val_mean_absolute_error: 0.1098\n",
      "Epoch 162/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.5076e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 00162: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.5076e-04 - mean_absolute_error: 0.0166 - val_loss: 0.0121 - val_mean_absolute_error: 0.1447\n",
      "Epoch 163/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.3665e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 00163: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.3639e-04 - mean_absolute_error: 0.0162 - val_loss: 0.0114 - val_mean_absolute_error: 0.1409\n",
      "Epoch 164/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.3733e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 00164: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.3710e-04 - mean_absolute_error: 0.0161 - val_loss: 0.0097 - val_mean_absolute_error: 0.1276\n",
      "Epoch 165/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.3364e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 00165: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.3364e-04 - mean_absolute_error: 0.0158 - val_loss: 0.0119 - val_mean_absolute_error: 0.1438\n",
      "Epoch 166/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.3547e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 00166: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.3431e-04 - mean_absolute_error: 0.0161 - val_loss: 0.0116 - val_mean_absolute_error: 0.1418\n",
      "Epoch 167/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.3934e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 00167: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.3942e-04 - mean_absolute_error: 0.0163 - val_loss: 0.0156 - val_mean_absolute_error: 0.1671\n",
      "Epoch 168/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.3921e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 00168: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.3936e-04 - mean_absolute_error: 0.0164 - val_loss: 0.0226 - val_mean_absolute_error: 0.2051\n",
      "Epoch 169/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.4029e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 00169: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.4019e-04 - mean_absolute_error: 0.0161 - val_loss: 0.0234 - val_mean_absolute_error: 0.2096\n",
      "Epoch 170/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.4024e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 00170: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.4024e-04 - mean_absolute_error: 0.0160 - val_loss: 0.0117 - val_mean_absolute_error: 0.1433\n",
      "Epoch 171/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.3609e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 00171: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.3557e-04 - mean_absolute_error: 0.0162 - val_loss: 0.0119 - val_mean_absolute_error: 0.1438\n",
      "Epoch 172/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.5189e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 00172: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.5179e-04 - mean_absolute_error: 0.0164 - val_loss: 0.0129 - val_mean_absolute_error: 0.1517\n",
      "Epoch 173/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.3155e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 00173: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.3155e-04 - mean_absolute_error: 0.0160 - val_loss: 0.0112 - val_mean_absolute_error: 0.1406\n",
      "Epoch 174/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.4031e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 00174: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.3933e-04 - mean_absolute_error: 0.0163 - val_loss: 0.0066 - val_mean_absolute_error: 0.1012\n",
      "Epoch 175/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.2326e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 00175: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.2322e-04 - mean_absolute_error: 0.0158 - val_loss: 0.0145 - val_mean_absolute_error: 0.1608\n",
      "Epoch 176/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.3534e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 00176: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.3456e-04 - mean_absolute_error: 0.0161 - val_loss: 0.0133 - val_mean_absolute_error: 0.1529\n",
      "Epoch 177/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.3397e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 00177: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.3397e-04 - mean_absolute_error: 0.0162 - val_loss: 0.0146 - val_mean_absolute_error: 0.1619\n",
      "Epoch 178/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.2612e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 00178: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.2612e-04 - mean_absolute_error: 0.0157 - val_loss: 0.0088 - val_mean_absolute_error: 0.1212\n",
      "Epoch 179/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.1811e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 00179: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.1741e-04 - mean_absolute_error: 0.0155 - val_loss: 0.0094 - val_mean_absolute_error: 0.1259\n",
      "Epoch 180/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.4053e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 00180: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.4053e-04 - mean_absolute_error: 0.0163 - val_loss: 0.0191 - val_mean_absolute_error: 0.1889\n",
      "Epoch 181/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.2555e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 00181: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 2.2489e-04 - mean_absolute_error: 0.0157 - val_loss: 0.0127 - val_mean_absolute_error: 0.1504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/1500\n",
      "75/79 [===========================>..] - ETA: 0s - loss: 2.3056e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 00182: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 2.3603e-04 - mean_absolute_error: 0.0160 - val_loss: 0.0088 - val_mean_absolute_error: 0.1187\n",
      "Epoch 183/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.1933e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 00183: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 2.1933e-04 - mean_absolute_error: 0.0156 - val_loss: 0.0181 - val_mean_absolute_error: 0.1808\n",
      "Epoch 184/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.2387e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 00184: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 2.2387e-04 - mean_absolute_error: 0.0159 - val_loss: 0.0197 - val_mean_absolute_error: 0.1883\n",
      "Epoch 185/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.2622e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 00185: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.2607e-04 - mean_absolute_error: 0.0158 - val_loss: 0.0122 - val_mean_absolute_error: 0.1454\n",
      "Epoch 186/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.2831e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 00186: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.2809e-04 - mean_absolute_error: 0.0158 - val_loss: 0.0113 - val_mean_absolute_error: 0.1407\n",
      "Epoch 187/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.2549e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 00187: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.2482e-04 - mean_absolute_error: 0.0157 - val_loss: 0.0132 - val_mean_absolute_error: 0.1513\n",
      "Epoch 188/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.2422e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 00188: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 2.2422e-04 - mean_absolute_error: 0.0158 - val_loss: 0.0140 - val_mean_absolute_error: 0.1586\n",
      "Epoch 189/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.1942e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 00189: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 2.1919e-04 - mean_absolute_error: 0.0156 - val_loss: 0.0088 - val_mean_absolute_error: 0.1217\n",
      "Epoch 190/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.1034e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 00190: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1020e-04 - mean_absolute_error: 0.0154 - val_loss: 0.0083 - val_mean_absolute_error: 0.1178\n",
      "Epoch 191/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.3370e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 00191: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.3353e-04 - mean_absolute_error: 0.0158 - val_loss: 0.0113 - val_mean_absolute_error: 0.1362\n",
      "Epoch 192/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.1690e-04 - mean_absolute_error: 0.0155\n",
      "Epoch 00192: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1690e-04 - mean_absolute_error: 0.0155 - val_loss: 0.0067 - val_mean_absolute_error: 0.1032\n",
      "Epoch 193/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.1071e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 00193: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1071e-04 - mean_absolute_error: 0.0154 - val_loss: 0.0101 - val_mean_absolute_error: 0.1312\n",
      "Epoch 194/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.1186e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 00194: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1186e-04 - mean_absolute_error: 0.0154 - val_loss: 0.0136 - val_mean_absolute_error: 0.1554\n",
      "Epoch 195/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.2283e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 00195: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.2467e-04 - mean_absolute_error: 0.0157 - val_loss: 0.0161 - val_mean_absolute_error: 0.1714\n",
      "Epoch 196/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.1754e-04 - mean_absolute_error: 0.0155\n",
      "Epoch 00196: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.1703e-04 - mean_absolute_error: 0.0155 - val_loss: 0.0069 - val_mean_absolute_error: 0.1047\n",
      "Epoch 197/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.1148e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 00197: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.1058e-04 - mean_absolute_error: 0.0155 - val_loss: 0.0185 - val_mean_absolute_error: 0.1840\n",
      "Epoch 198/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.1764e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 00198: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.1739e-04 - mean_absolute_error: 0.0156 - val_loss: 0.0143 - val_mean_absolute_error: 0.1599\n",
      "Epoch 199/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.1474e-04 - mean_absolute_error: 0.0155\n",
      "Epoch 00199: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1463e-04 - mean_absolute_error: 0.0155 - val_loss: 0.0211 - val_mean_absolute_error: 0.1979\n",
      "Epoch 200/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.1268e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 00200: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1268e-04 - mean_absolute_error: 0.0154 - val_loss: 0.0095 - val_mean_absolute_error: 0.1244\n",
      "Epoch 201/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.1939e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 00201: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.1817e-04 - mean_absolute_error: 0.0156 - val_loss: 0.0094 - val_mean_absolute_error: 0.1264\n",
      "Epoch 202/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.0593e-04 - mean_absolute_error: 0.0153\n",
      "Epoch 00202: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.0593e-04 - mean_absolute_error: 0.0153 - val_loss: 0.0075 - val_mean_absolute_error: 0.1106\n",
      "Epoch 203/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.1480e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 00203: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1480e-04 - mean_absolute_error: 0.0154 - val_loss: 0.0105 - val_mean_absolute_error: 0.1362\n",
      "Epoch 204/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.0657e-04 - mean_absolute_error: 0.0150\n",
      "Epoch 00204: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.0657e-04 - mean_absolute_error: 0.0150 - val_loss: 0.0079 - val_mean_absolute_error: 0.1140\n",
      "Epoch 205/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.1026e-04 - mean_absolute_error: 0.0152\n",
      "Epoch 00205: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.0969e-04 - mean_absolute_error: 0.0152 - val_loss: 0.0123 - val_mean_absolute_error: 0.1478\n",
      "Epoch 206/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.0448e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 00206: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.0489e-04 - mean_absolute_error: 0.0151 - val_loss: 0.0078 - val_mean_absolute_error: 0.1142\n",
      "Epoch 207/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.0476e-04 - mean_absolute_error: 0.0152\n",
      "Epoch 00207: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.0451e-04 - mean_absolute_error: 0.0152 - val_loss: 0.0117 - val_mean_absolute_error: 0.1428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.0510e-04 - mean_absolute_error: 0.0152\n",
      "Epoch 00208: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.0510e-04 - mean_absolute_error: 0.0152 - val_loss: 0.0139 - val_mean_absolute_error: 0.1590\n",
      "Epoch 209/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9782e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 00209: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9782e-04 - mean_absolute_error: 0.0151 - val_loss: 0.0079 - val_mean_absolute_error: 0.1136\n",
      "Epoch 210/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9741e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 00210: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9741e-04 - mean_absolute_error: 0.0151 - val_loss: 0.0137 - val_mean_absolute_error: 0.1581\n",
      "Epoch 211/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.1001e-04 - mean_absolute_error: 0.0152\n",
      "Epoch 00211: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1001e-04 - mean_absolute_error: 0.0152 - val_loss: 0.0165 - val_mean_absolute_error: 0.1735\n",
      "Epoch 212/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.3383e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 00212: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.3501e-04 - mean_absolute_error: 0.0157 - val_loss: 0.0076 - val_mean_absolute_error: 0.1116\n",
      "Epoch 213/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.1441e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 00213: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1441e-04 - mean_absolute_error: 0.0154 - val_loss: 0.0112 - val_mean_absolute_error: 0.1405\n",
      "Epoch 214/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.2284e-04 - mean_absolute_error: 0.0155\n",
      "Epoch 00214: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.2116e-04 - mean_absolute_error: 0.0154 - val_loss: 0.0079 - val_mean_absolute_error: 0.1152\n",
      "Epoch 215/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.1231e-04 - mean_absolute_error: 0.0153\n",
      "Epoch 00215: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.1237e-04 - mean_absolute_error: 0.0153 - val_loss: 0.0158 - val_mean_absolute_error: 0.1651\n",
      "Epoch 216/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.0126e-04 - mean_absolute_error: 0.0153\n",
      "Epoch 00216: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.0126e-04 - mean_absolute_error: 0.0153 - val_loss: 0.0115 - val_mean_absolute_error: 0.1401\n",
      "Epoch 217/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9844e-04 - mean_absolute_error: 0.0149\n",
      "Epoch 00217: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.9844e-04 - mean_absolute_error: 0.0149 - val_loss: 0.0115 - val_mean_absolute_error: 0.1422\n",
      "Epoch 218/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.1344e-04 - mean_absolute_error: 0.0153\n",
      "Epoch 00218: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.1337e-04 - mean_absolute_error: 0.0153 - val_loss: 0.0134 - val_mean_absolute_error: 0.1535\n",
      "Epoch 219/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9508e-04 - mean_absolute_error: 0.0150\n",
      "Epoch 00219: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.9508e-04 - mean_absolute_error: 0.0150 - val_loss: 0.0050 - val_mean_absolute_error: 0.0867\n",
      "Epoch 220/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.1464e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 00220: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1448e-04 - mean_absolute_error: 0.0154 - val_loss: 0.0145 - val_mean_absolute_error: 0.1604\n",
      "Epoch 221/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.0423e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00221: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.0423e-04 - mean_absolute_error: 0.0147 - val_loss: 0.0111 - val_mean_absolute_error: 0.1392\n",
      "Epoch 222/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.1304e-04 - mean_absolute_error: 0.0153\n",
      "Epoch 00222: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.1304e-04 - mean_absolute_error: 0.0153 - val_loss: 0.0054 - val_mean_absolute_error: 0.0907\n",
      "Epoch 223/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.9146e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00223: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9245e-04 - mean_absolute_error: 0.0148 - val_loss: 0.0082 - val_mean_absolute_error: 0.1167\n",
      "Epoch 224/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9869e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 00224: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9869e-04 - mean_absolute_error: 0.0151 - val_loss: 0.0084 - val_mean_absolute_error: 0.1171\n",
      "Epoch 225/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.9472e-04 - mean_absolute_error: 0.0148\n",
      "Epoch 00225: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9465e-04 - mean_absolute_error: 0.0148 - val_loss: 0.0133 - val_mean_absolute_error: 0.1542\n",
      "Epoch 226/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.9802e-04 - mean_absolute_error: 0.0149\n",
      "Epoch 00226: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.9808e-04 - mean_absolute_error: 0.0149 - val_loss: 0.0157 - val_mean_absolute_error: 0.1656\n",
      "Epoch 227/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9051e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00227: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9051e-04 - mean_absolute_error: 0.0147 - val_loss: 0.0152 - val_mean_absolute_error: 0.1662\n",
      "Epoch 228/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.1152e-04 - mean_absolute_error: 0.0153\n",
      "Epoch 00228: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 2.1109e-04 - mean_absolute_error: 0.0153 - val_loss: 0.0110 - val_mean_absolute_error: 0.1370\n",
      "Epoch 229/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.0185e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 00229: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 2.0185e-04 - mean_absolute_error: 0.0151 - val_loss: 0.0165 - val_mean_absolute_error: 0.1733\n",
      "Epoch 230/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.0473e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 00230: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.0491e-04 - mean_absolute_error: 0.0151 - val_loss: 0.0164 - val_mean_absolute_error: 0.1734\n",
      "Epoch 231/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.0966e-04 - mean_absolute_error: 0.0152\n",
      "Epoch 00231: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 2.0966e-04 - mean_absolute_error: 0.0152 - val_loss: 0.0048 - val_mean_absolute_error: 0.0835\n",
      "Epoch 232/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.9264e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00232: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.9364e-04 - mean_absolute_error: 0.0148 - val_loss: 0.0097 - val_mean_absolute_error: 0.1257\n",
      "Epoch 233/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.9160e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00233: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.9250e-04 - mean_absolute_error: 0.0148 - val_loss: 0.0039 - val_mean_absolute_error: 0.0752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.2554e-04 - mean_absolute_error: 0.0153\n",
      "Epoch 00234: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.2567e-04 - mean_absolute_error: 0.0153 - val_loss: 0.0093 - val_mean_absolute_error: 0.1247\n",
      "Epoch 235/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9831e-04 - mean_absolute_error: 0.0149\n",
      "Epoch 00235: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.9831e-04 - mean_absolute_error: 0.0149 - val_loss: 0.0184 - val_mean_absolute_error: 0.1854\n",
      "Epoch 236/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.9283e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00236: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9368e-04 - mean_absolute_error: 0.0147 - val_loss: 0.0108 - val_mean_absolute_error: 0.1379\n",
      "Epoch 237/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.1071e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 00237: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1016e-04 - mean_absolute_error: 0.0151 - val_loss: 0.0058 - val_mean_absolute_error: 0.0924\n",
      "Epoch 238/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.9674e-04 - mean_absolute_error: 0.0149\n",
      "Epoch 00238: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.9667e-04 - mean_absolute_error: 0.0149 - val_loss: 0.0158 - val_mean_absolute_error: 0.1694\n",
      "Epoch 239/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.1257e-04 - mean_absolute_error: 0.0153\n",
      "Epoch 00239: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1181e-04 - mean_absolute_error: 0.0152 - val_loss: 0.0114 - val_mean_absolute_error: 0.1399\n",
      "Epoch 240/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9888e-04 - mean_absolute_error: 0.0150\n",
      "Epoch 00240: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9888e-04 - mean_absolute_error: 0.0150 - val_loss: 0.0098 - val_mean_absolute_error: 0.1291\n",
      "Epoch 241/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.0369e-04 - mean_absolute_error: 0.0150\n",
      "Epoch 00241: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.0544e-04 - mean_absolute_error: 0.0150 - val_loss: 0.0140 - val_mean_absolute_error: 0.1572\n",
      "Epoch 242/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 2.2056e-04 - mean_absolute_error: 0.0152\n",
      "Epoch 00242: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.2224e-04 - mean_absolute_error: 0.0153 - val_loss: 0.0127 - val_mean_absolute_error: 0.1485\n",
      "Epoch 243/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.0521e-04 - mean_absolute_error: 0.0148\n",
      "Epoch 00243: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.0493e-04 - mean_absolute_error: 0.0148 - val_loss: 0.0101 - val_mean_absolute_error: 0.1314\n",
      "Epoch 244/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.8753e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 00244: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.8753e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0120 - val_mean_absolute_error: 0.1434\n",
      "Epoch 245/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.9887e-04 - mean_absolute_error: 0.0150\n",
      "Epoch 00245: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9921e-04 - mean_absolute_error: 0.0150 - val_loss: 0.0171 - val_mean_absolute_error: 0.1727\n",
      "Epoch 246/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.1906e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 00246: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.1903e-04 - mean_absolute_error: 0.0151 - val_loss: 0.0044 - val_mean_absolute_error: 0.0807\n",
      "Epoch 247/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.9656e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00247: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9636e-04 - mean_absolute_error: 0.0147 - val_loss: 0.0128 - val_mean_absolute_error: 0.1504\n",
      "Epoch 248/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.9455e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00248: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.9507e-04 - mean_absolute_error: 0.0147 - val_loss: 0.0113 - val_mean_absolute_error: 0.1407\n",
      "Epoch 249/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.8563e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 00249: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8563e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0145 - val_mean_absolute_error: 0.1612\n",
      "Epoch 250/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9804e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00250: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.9804e-04 - mean_absolute_error: 0.0147 - val_loss: 0.0128 - val_mean_absolute_error: 0.1488\n",
      "Epoch 251/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.9062e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00251: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.9042e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0073 - val_mean_absolute_error: 0.1072\n",
      "Epoch 252/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.8909e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 00252: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.8909e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0091 - val_mean_absolute_error: 0.1223\n",
      "Epoch 253/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.8800e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00253: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.8781e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0078 - val_mean_absolute_error: 0.1117\n",
      "Epoch 254/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.9382e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 00254: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.9385e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0091 - val_mean_absolute_error: 0.1223\n",
      "Epoch 255/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.9461e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 00255: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9393e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0064 - val_mean_absolute_error: 0.0996\n",
      "Epoch 256/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.9217e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00256: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9192e-04 - mean_absolute_error: 0.0147 - val_loss: 0.0088 - val_mean_absolute_error: 0.1204\n",
      "Epoch 257/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.9264e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00257: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.9267e-04 - mean_absolute_error: 0.0147 - val_loss: 0.0113 - val_mean_absolute_error: 0.1386\n",
      "Epoch 258/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8571e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 00258: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8649e-04 - mean_absolute_error: 0.0145 - val_loss: 0.0164 - val_mean_absolute_error: 0.1723\n",
      "Epoch 259/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.9216e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00259: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.9209e-04 - mean_absolute_error: 0.0147 - val_loss: 0.0075 - val_mean_absolute_error: 0.1077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.7911e-04 - mean_absolute_error: 0.0144\n",
      "Epoch 00260: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.8024e-04 - mean_absolute_error: 0.0144 - val_loss: 0.0138 - val_mean_absolute_error: 0.1551\n",
      "Epoch 261/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9949e-04 - mean_absolute_error: 0.0149\n",
      "Epoch 00261: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.9949e-04 - mean_absolute_error: 0.0149 - val_loss: 0.0128 - val_mean_absolute_error: 0.1485\n",
      "Epoch 262/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8731e-04 - mean_absolute_error: 0.0144\n",
      "Epoch 00262: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.8704e-04 - mean_absolute_error: 0.0144 - val_loss: 0.0142 - val_mean_absolute_error: 0.1555\n",
      "Epoch 263/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7829e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00263: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7829e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0105 - val_mean_absolute_error: 0.1320\n",
      "Epoch 264/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.8323e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 00264: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8323e-04 - mean_absolute_error: 0.0145 - val_loss: 0.0128 - val_mean_absolute_error: 0.1481\n",
      "Epoch 265/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.8888e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 00265: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.8877e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0104 - val_mean_absolute_error: 0.1329\n",
      "Epoch 266/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8668e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 00266: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8724e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0152 - val_mean_absolute_error: 0.1657\n",
      "Epoch 267/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8616e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00267: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.8633e-04 - mean_absolute_error: 0.0144 - val_loss: 0.0095 - val_mean_absolute_error: 0.1280\n",
      "Epoch 268/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9916e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 00268: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.9916e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0088 - val_mean_absolute_error: 0.1213\n",
      "Epoch 269/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8885e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 00269: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8895e-04 - mean_absolute_error: 0.0145 - val_loss: 0.0107 - val_mean_absolute_error: 0.1329\n",
      "Epoch 270/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.6590e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 00270: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 2.6585e-04 - mean_absolute_error: 0.0160 - val_loss: 0.0059 - val_mean_absolute_error: 0.0943\n",
      "Epoch 271/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.9170e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00271: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9197e-04 - mean_absolute_error: 0.0147 - val_loss: 0.0054 - val_mean_absolute_error: 0.0896\n",
      "Epoch 272/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.8387e-04 - mean_absolute_error: 0.0144\n",
      "Epoch 00272: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.8380e-04 - mean_absolute_error: 0.0144 - val_loss: 0.0093 - val_mean_absolute_error: 0.1254\n",
      "Epoch 273/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8313e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00273: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8353e-04 - mean_absolute_error: 0.0144 - val_loss: 0.0052 - val_mean_absolute_error: 0.0869\n",
      "Epoch 274/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.9035e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00274: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.9039e-04 - mean_absolute_error: 0.0144 - val_loss: 0.0079 - val_mean_absolute_error: 0.1132\n",
      "Epoch 275/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.8617e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 00275: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8609e-04 - mean_absolute_error: 0.0145 - val_loss: 0.0108 - val_mean_absolute_error: 0.1365\n",
      "Epoch 276/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.8402e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 00276: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.8402e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0085 - val_mean_absolute_error: 0.1179\n",
      "Epoch 277/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7315e-04 - mean_absolute_error: 0.0142\n",
      "Epoch 00277: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7315e-04 - mean_absolute_error: 0.0142 - val_loss: 0.0055 - val_mean_absolute_error: 0.0887\n",
      "Epoch 278/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8507e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 00278: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8620e-04 - mean_absolute_error: 0.0145 - val_loss: 0.0097 - val_mean_absolute_error: 0.1260\n",
      "Epoch 279/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8216e-04 - mean_absolute_error: 0.0142\n",
      "Epoch 00279: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8140e-04 - mean_absolute_error: 0.0142 - val_loss: 0.0114 - val_mean_absolute_error: 0.1399\n",
      "Epoch 280/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7767e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00280: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 1.7767e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0072 - val_mean_absolute_error: 0.1068\n",
      "Epoch 281/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.8114e-04 - mean_absolute_error: 0.0142\n",
      "Epoch 00281: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.8114e-04 - mean_absolute_error: 0.0142 - val_loss: 0.0061 - val_mean_absolute_error: 0.0940\n",
      "Epoch 282/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.8225e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00282: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8207e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0050 - val_mean_absolute_error: 0.0843\n",
      "Epoch 283/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8521e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00283: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.8623e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0098 - val_mean_absolute_error: 0.1284\n",
      "Epoch 284/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7886e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00284: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.7886e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0064 - val_mean_absolute_error: 0.0994\n",
      "Epoch 285/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.8182e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 00285: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8182e-04 - mean_absolute_error: 0.0145 - val_loss: 0.0048 - val_mean_absolute_error: 0.0821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7739e-04 - mean_absolute_error: 0.0142\n",
      "Epoch 00286: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7739e-04 - mean_absolute_error: 0.0142 - val_loss: 0.0085 - val_mean_absolute_error: 0.1178\n",
      "Epoch 287/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7225e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 00287: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7225e-04 - mean_absolute_error: 0.0140 - val_loss: 0.0081 - val_mean_absolute_error: 0.1154\n",
      "Epoch 288/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7820e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 00288: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7820e-04 - mean_absolute_error: 0.0145 - val_loss: 0.0092 - val_mean_absolute_error: 0.1223\n",
      "Epoch 289/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8207e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 00289: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8177e-04 - mean_absolute_error: 0.0145 - val_loss: 0.0127 - val_mean_absolute_error: 0.1488\n",
      "Epoch 290/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7993e-04 - mean_absolute_error: 0.0142\n",
      "Epoch 00290: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.7993e-04 - mean_absolute_error: 0.0142 - val_loss: 0.0081 - val_mean_absolute_error: 0.1139\n",
      "Epoch 291/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7056e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 00291: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.7056e-04 - mean_absolute_error: 0.0139 - val_loss: 0.0098 - val_mean_absolute_error: 0.1284\n",
      "Epoch 292/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.7399e-04 - mean_absolute_error: 0.0141\n",
      "Epoch 00292: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.7351e-04 - mean_absolute_error: 0.0141 - val_loss: 0.0095 - val_mean_absolute_error: 0.1265\n",
      "Epoch 293/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.7232e-04 - mean_absolute_error: 0.0141\n",
      "Epoch 00293: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7164e-04 - mean_absolute_error: 0.0140 - val_loss: 0.0110 - val_mean_absolute_error: 0.1371\n",
      "Epoch 294/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8188e-04 - mean_absolute_error: 0.0144\n",
      "Epoch 00294: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8257e-04 - mean_absolute_error: 0.0144 - val_loss: 0.0099 - val_mean_absolute_error: 0.1281\n",
      "Epoch 295/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.6740e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 00295: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6689e-04 - mean_absolute_error: 0.0139 - val_loss: 0.0098 - val_mean_absolute_error: 0.1281\n",
      "Epoch 296/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.8162e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00296: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8162e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0097 - val_mean_absolute_error: 0.1268\n",
      "Epoch 297/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.7579e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00297: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.7564e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0105 - val_mean_absolute_error: 0.1326\n",
      "Epoch 298/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.8100e-04 - mean_absolute_error: 0.0141\n",
      "Epoch 00298: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.8097e-04 - mean_absolute_error: 0.0141 - val_loss: 0.0163 - val_mean_absolute_error: 0.1695\n",
      "Epoch 299/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.8278e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00299: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8278e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0133 - val_mean_absolute_error: 0.1512\n",
      "Epoch 300/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.7134e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 00300: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7128e-04 - mean_absolute_error: 0.0140 - val_loss: 0.0096 - val_mean_absolute_error: 0.1265\n",
      "Epoch 301/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.7394e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 00301: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7426e-04 - mean_absolute_error: 0.0139 - val_loss: 0.0080 - val_mean_absolute_error: 0.1140\n",
      "Epoch 302/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6935e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 00302: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6935e-04 - mean_absolute_error: 0.0140 - val_loss: 0.0101 - val_mean_absolute_error: 0.1291\n",
      "Epoch 303/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.8281e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00303: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8268e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0069 - val_mean_absolute_error: 0.1044\n",
      "Epoch 304/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 2.1737e-04 - mean_absolute_error: 0.0150\n",
      "Epoch 00304: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.1702e-04 - mean_absolute_error: 0.0150 - val_loss: 0.0084 - val_mean_absolute_error: 0.1186\n",
      "Epoch 305/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.7102e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 00305: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.7088e-04 - mean_absolute_error: 0.0140 - val_loss: 0.0123 - val_mean_absolute_error: 0.1467\n",
      "Epoch 306/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9336e-04 - mean_absolute_error: 0.0141\n",
      "Epoch 00306: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9336e-04 - mean_absolute_error: 0.0141 - val_loss: 0.0112 - val_mean_absolute_error: 0.1395\n",
      "Epoch 307/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7102e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 00307: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7102e-04 - mean_absolute_error: 0.0140 - val_loss: 0.0086 - val_mean_absolute_error: 0.1186\n",
      "Epoch 308/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.8682e-04 - mean_absolute_error: 0.0142\n",
      "Epoch 00308: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.8688e-04 - mean_absolute_error: 0.0142 - val_loss: 0.0103 - val_mean_absolute_error: 0.1317\n",
      "Epoch 309/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7250e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 00309: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7250e-04 - mean_absolute_error: 0.0140 - val_loss: 0.0077 - val_mean_absolute_error: 0.1091\n",
      "Epoch 310/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7006e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 00310: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7006e-04 - mean_absolute_error: 0.0139 - val_loss: 0.0163 - val_mean_absolute_error: 0.1647\n",
      "Epoch 311/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6566e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 00311: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.6566e-04 - mean_absolute_error: 0.0137 - val_loss: 0.0107 - val_mean_absolute_error: 0.1344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.6786e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 00312: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6769e-04 - mean_absolute_error: 0.0139 - val_loss: 0.0141 - val_mean_absolute_error: 0.1554\n",
      "Epoch 313/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.6561e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 00313: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6527e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0072 - val_mean_absolute_error: 0.1056\n",
      "Epoch 314/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.7441e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 00314: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.7477e-04 - mean_absolute_error: 0.0141 - val_loss: 0.0082 - val_mean_absolute_error: 0.1141\n",
      "Epoch 315/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 1.6380e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 00315: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6302e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0102 - val_mean_absolute_error: 0.1310\n",
      "Epoch 316/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8095e-04 - mean_absolute_error: 0.0141\n",
      "Epoch 00316: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.8050e-04 - mean_absolute_error: 0.0141 - val_loss: 0.0077 - val_mean_absolute_error: 0.1112\n",
      "Epoch 317/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6279e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 00317: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6279e-04 - mean_absolute_error: 0.0137 - val_loss: 0.0097 - val_mean_absolute_error: 0.1253\n",
      "Epoch 318/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8714e-04 - mean_absolute_error: 0.0142\n",
      "Epoch 00318: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.8685e-04 - mean_absolute_error: 0.0142 - val_loss: 0.0093 - val_mean_absolute_error: 0.1239\n",
      "Epoch 319/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.6394e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 00319: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6414e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0153 - val_mean_absolute_error: 0.1653\n",
      "Epoch 320/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.6937e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 00320: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6917e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0084 - val_mean_absolute_error: 0.1149\n",
      "Epoch 321/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6958e-04 - mean_absolute_error: 0.0141\n",
      "Epoch 00321: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6958e-04 - mean_absolute_error: 0.0141 - val_loss: 0.0097 - val_mean_absolute_error: 0.1266\n",
      "Epoch 322/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.7291e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 00322: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.7286e-04 - mean_absolute_error: 0.0140 - val_loss: 0.0113 - val_mean_absolute_error: 0.1380\n",
      "Epoch 323/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.6909e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 00323: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6967e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0097 - val_mean_absolute_error: 0.1260\n",
      "Epoch 324/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6084e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00324: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6084e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0087 - val_mean_absolute_error: 0.1177\n",
      "Epoch 325/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.6441e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 00325: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6370e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0093 - val_mean_absolute_error: 0.1242\n",
      "Epoch 326/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.6837e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 00326: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6780e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0069 - val_mean_absolute_error: 0.1030\n",
      "Epoch 327/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7568e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 00327: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7568e-04 - mean_absolute_error: 0.0140 - val_loss: 0.0073 - val_mean_absolute_error: 0.1043\n",
      "Epoch 328/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7571e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 00328: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7571e-04 - mean_absolute_error: 0.0140 - val_loss: 0.0120 - val_mean_absolute_error: 0.1410\n",
      "Epoch 329/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7175e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 00329: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.7175e-04 - mean_absolute_error: 0.0137 - val_loss: 0.0083 - val_mean_absolute_error: 0.1152\n",
      "Epoch 330/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.7116e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 00330: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7125e-04 - mean_absolute_error: 0.0139 - val_loss: 0.0164 - val_mean_absolute_error: 0.1708\n",
      "Epoch 331/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.6646e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 00331: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6653e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0154 - val_mean_absolute_error: 0.1654\n",
      "Epoch 332/1500\n",
      "75/79 [===========================>..] - ETA: 0s - loss: 1.6501e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 00332: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6495e-04 - mean_absolute_error: 0.0137 - val_loss: 0.0106 - val_mean_absolute_error: 0.1338\n",
      "Epoch 333/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6163e-04 - mean_absolute_error: 0.0135\n",
      "Epoch 00333: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6163e-04 - mean_absolute_error: 0.0135 - val_loss: 0.0154 - val_mean_absolute_error: 0.1645\n",
      "Epoch 334/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.6190e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00334: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6181e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0105 - val_mean_absolute_error: 0.1324\n",
      "Epoch 335/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6243e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 00335: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6243e-04 - mean_absolute_error: 0.0137 - val_loss: 0.0109 - val_mean_absolute_error: 0.1349\n",
      "Epoch 336/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6145e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00336: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6145e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0100 - val_mean_absolute_error: 0.1258\n",
      "Epoch 337/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.7671e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 00337: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7671e-04 - mean_absolute_error: 0.0139 - val_loss: 0.0092 - val_mean_absolute_error: 0.1183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.7385e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 00338: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7383e-04 - mean_absolute_error: 0.0139 - val_loss: 0.0051 - val_mean_absolute_error: 0.0840\n",
      "Epoch 339/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.6161e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00339: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6143e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0075 - val_mean_absolute_error: 0.1084\n",
      "Epoch 340/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6381e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 00340: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6381e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0072 - val_mean_absolute_error: 0.1020\n",
      "Epoch 341/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.6606e-04 - mean_absolute_error: 0.0135\n",
      "Epoch 00341: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6606e-04 - mean_absolute_error: 0.0135 - val_loss: 0.0068 - val_mean_absolute_error: 0.1017\n",
      "Epoch 342/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6190e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00342: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6190e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0077 - val_mean_absolute_error: 0.1090\n",
      "Epoch 343/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.6826e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 00343: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6845e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0122 - val_mean_absolute_error: 0.1433\n",
      "Epoch 344/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.6861e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 00344: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 1.6845e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0068 - val_mean_absolute_error: 0.1011\n",
      "Epoch 345/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.8791e-04 - mean_absolute_error: 0.0141\n",
      "Epoch 00345: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.8777e-04 - mean_absolute_error: 0.0141 - val_loss: 0.0056 - val_mean_absolute_error: 0.0897\n",
      "Epoch 346/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.5761e-04 - mean_absolute_error: 0.0134\n",
      "Epoch 00346: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5797e-04 - mean_absolute_error: 0.0134 - val_loss: 0.0162 - val_mean_absolute_error: 0.1704\n",
      "Epoch 347/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.7055e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 00347: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.7058e-04 - mean_absolute_error: 0.0137 - val_loss: 0.0112 - val_mean_absolute_error: 0.1380\n",
      "Epoch 348/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.5768e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00348: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.5747e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0137 - val_mean_absolute_error: 0.1560\n",
      "Epoch 349/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.6366e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00349: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.6272e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0078 - val_mean_absolute_error: 0.1103\n",
      "Epoch 350/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.7519e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 00350: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.7546e-04 - mean_absolute_error: 0.0137 - val_loss: 0.0158 - val_mean_absolute_error: 0.1629\n",
      "Epoch 351/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.8104e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 00351: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.8104e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0110 - val_mean_absolute_error: 0.1357\n",
      "Epoch 352/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.5562e-04 - mean_absolute_error: 0.0134\n",
      "Epoch 00352: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.5593e-04 - mean_absolute_error: 0.0134 - val_loss: 0.0089 - val_mean_absolute_error: 0.1171\n",
      "Epoch 353/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.5976e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00353: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5879e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0149 - val_mean_absolute_error: 0.1608\n",
      "Epoch 354/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6248e-04 - mean_absolute_error: 0.0135\n",
      "Epoch 00354: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6248e-04 - mean_absolute_error: 0.0135 - val_loss: 0.0067 - val_mean_absolute_error: 0.0991\n",
      "Epoch 355/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6618e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 00355: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.6618e-04 - mean_absolute_error: 0.0137 - val_loss: 0.0107 - val_mean_absolute_error: 0.1334\n",
      "Epoch 356/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.5881e-04 - mean_absolute_error: 0.0133\n",
      "Epoch 00356: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5881e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0075 - val_mean_absolute_error: 0.1067\n",
      "Epoch 357/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6147e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00357: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6147e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0093 - val_mean_absolute_error: 0.1197\n",
      "Epoch 358/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.5294e-04 - mean_absolute_error: 0.0132\n",
      "Epoch 00358: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5283e-04 - mean_absolute_error: 0.0132 - val_loss: 0.0082 - val_mean_absolute_error: 0.1126\n",
      "Epoch 359/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6901e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00359: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6901e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0096 - val_mean_absolute_error: 0.1263\n",
      "Epoch 360/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.5903e-04 - mean_absolute_error: 0.0134\n",
      "Epoch 00360: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5895e-04 - mean_absolute_error: 0.0134 - val_loss: 0.0098 - val_mean_absolute_error: 0.1260\n",
      "Epoch 361/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.5674e-04 - mean_absolute_error: 0.0134\n",
      "Epoch 00361: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.5694e-04 - mean_absolute_error: 0.0134 - val_loss: 0.0133 - val_mean_absolute_error: 0.1569\n",
      "Epoch 362/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.5501e-04 - mean_absolute_error: 0.0132\n",
      "Epoch 00362: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5607e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0108 - val_mean_absolute_error: 0.1350\n",
      "Epoch 363/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.4861e-04 - mean_absolute_error: 0.0132\n",
      "Epoch 00363: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.4866e-04 - mean_absolute_error: 0.0132 - val_loss: 0.0047 - val_mean_absolute_error: 0.0810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.5553e-04 - mean_absolute_error: 0.0134\n",
      "Epoch 00364: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5510e-04 - mean_absolute_error: 0.0134 - val_loss: 0.0092 - val_mean_absolute_error: 0.1196\n",
      "Epoch 365/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.5063e-04 - mean_absolute_error: 0.0132\n",
      "Epoch 00365: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.5076e-04 - mean_absolute_error: 0.0132 - val_loss: 0.0092 - val_mean_absolute_error: 0.1240\n",
      "Epoch 366/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.5695e-04 - mean_absolute_error: 0.0134\n",
      "Epoch 00366: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.5695e-04 - mean_absolute_error: 0.0134 - val_loss: 0.0080 - val_mean_absolute_error: 0.1113\n",
      "Epoch 367/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.5346e-04 - mean_absolute_error: 0.0133\n",
      "Epoch 00367: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.5337e-04 - mean_absolute_error: 0.0132 - val_loss: 0.0096 - val_mean_absolute_error: 0.1251\n",
      "Epoch 368/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.5537e-04 - mean_absolute_error: 0.0134\n",
      "Epoch 00368: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5558e-04 - mean_absolute_error: 0.0134 - val_loss: 0.0084 - val_mean_absolute_error: 0.1153\n",
      "Epoch 369/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.5723e-04 - mean_absolute_error: 0.0134\n",
      "Epoch 00369: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5712e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0099 - val_mean_absolute_error: 0.1279\n",
      "Epoch 370/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.5293e-04 - mean_absolute_error: 0.0133\n",
      "Epoch 00370: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.5281e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0085 - val_mean_absolute_error: 0.1167\n",
      "Epoch 371/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.5083e-04 - mean_absolute_error: 0.0132\n",
      "Epoch 00371: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5098e-04 - mean_absolute_error: 0.0132 - val_loss: 0.0151 - val_mean_absolute_error: 0.1642\n",
      "Epoch 372/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.5261e-04 - mean_absolute_error: 0.0131\n",
      "Epoch 00372: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5252e-04 - mean_absolute_error: 0.0131 - val_loss: 0.0140 - val_mean_absolute_error: 0.1562\n",
      "Epoch 373/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.4794e-04 - mean_absolute_error: 0.0130\n",
      "Epoch 00373: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.4833e-04 - mean_absolute_error: 0.0130 - val_loss: 0.0101 - val_mean_absolute_error: 0.1194\n",
      "Epoch 374/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.5325e-04 - mean_absolute_error: 0.0132\n",
      "Epoch 00374: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5334e-04 - mean_absolute_error: 0.0132 - val_loss: 0.0100 - val_mean_absolute_error: 0.1271\n",
      "Epoch 375/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.5466e-04 - mean_absolute_error: 0.0133\n",
      "Epoch 00375: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.5466e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0112 - val_mean_absolute_error: 0.1343\n",
      "Epoch 376/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.5454e-04 - mean_absolute_error: 0.0131\n",
      "Epoch 00376: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5401e-04 - mean_absolute_error: 0.0131 - val_loss: 0.0106 - val_mean_absolute_error: 0.1309\n",
      "Epoch 377/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.4232e-04 - mean_absolute_error: 0.0127\n",
      "Epoch 00377: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.4232e-04 - mean_absolute_error: 0.0127 - val_loss: 0.0093 - val_mean_absolute_error: 0.1188\n",
      "Epoch 378/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.5943e-04 - mean_absolute_error: 0.0131\n",
      "Epoch 00378: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5900e-04 - mean_absolute_error: 0.0131 - val_loss: 0.0203 - val_mean_absolute_error: 0.1889\n",
      "Epoch 379/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.5673e-04 - mean_absolute_error: 0.0132\n",
      "Epoch 00379: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.5673e-04 - mean_absolute_error: 0.0132 - val_loss: 0.0158 - val_mean_absolute_error: 0.1670\n",
      "Epoch 380/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.4936e-04 - mean_absolute_error: 0.0129\n",
      "Epoch 00380: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.4918e-04 - mean_absolute_error: 0.0129 - val_loss: 0.0100 - val_mean_absolute_error: 0.1240\n",
      "Epoch 381/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.5050e-04 - mean_absolute_error: 0.0132\n",
      "Epoch 00381: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5103e-04 - mean_absolute_error: 0.0132 - val_loss: 0.0096 - val_mean_absolute_error: 0.1248\n",
      "Epoch 382/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.4522e-04 - mean_absolute_error: 0.0129\n",
      "Epoch 00382: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.4499e-04 - mean_absolute_error: 0.0129 - val_loss: 0.0123 - val_mean_absolute_error: 0.1445\n",
      "Epoch 383/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.5319e-04 - mean_absolute_error: 0.0132\n",
      "Epoch 00383: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5319e-04 - mean_absolute_error: 0.0132 - val_loss: 0.0066 - val_mean_absolute_error: 0.0969\n",
      "Epoch 384/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.2913e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00384: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 2.2913e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0106 - val_mean_absolute_error: 0.1292\n",
      "Epoch 385/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.4405e-04 - mean_absolute_error: 0.0129\n",
      "Epoch 00385: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.4405e-04 - mean_absolute_error: 0.0129 - val_loss: 0.0115 - val_mean_absolute_error: 0.1382\n",
      "Epoch 386/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.4041e-04 - mean_absolute_error: 0.0127\n",
      "Epoch 00386: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.4033e-04 - mean_absolute_error: 0.0127 - val_loss: 0.0117 - val_mean_absolute_error: 0.1379\n",
      "Epoch 387/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.5015e-04 - mean_absolute_error: 0.0130\n",
      "Epoch 00387: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.5015e-04 - mean_absolute_error: 0.0130 - val_loss: 0.0103 - val_mean_absolute_error: 0.1266\n",
      "Epoch 388/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.4479e-04 - mean_absolute_error: 0.0128\n",
      "Epoch 00388: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.4517e-04 - mean_absolute_error: 0.0128 - val_loss: 0.0069 - val_mean_absolute_error: 0.0993\n",
      "Epoch 389/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.4019e-04 - mean_absolute_error: 0.0127\n",
      "Epoch 00389: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3991e-04 - mean_absolute_error: 0.0127 - val_loss: 0.0117 - val_mean_absolute_error: 0.1385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.5470e-04 - mean_absolute_error: 0.0129\n",
      "Epoch 00390: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.5452e-04 - mean_absolute_error: 0.0129 - val_loss: 0.0110 - val_mean_absolute_error: 0.1313\n",
      "Epoch 391/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6343e-04 - mean_absolute_error: 0.0130\n",
      "Epoch 00391: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.6343e-04 - mean_absolute_error: 0.0130 - val_loss: 0.0144 - val_mean_absolute_error: 0.1540\n",
      "Epoch 392/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.4905e-04 - mean_absolute_error: 0.0129\n",
      "Epoch 00392: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.4905e-04 - mean_absolute_error: 0.0129 - val_loss: 0.0130 - val_mean_absolute_error: 0.1498\n",
      "Epoch 393/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.4300e-04 - mean_absolute_error: 0.0128\n",
      "Epoch 00393: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 1.4315e-04 - mean_absolute_error: 0.0128 - val_loss: 0.0105 - val_mean_absolute_error: 0.1266\n",
      "Epoch 394/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.4590e-04 - mean_absolute_error: 0.0127\n",
      "Epoch 00394: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.4590e-04 - mean_absolute_error: 0.0127 - val_loss: 0.0128 - val_mean_absolute_error: 0.1436\n",
      "Epoch 395/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.4629e-04 - mean_absolute_error: 0.0127\n",
      "Epoch 00395: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.4649e-04 - mean_absolute_error: 0.0127 - val_loss: 0.0100 - val_mean_absolute_error: 0.1279\n",
      "Epoch 396/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3634e-04 - mean_absolute_error: 0.0125\n",
      "Epoch 00396: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.3634e-04 - mean_absolute_error: 0.0125 - val_loss: 0.0093 - val_mean_absolute_error: 0.1212\n",
      "Epoch 397/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.5471e-04 - mean_absolute_error: 0.0131\n",
      "Epoch 00397: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.5471e-04 - mean_absolute_error: 0.0131 - val_loss: 0.0097 - val_mean_absolute_error: 0.1254\n",
      "Epoch 398/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.4063e-04 - mean_absolute_error: 0.0125\n",
      "Epoch 00398: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.4524e-04 - mean_absolute_error: 0.0126 - val_loss: 0.0430 - val_mean_absolute_error: 0.2889\n",
      "Epoch 399/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.4680e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 00399: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 2.4680e-04 - mean_absolute_error: 0.0147 - val_loss: 0.0131 - val_mean_absolute_error: 0.1472\n",
      "Epoch 400/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.4898e-04 - mean_absolute_error: 0.0128\n",
      "Epoch 00400: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.4902e-04 - mean_absolute_error: 0.0128 - val_loss: 0.0074 - val_mean_absolute_error: 0.1041\n",
      "Epoch 401/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.4821e-04 - mean_absolute_error: 0.0129\n",
      "Epoch 00401: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.4764e-04 - mean_absolute_error: 0.0129 - val_loss: 0.0107 - val_mean_absolute_error: 0.1295\n",
      "Epoch 402/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.4601e-04 - mean_absolute_error: 0.0126\n",
      "Epoch 00402: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.4580e-04 - mean_absolute_error: 0.0126 - val_loss: 0.0133 - val_mean_absolute_error: 0.1462\n",
      "Epoch 403/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3829e-04 - mean_absolute_error: 0.0125\n",
      "Epoch 00403: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.3813e-04 - mean_absolute_error: 0.0124 - val_loss: 0.0114 - val_mean_absolute_error: 0.1371\n",
      "Epoch 404/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.4318e-04 - mean_absolute_error: 0.0126\n",
      "Epoch 00404: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.4334e-04 - mean_absolute_error: 0.0126 - val_loss: 0.0080 - val_mean_absolute_error: 0.1043\n",
      "Epoch 405/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.6907e-04 - mean_absolute_error: 0.0129\n",
      "Epoch 00405: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.6883e-04 - mean_absolute_error: 0.0129 - val_loss: 0.0157 - val_mean_absolute_error: 0.1632\n",
      "Epoch 406/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.4336e-04 - mean_absolute_error: 0.0128\n",
      "Epoch 00406: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.4428e-04 - mean_absolute_error: 0.0128 - val_loss: 0.0176 - val_mean_absolute_error: 0.1709\n",
      "Epoch 407/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.4832e-04 - mean_absolute_error: 0.0126\n",
      "Epoch 00407: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 1.4832e-04 - mean_absolute_error: 0.0126 - val_loss: 0.0152 - val_mean_absolute_error: 0.1612\n",
      "Epoch 408/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3126e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 00408: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.3132e-04 - mean_absolute_error: 0.0122 - val_loss: 0.0098 - val_mean_absolute_error: 0.1248\n",
      "Epoch 409/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3576e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 00409: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3575e-04 - mean_absolute_error: 0.0123 - val_loss: 0.0129 - val_mean_absolute_error: 0.1468\n",
      "Epoch 410/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.4409e-04 - mean_absolute_error: 0.0126\n",
      "Epoch 00410: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.4409e-04 - mean_absolute_error: 0.0126 - val_loss: 0.0170 - val_mean_absolute_error: 0.1707\n",
      "Epoch 411/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.9231e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 00411: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.9213e-04 - mean_absolute_error: 0.0137 - val_loss: 0.0110 - val_mean_absolute_error: 0.1348\n",
      "Epoch 412/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.4069e-04 - mean_absolute_error: 0.0126\n",
      "Epoch 00412: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.4058e-04 - mean_absolute_error: 0.0126 - val_loss: 0.0129 - val_mean_absolute_error: 0.1507\n",
      "Epoch 413/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3785e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 00413: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3785e-04 - mean_absolute_error: 0.0123 - val_loss: 0.0119 - val_mean_absolute_error: 0.1379\n",
      "Epoch 414/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.4026e-04 - mean_absolute_error: 0.0124\n",
      "Epoch 00414: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.4063e-04 - mean_absolute_error: 0.0125 - val_loss: 0.0147 - val_mean_absolute_error: 0.1601\n",
      "Epoch 415/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3329e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 00415: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3307e-04 - mean_absolute_error: 0.0122 - val_loss: 0.0130 - val_mean_absolute_error: 0.1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3644e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 00416: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3653e-04 - mean_absolute_error: 0.0122 - val_loss: 0.0132 - val_mean_absolute_error: 0.1425\n",
      "Epoch 417/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.4315e-04 - mean_absolute_error: 0.0125\n",
      "Epoch 00417: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.4311e-04 - mean_absolute_error: 0.0125 - val_loss: 0.0100 - val_mean_absolute_error: 0.1242\n",
      "Epoch 418/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.3293e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00418: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3463e-04 - mean_absolute_error: 0.0120 - val_loss: 0.0153 - val_mean_absolute_error: 0.1592\n",
      "Epoch 419/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3402e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 00419: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.3402e-04 - mean_absolute_error: 0.0121 - val_loss: 0.0117 - val_mean_absolute_error: 0.1354\n",
      "Epoch 420/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3318e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 00420: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3321e-04 - mean_absolute_error: 0.0121 - val_loss: 0.0101 - val_mean_absolute_error: 0.1264\n",
      "Epoch 421/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3722e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 00421: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3715e-04 - mean_absolute_error: 0.0123 - val_loss: 0.0099 - val_mean_absolute_error: 0.1250\n",
      "Epoch 422/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3871e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 00422: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3856e-04 - mean_absolute_error: 0.0123 - val_loss: 0.0121 - val_mean_absolute_error: 0.1417\n",
      "Epoch 423/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 1.5315e-04 - mean_absolute_error: 0.0125\n",
      "Epoch 00423: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.5332e-04 - mean_absolute_error: 0.0125 - val_loss: 0.0105 - val_mean_absolute_error: 0.1297\n",
      "Epoch 424/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3333e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 00424: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3327e-04 - mean_absolute_error: 0.0123 - val_loss: 0.0176 - val_mean_absolute_error: 0.1717\n",
      "Epoch 425/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2883e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00425: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2883e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0147 - val_mean_absolute_error: 0.1538\n",
      "Epoch 426/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2862e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 00426: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.2848e-04 - mean_absolute_error: 0.0121 - val_loss: 0.0129 - val_mean_absolute_error: 0.1436\n",
      "Epoch 427/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3010e-04 - mean_absolute_error: 0.0120\n",
      "Epoch 00427: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3010e-04 - mean_absolute_error: 0.0120 - val_loss: 0.0121 - val_mean_absolute_error: 0.1419\n",
      "Epoch 428/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3104e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 00428: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3104e-04 - mean_absolute_error: 0.0122 - val_loss: 0.0131 - val_mean_absolute_error: 0.1477\n",
      "Epoch 429/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3039e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 00429: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.3023e-04 - mean_absolute_error: 0.0120 - val_loss: 0.0089 - val_mean_absolute_error: 0.1167\n",
      "Epoch 430/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2989e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00430: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2989e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0151 - val_mean_absolute_error: 0.1574\n",
      "Epoch 431/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3080e-04 - mean_absolute_error: 0.0120\n",
      "Epoch 00431: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.3080e-04 - mean_absolute_error: 0.0120 - val_loss: 0.0162 - val_mean_absolute_error: 0.1687\n",
      "Epoch 432/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3308e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 00432: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.3336e-04 - mean_absolute_error: 0.0121 - val_loss: 0.0143 - val_mean_absolute_error: 0.1534\n",
      "Epoch 433/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3365e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 00433: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.3370e-04 - mean_absolute_error: 0.0123 - val_loss: 0.0142 - val_mean_absolute_error: 0.1536\n",
      "Epoch 434/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3564e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 00434: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3554e-04 - mean_absolute_error: 0.0123 - val_loss: 0.0112 - val_mean_absolute_error: 0.1321\n",
      "Epoch 435/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.3361e-04 - mean_absolute_error: 0.0120\n",
      "Epoch 00435: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3340e-04 - mean_absolute_error: 0.0120 - val_loss: 0.0151 - val_mean_absolute_error: 0.1599\n",
      "Epoch 436/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3604e-04 - mean_absolute_error: 0.0120\n",
      "Epoch 00436: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.3604e-04 - mean_absolute_error: 0.0120 - val_loss: 0.0117 - val_mean_absolute_error: 0.1380\n",
      "Epoch 437/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3209e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 00437: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.3209e-04 - mean_absolute_error: 0.0121 - val_loss: 0.0114 - val_mean_absolute_error: 0.1369\n",
      "Epoch 438/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2239e-04 - mean_absolute_error: 0.0117\n",
      "Epoch 00438: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.2239e-04 - mean_absolute_error: 0.0117 - val_loss: 0.0153 - val_mean_absolute_error: 0.1600\n",
      "Epoch 439/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3242e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00439: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3242e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0138 - val_mean_absolute_error: 0.1498\n",
      "Epoch 440/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.2736e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00440: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3116e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0137 - val_mean_absolute_error: 0.1534\n",
      "Epoch 441/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2638e-04 - mean_absolute_error: 0.0120\n",
      "Epoch 00441: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2662e-04 - mean_absolute_error: 0.0120 - val_loss: 0.0121 - val_mean_absolute_error: 0.1380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2773e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00442: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2773e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0117 - val_mean_absolute_error: 0.1375\n",
      "Epoch 443/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.2572e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00443: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2530e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0144 - val_mean_absolute_error: 0.1572\n",
      "Epoch 444/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.2902e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00444: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.2890e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0145 - val_mean_absolute_error: 0.1597\n",
      "Epoch 445/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 1.2718e-04 - mean_absolute_error: 0.0118\n",
      "Epoch 00445: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.2715e-04 - mean_absolute_error: 0.0118 - val_loss: 0.0108 - val_mean_absolute_error: 0.1333\n",
      "Epoch 446/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.3013e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00446: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.3055e-04 - mean_absolute_error: 0.0120 - val_loss: 0.0162 - val_mean_absolute_error: 0.1662\n",
      "Epoch 447/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.2887e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00447: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.2859e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0139 - val_mean_absolute_error: 0.1547\n",
      "Epoch 448/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2829e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00448: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.2829e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0116 - val_mean_absolute_error: 0.1387\n",
      "Epoch 449/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.2633e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00449: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.2606e-04 - mean_absolute_error: 0.0118 - val_loss: 0.0109 - val_mean_absolute_error: 0.1322\n",
      "Epoch 450/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3135e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 00450: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.3135e-04 - mean_absolute_error: 0.0121 - val_loss: 0.0108 - val_mean_absolute_error: 0.1275\n",
      "Epoch 451/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.2641e-04 - mean_absolute_error: 0.0117\n",
      "Epoch 00451: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.2656e-04 - mean_absolute_error: 0.0118 - val_loss: 0.0135 - val_mean_absolute_error: 0.1528\n",
      "Epoch 452/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.2855e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00452: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2846e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0101 - val_mean_absolute_error: 0.1291\n",
      "Epoch 453/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2566e-04 - mean_absolute_error: 0.0118\n",
      "Epoch 00453: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.2566e-04 - mean_absolute_error: 0.0118 - val_loss: 0.0151 - val_mean_absolute_error: 0.1638\n",
      "Epoch 454/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.2490e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 00454: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2553e-04 - mean_absolute_error: 0.0115 - val_loss: 0.0105 - val_mean_absolute_error: 0.1307\n",
      "Epoch 455/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3062e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00455: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3062e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0154 - val_mean_absolute_error: 0.1616\n",
      "Epoch 456/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2104e-04 - mean_absolute_error: 0.0117\n",
      "Epoch 00456: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.2104e-04 - mean_absolute_error: 0.0117 - val_loss: 0.0135 - val_mean_absolute_error: 0.1497\n",
      "Epoch 457/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.2476e-04 - mean_absolute_error: 0.0117\n",
      "Epoch 00457: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.2494e-04 - mean_absolute_error: 0.0117 - val_loss: 0.0096 - val_mean_absolute_error: 0.1253\n",
      "Epoch 458/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3256e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00458: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3256e-04 - mean_absolute_error: 0.0119 - val_loss: 0.0104 - val_mean_absolute_error: 0.1321\n",
      "Epoch 459/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2801e-04 - mean_absolute_error: 0.0118\n",
      "Epoch 00459: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2795e-04 - mean_absolute_error: 0.0118 - val_loss: 0.0128 - val_mean_absolute_error: 0.1478\n",
      "Epoch 460/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2579e-04 - mean_absolute_error: 0.0118\n",
      "Epoch 00460: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2586e-04 - mean_absolute_error: 0.0118 - val_loss: 0.0079 - val_mean_absolute_error: 0.1097\n",
      "Epoch 461/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.3028e-04 - mean_absolute_error: 0.0118\n",
      "Epoch 00461: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2994e-04 - mean_absolute_error: 0.0118 - val_loss: 0.0050 - val_mean_absolute_error: 0.0842\n",
      "Epoch 462/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2348e-04 - mean_absolute_error: 0.0118\n",
      "Epoch 00462: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2339e-04 - mean_absolute_error: 0.0118 - val_loss: 0.0075 - val_mean_absolute_error: 0.1063\n",
      "Epoch 463/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2274e-04 - mean_absolute_error: 0.0117\n",
      "Epoch 00463: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2274e-04 - mean_absolute_error: 0.0117 - val_loss: 0.0121 - val_mean_absolute_error: 0.1430\n",
      "Epoch 464/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.2862e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 00464: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2841e-04 - mean_absolute_error: 0.0116 - val_loss: 0.0091 - val_mean_absolute_error: 0.1159\n",
      "Epoch 465/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2072e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 00465: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.2072e-04 - mean_absolute_error: 0.0115 - val_loss: 0.0140 - val_mean_absolute_error: 0.1503\n",
      "Epoch 466/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1539e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 00466: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.1577e-04 - mean_absolute_error: 0.0115 - val_loss: 0.0129 - val_mean_absolute_error: 0.1472\n",
      "Epoch 467/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2359e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 00467: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2359e-04 - mean_absolute_error: 0.0116 - val_loss: 0.0102 - val_mean_absolute_error: 0.1274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1918e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 00468: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1905e-04 - mean_absolute_error: 0.0114 - val_loss: 0.0097 - val_mean_absolute_error: 0.1244\n",
      "Epoch 469/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2307e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 00469: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2307e-04 - mean_absolute_error: 0.0116 - val_loss: 0.0095 - val_mean_absolute_error: 0.1254\n",
      "Epoch 470/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2036e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 00470: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2036e-04 - mean_absolute_error: 0.0116 - val_loss: 0.0118 - val_mean_absolute_error: 0.1413\n",
      "Epoch 471/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1733e-04 - mean_absolute_error: 0.0113\n",
      "Epoch 00471: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 1.1731e-04 - mean_absolute_error: 0.0113 - val_loss: 0.0088 - val_mean_absolute_error: 0.1158\n",
      "Epoch 472/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.3923e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 00472: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.3897e-04 - mean_absolute_error: 0.0116 - val_loss: 0.0125 - val_mean_absolute_error: 0.1442\n",
      "Epoch 473/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1917e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 00473: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1925e-04 - mean_absolute_error: 0.0115 - val_loss: 0.0076 - val_mean_absolute_error: 0.1055\n",
      "Epoch 474/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1985e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 00474: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2007e-04 - mean_absolute_error: 0.0114 - val_loss: 0.0196 - val_mean_absolute_error: 0.1887\n",
      "Epoch 475/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1597e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 00475: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1597e-04 - mean_absolute_error: 0.0112 - val_loss: 0.0155 - val_mean_absolute_error: 0.1627\n",
      "Epoch 476/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1816e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 00476: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.1816e-04 - mean_absolute_error: 0.0114 - val_loss: 0.0149 - val_mean_absolute_error: 0.1607\n",
      "Epoch 477/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2064e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 00477: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.2048e-04 - mean_absolute_error: 0.0114 - val_loss: 0.0114 - val_mean_absolute_error: 0.1353\n",
      "Epoch 478/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2115e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 00478: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.2115e-04 - mean_absolute_error: 0.0116 - val_loss: 0.0106 - val_mean_absolute_error: 0.1298\n",
      "Epoch 479/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1307e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 00479: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 1.1335e-04 - mean_absolute_error: 0.0112 - val_loss: 0.0179 - val_mean_absolute_error: 0.1776\n",
      "Epoch 480/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1829e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 00480: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1879e-04 - mean_absolute_error: 0.0112 - val_loss: 0.0131 - val_mean_absolute_error: 0.1479\n",
      "Epoch 481/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1654e-04 - mean_absolute_error: 0.0113\n",
      "Epoch 00481: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1654e-04 - mean_absolute_error: 0.0113 - val_loss: 0.0156 - val_mean_absolute_error: 0.1682\n",
      "Epoch 482/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1607e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 00482: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1563e-04 - mean_absolute_error: 0.0114 - val_loss: 0.0093 - val_mean_absolute_error: 0.1205\n",
      "Epoch 483/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1532e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 00483: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1539e-04 - mean_absolute_error: 0.0114 - val_loss: 0.0149 - val_mean_absolute_error: 0.1605\n",
      "Epoch 484/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3536e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 00484: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.3536e-04 - mean_absolute_error: 0.0116 - val_loss: 0.0088 - val_mean_absolute_error: 0.1206\n",
      "Epoch 485/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2158e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 00485: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.2165e-04 - mean_absolute_error: 0.0115 - val_loss: 0.0161 - val_mean_absolute_error: 0.1647\n",
      "Epoch 486/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2245e-04 - mean_absolute_error: 0.0113\n",
      "Epoch 00486: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2245e-04 - mean_absolute_error: 0.0113 - val_loss: 0.0104 - val_mean_absolute_error: 0.1265\n",
      "Epoch 487/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1799e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 00487: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1799e-04 - mean_absolute_error: 0.0114 - val_loss: 0.0147 - val_mean_absolute_error: 0.1617\n",
      "Epoch 488/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2281e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 00488: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.2281e-04 - mean_absolute_error: 0.0115 - val_loss: 0.0133 - val_mean_absolute_error: 0.1509\n",
      "Epoch 489/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1855e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 00489: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1847e-04 - mean_absolute_error: 0.0114 - val_loss: 0.0127 - val_mean_absolute_error: 0.1470\n",
      "Epoch 490/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2205e-04 - mean_absolute_error: 0.0113\n",
      "Epoch 00490: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.2186e-04 - mean_absolute_error: 0.0113 - val_loss: 0.0124 - val_mean_absolute_error: 0.1438\n",
      "Epoch 491/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1354e-04 - mean_absolute_error: 0.0111\n",
      "Epoch 00491: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1374e-04 - mean_absolute_error: 0.0111 - val_loss: 0.0128 - val_mean_absolute_error: 0.1462\n",
      "Epoch 492/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1494e-04 - mean_absolute_error: 0.0113\n",
      "Epoch 00492: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1494e-04 - mean_absolute_error: 0.0113 - val_loss: 0.0131 - val_mean_absolute_error: 0.1526\n",
      "Epoch 493/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1173e-04 - mean_absolute_error: 0.0111\n",
      "Epoch 00493: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1179e-04 - mean_absolute_error: 0.0111 - val_loss: 0.0060 - val_mean_absolute_error: 0.0940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1209e-04 - mean_absolute_error: 0.0111\n",
      "Epoch 00494: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1209e-04 - mean_absolute_error: 0.0111 - val_loss: 0.0118 - val_mean_absolute_error: 0.1428\n",
      "Epoch 495/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2065e-04 - mean_absolute_error: 0.0113\n",
      "Epoch 00495: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2047e-04 - mean_absolute_error: 0.0113 - val_loss: 0.0098 - val_mean_absolute_error: 0.1278\n",
      "Epoch 496/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2178e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 00496: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2168e-04 - mean_absolute_error: 0.0114 - val_loss: 0.0121 - val_mean_absolute_error: 0.1432\n",
      "Epoch 497/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1233e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00497: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1240e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0097 - val_mean_absolute_error: 0.1209\n",
      "Epoch 498/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1415e-04 - mean_absolute_error: 0.0111\n",
      "Epoch 00498: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1389e-04 - mean_absolute_error: 0.0111 - val_loss: 0.0103 - val_mean_absolute_error: 0.1294\n",
      "Epoch 499/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1222e-04 - mean_absolute_error: 0.0111\n",
      "Epoch 00499: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.1222e-04 - mean_absolute_error: 0.0111 - val_loss: 0.0141 - val_mean_absolute_error: 0.1559\n",
      "Epoch 500/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1535e-04 - mean_absolute_error: 0.0112- ETA: 0s - loss: 1.1645e-04 - mean_absolute_erro\n",
      "Epoch 00500: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1535e-04 - mean_absolute_error: 0.0112 - val_loss: 0.0120 - val_mean_absolute_error: 0.1410\n",
      "Epoch 501/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1052e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00501: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1048e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0111 - val_mean_absolute_error: 0.1346\n",
      "Epoch 502/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1564e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 00502: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1527e-04 - mean_absolute_error: 0.0112 - val_loss: 0.0136 - val_mean_absolute_error: 0.1526\n",
      "Epoch 503/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1025e-04 - mean_absolute_error: 0.0111\n",
      "Epoch 00503: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0963e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0121 - val_mean_absolute_error: 0.1414\n",
      "Epoch 504/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0942e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00504: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0987e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0129 - val_mean_absolute_error: 0.1499\n",
      "Epoch 505/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1238e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 00505: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1238e-04 - mean_absolute_error: 0.0112 - val_loss: 0.0097 - val_mean_absolute_error: 0.1252\n",
      "Epoch 506/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1127e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00506: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1149e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0103 - val_mean_absolute_error: 0.1310\n",
      "Epoch 507/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2006e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 00507: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.2006e-04 - mean_absolute_error: 0.0112 - val_loss: 0.0067 - val_mean_absolute_error: 0.0983\n",
      "Epoch 508/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1367e-04 - mean_absolute_error: 0.0111\n",
      "Epoch 00508: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1367e-04 - mean_absolute_error: 0.0111 - val_loss: 0.0128 - val_mean_absolute_error: 0.1476\n",
      "Epoch 509/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1108e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 00509: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1165e-04 - mean_absolute_error: 0.0109 - val_loss: 0.0097 - val_mean_absolute_error: 0.1251\n",
      "Epoch 510/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1396e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 00510: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1407e-04 - mean_absolute_error: 0.0112 - val_loss: 0.0111 - val_mean_absolute_error: 0.1355\n",
      "Epoch 511/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1802e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 00511: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1846e-04 - mean_absolute_error: 0.0112 - val_loss: 0.0149 - val_mean_absolute_error: 0.1616\n",
      "Epoch 512/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1273e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00512: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1266e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0121 - val_mean_absolute_error: 0.1407\n",
      "Epoch 513/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1324e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 00513: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1324e-04 - mean_absolute_error: 0.0112 - val_loss: 0.0073 - val_mean_absolute_error: 0.1050\n",
      "Epoch 514/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1814e-04 - mean_absolute_error: 0.0111\n",
      "Epoch 00514: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1804e-04 - mean_absolute_error: 0.0111 - val_loss: 0.0126 - val_mean_absolute_error: 0.1462\n",
      "Epoch 515/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0971e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00515: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0979e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0136 - val_mean_absolute_error: 0.1552\n",
      "Epoch 516/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1165e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 00516: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1155e-04 - mean_absolute_error: 0.0109 - val_loss: 0.0127 - val_mean_absolute_error: 0.1469\n",
      "Epoch 517/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0516e-04 - mean_absolute_error: 0.0108\n",
      "Epoch 00517: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0516e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0106 - val_mean_absolute_error: 0.1345\n",
      "Epoch 518/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1612e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00518: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1608e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0106 - val_mean_absolute_error: 0.1324\n",
      "Epoch 519/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1240e-04 - mean_absolute_error: 0.0111\n",
      "Epoch 00519: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1223e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0137 - val_mean_absolute_error: 0.1531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1425e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00520: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1425e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0137 - val_mean_absolute_error: 0.1546\n",
      "Epoch 521/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0783e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00521: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0856e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0128 - val_mean_absolute_error: 0.1493\n",
      "Epoch 522/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0786e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 00522: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0735e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0109 - val_mean_absolute_error: 0.1349\n",
      "Epoch 523/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0981e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00523: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0989e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0100 - val_mean_absolute_error: 0.1268\n",
      "Epoch 524/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0878e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 00524: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0874e-04 - mean_absolute_error: 0.0109 - val_loss: 0.0065 - val_mean_absolute_error: 0.0971\n",
      "Epoch 525/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0838e-04 - mean_absolute_error: 0.0108\n",
      "Epoch 00525: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0824e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0119 - val_mean_absolute_error: 0.1418\n",
      "Epoch 526/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1029e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00526: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.1113e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0068 - val_mean_absolute_error: 0.1026\n",
      "Epoch 527/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0593e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00527: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0593e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0124 - val_mean_absolute_error: 0.1460\n",
      "Epoch 528/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0508e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00528: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0508e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0122 - val_mean_absolute_error: 0.1447\n",
      "Epoch 529/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0490e-04 - mean_absolute_error: 0.0108\n",
      "Epoch 00529: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0414e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0114 - val_mean_absolute_error: 0.1378\n",
      "Epoch 530/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.1420e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00530: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.1394e-04 - mean_absolute_error: 0.0110 - val_loss: 0.0134 - val_mean_absolute_error: 0.1528\n",
      "Epoch 531/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0276e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00531: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0276e-04 - mean_absolute_error: 0.0106 - val_loss: 0.0098 - val_mean_absolute_error: 0.1255\n",
      "Epoch 532/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0606e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00532: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0592e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0136 - val_mean_absolute_error: 0.1524\n",
      "Epoch 533/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1063e-04 - mean_absolute_error: 0.0108\n",
      "Epoch 00533: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1063e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0132 - val_mean_absolute_error: 0.1519\n",
      "Epoch 534/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0904e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 00534: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 1.0909e-04 - mean_absolute_error: 0.0109 - val_loss: 0.0123 - val_mean_absolute_error: 0.1422\n",
      "Epoch 535/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0485e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00535: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0485e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0139 - val_mean_absolute_error: 0.1513\n",
      "Epoch 536/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0725e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00536: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0719e-04 - mean_absolute_error: 0.0106 - val_loss: 0.0138 - val_mean_absolute_error: 0.1512\n",
      "Epoch 537/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0368e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00537: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0368e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0129 - val_mean_absolute_error: 0.1456\n",
      "Epoch 538/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0573e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00538: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0573e-04 - mean_absolute_error: 0.0106 - val_loss: 0.0144 - val_mean_absolute_error: 0.1569\n",
      "Epoch 539/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0366e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00539: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0360e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0165 - val_mean_absolute_error: 0.1687\n",
      "Epoch 540/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0236e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00540: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0233e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0153 - val_mean_absolute_error: 0.1616\n",
      "Epoch 541/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0730e-04 - mean_absolute_error: 0.0108\n",
      "Epoch 00541: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0730e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0093 - val_mean_absolute_error: 0.1210\n",
      "Epoch 542/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0868e-04 - mean_absolute_error: 0.0108\n",
      "Epoch 00542: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0868e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0103 - val_mean_absolute_error: 0.1312\n",
      "Epoch 543/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0753e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00543: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0753e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0192 - val_mean_absolute_error: 0.1855\n",
      "Epoch 544/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0569e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00544: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0562e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0123 - val_mean_absolute_error: 0.1422\n",
      "Epoch 545/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0900e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00545: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0900e-04 - mean_absolute_error: 0.0106 - val_loss: 0.0106 - val_mean_absolute_error: 0.1321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0809e-04 - mean_absolute_error: 0.0108\n",
      "Epoch 00546: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0809e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0146 - val_mean_absolute_error: 0.1612\n",
      "Epoch 547/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1014e-04 - mean_absolute_error: 0.0108\n",
      "Epoch 00547: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.1022e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0110 - val_mean_absolute_error: 0.1349\n",
      "Epoch 548/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0843e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00548: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.0843e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0122 - val_mean_absolute_error: 0.1419\n",
      "Epoch 549/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0348e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00549: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.0362e-04 - mean_absolute_error: 0.0104 - val_loss: 0.0135 - val_mean_absolute_error: 0.1516\n",
      "Epoch 550/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0499e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00550: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0496e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0151 - val_mean_absolute_error: 0.1647\n",
      "Epoch 551/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0847e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00551: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 1.0907e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0075 - val_mean_absolute_error: 0.1074\n",
      "Epoch 552/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0770e-04 - mean_absolute_error: 0.0108\n",
      "Epoch 00552: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0847e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0130 - val_mean_absolute_error: 0.1482\n",
      "Epoch 553/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0514e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00553: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0514e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0119 - val_mean_absolute_error: 0.1417\n",
      "Epoch 554/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0473e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00554: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0473e-04 - mean_absolute_error: 0.0106 - val_loss: 0.0171 - val_mean_absolute_error: 0.1743\n",
      "Epoch 555/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0095e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00555: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0095e-04 - mean_absolute_error: 0.0104 - val_loss: 0.0107 - val_mean_absolute_error: 0.1309\n",
      "Epoch 556/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0428e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00556: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0428e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0088 - val_mean_absolute_error: 0.1178\n",
      "Epoch 557/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0337e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00557: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.0308e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0082 - val_mean_absolute_error: 0.1122\n",
      "Epoch 558/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0446e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00558: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.0421e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0199 - val_mean_absolute_error: 0.1881\n",
      "Epoch 559/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0280e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00559: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0234e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0104 - val_mean_absolute_error: 0.1299\n",
      "Epoch 560/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0823e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00560: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 1.0823e-04 - mean_absolute_error: 0.0107 - val_loss: 0.0163 - val_mean_absolute_error: 0.1695\n",
      "Epoch 561/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0219e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00561: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0219e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0162 - val_mean_absolute_error: 0.1691\n",
      "Epoch 562/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0002e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00562: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0071e-04 - mean_absolute_error: 0.0104 - val_loss: 0.0166 - val_mean_absolute_error: 0.1682\n",
      "Epoch 563/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0339e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00563: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0307e-04 - mean_absolute_error: 0.0106 - val_loss: 0.0106 - val_mean_absolute_error: 0.1290\n",
      "Epoch 564/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0432e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00564: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0426e-04 - mean_absolute_error: 0.0106 - val_loss: 0.0068 - val_mean_absolute_error: 0.1016\n",
      "Epoch 565/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.8767e-05 - mean_absolute_error: 0.0104\n",
      "Epoch 00565: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.8767e-05 - mean_absolute_error: 0.0104 - val_loss: 0.0109 - val_mean_absolute_error: 0.1329\n",
      "Epoch 566/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.8716e-05 - mean_absolute_error: 0.0103\n",
      "Epoch 00566: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.8633e-05 - mean_absolute_error: 0.0103 - val_loss: 0.0080 - val_mean_absolute_error: 0.1114\n",
      "Epoch 567/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0444e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00567: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0424e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0084 - val_mean_absolute_error: 0.1114\n",
      "Epoch 568/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0242e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00568: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0240e-04 - mean_absolute_error: 0.0106 - val_loss: 0.0077 - val_mean_absolute_error: 0.1081\n",
      "Epoch 569/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0459e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00569: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0500e-04 - mean_absolute_error: 0.0104 - val_loss: 0.0152 - val_mean_absolute_error: 0.1632\n",
      "Epoch 570/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0300e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00570: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0289e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0127 - val_mean_absolute_error: 0.1471\n",
      "Epoch 571/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0731e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00571: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0736e-04 - mean_absolute_error: 0.0106 - val_loss: 0.0090 - val_mean_absolute_error: 0.1193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 572/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0181e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00572: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0184e-04 - mean_absolute_error: 0.0104 - val_loss: 0.0126 - val_mean_absolute_error: 0.1471\n",
      "Epoch 573/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0265e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00573: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0265e-04 - mean_absolute_error: 0.0104 - val_loss: 0.0094 - val_mean_absolute_error: 0.1212\n",
      "Epoch 574/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.6811e-05 - mean_absolute_error: 0.0103\n",
      "Epoch 00574: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.6809e-05 - mean_absolute_error: 0.0103 - val_loss: 0.0116 - val_mean_absolute_error: 0.1396\n",
      "Epoch 575/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0760e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00575: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0746e-04 - mean_absolute_error: 0.0104 - val_loss: 0.0140 - val_mean_absolute_error: 0.1556\n",
      "Epoch 576/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.9606e-05 - mean_absolute_error: 0.0104\n",
      "Epoch 00576: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.9412e-05 - mean_absolute_error: 0.0104 - val_loss: 0.0133 - val_mean_absolute_error: 0.1504\n",
      "Epoch 577/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0516e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00577: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0513e-04 - mean_absolute_error: 0.0103 - val_loss: 0.0157 - val_mean_absolute_error: 0.1638\n",
      "Epoch 578/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0193e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00578: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.0186e-04 - mean_absolute_error: 0.0104 - val_loss: 0.0099 - val_mean_absolute_error: 0.1260\n",
      "Epoch 579/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0125e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00579: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0125e-04 - mean_absolute_error: 0.0104 - val_loss: 0.0121 - val_mean_absolute_error: 0.1434\n",
      "Epoch 580/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0388e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00580: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0388e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0132 - val_mean_absolute_error: 0.1478\n",
      "Epoch 581/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0435e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00581: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0435e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0093 - val_mean_absolute_error: 0.1216\n",
      "Epoch 582/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0449e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00582: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0499e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0132 - val_mean_absolute_error: 0.1525\n",
      "Epoch 583/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0351e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00583: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0301e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0163 - val_mean_absolute_error: 0.1682\n",
      "Epoch 584/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0069e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 00584: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0069e-04 - mean_absolute_error: 0.0102 - val_loss: 0.0143 - val_mean_absolute_error: 0.1570\n",
      "Epoch 585/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.8175e-05 - mean_absolute_error: 0.0103\n",
      "Epoch 00585: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.7915e-05 - mean_absolute_error: 0.0103 - val_loss: 0.0125 - val_mean_absolute_error: 0.1444\n",
      "Epoch 586/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.0249e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00586: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0216e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0090 - val_mean_absolute_error: 0.1186\n",
      "Epoch 587/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0150e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00587: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0150e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0110 - val_mean_absolute_error: 0.1346\n",
      "Epoch 588/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.7242e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00588: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.7242e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0099 - val_mean_absolute_error: 0.1250\n",
      "Epoch 589/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.9696e-05 - mean_absolute_error: 0.0103\n",
      "Epoch 00589: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.9696e-05 - mean_absolute_error: 0.0103 - val_loss: 0.0140 - val_mean_absolute_error: 0.1539\n",
      "Epoch 590/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0062e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00590: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.0125e-04 - mean_absolute_error: 0.0103 - val_loss: 0.0210 - val_mean_absolute_error: 0.1970\n",
      "Epoch 591/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0393e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00591: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0388e-04 - mean_absolute_error: 0.0103 - val_loss: 0.0081 - val_mean_absolute_error: 0.1102\n",
      "Epoch 592/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0262e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00592: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0262e-04 - mean_absolute_error: 0.0103 - val_loss: 0.0117 - val_mean_absolute_error: 0.1401\n",
      "Epoch 593/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0045e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00593: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0056e-04 - mean_absolute_error: 0.0103 - val_loss: 0.0106 - val_mean_absolute_error: 0.1322\n",
      "Epoch 594/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.6811e-05 - mean_absolute_error: 0.0101\n",
      "Epoch 00594: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.6811e-05 - mean_absolute_error: 0.0101 - val_loss: 0.0094 - val_mean_absolute_error: 0.1205\n",
      "Epoch 595/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0087e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00595: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0100e-04 - mean_absolute_error: 0.0104 - val_loss: 0.0107 - val_mean_absolute_error: 0.1301\n",
      "Epoch 596/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.5819e-05 - mean_absolute_error: 0.0101\n",
      "Epoch 00596: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.5819e-05 - mean_absolute_error: 0.0101 - val_loss: 0.0134 - val_mean_absolute_error: 0.1521\n",
      "Epoch 597/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.6331e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00597: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 9.6331e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0147 - val_mean_absolute_error: 0.1607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 598/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0100e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00598: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.0166e-04 - mean_absolute_error: 0.0103 - val_loss: 0.0184 - val_mean_absolute_error: 0.1801\n",
      "Epoch 599/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.7253e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00599: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.7215e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0127 - val_mean_absolute_error: 0.1450\n",
      "Epoch 600/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.1399e-05 - mean_absolute_error: 0.0101\n",
      "Epoch 00600: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 9.2008e-05 - mean_absolute_error: 0.0101 - val_loss: 0.0106 - val_mean_absolute_error: 0.1274\n",
      "Epoch 601/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.6351e-05 - mean_absolute_error: 0.0101\n",
      "Epoch 00601: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.6098e-05 - mean_absolute_error: 0.0101 - val_loss: 0.0124 - val_mean_absolute_error: 0.1447\n",
      "Epoch 602/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.7822e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00602: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.7733e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0105 - val_mean_absolute_error: 0.1311\n",
      "Epoch 603/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.7424e-05 - mean_absolute_error: 0.0101\n",
      "Epoch 00603: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.7246e-05 - mean_absolute_error: 0.0101 - val_loss: 0.0104 - val_mean_absolute_error: 0.1322\n",
      "Epoch 604/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0095e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00604: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0091e-04 - mean_absolute_error: 0.0103 - val_loss: 0.0123 - val_mean_absolute_error: 0.1469\n",
      "Epoch 605/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.7753e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00605: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.7835e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0151 - val_mean_absolute_error: 0.1626\n",
      "Epoch 606/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.5722e-05 - mean_absolute_error: 0.0101\n",
      "Epoch 00606: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.5830e-05 - mean_absolute_error: 0.0101 - val_loss: 0.0125 - val_mean_absolute_error: 0.1488\n",
      "Epoch 607/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.6890e-05 - mean_absolute_error: 0.0101\n",
      "Epoch 00607: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.7139e-05 - mean_absolute_error: 0.0101 - val_loss: 0.0120 - val_mean_absolute_error: 0.1441\n",
      "Epoch 608/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 1.2283e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00608: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 1.2222e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0157 - val_mean_absolute_error: 0.1639\n",
      "Epoch 609/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.1429e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00609: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.1441e-04 - mean_absolute_error: 0.0106 - val_loss: 0.0148 - val_mean_absolute_error: 0.1609\n",
      "Epoch 610/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.7800e-05 - mean_absolute_error: 0.0100\n",
      "Epoch 00610: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.7800e-05 - mean_absolute_error: 0.0100 - val_loss: 0.0140 - val_mean_absolute_error: 0.1579\n",
      "Epoch 611/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.9242e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00611: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.8979e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0100 - val_mean_absolute_error: 0.1278\n",
      "Epoch 612/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.8734e-05 - mean_absolute_error: 0.0103\n",
      "Epoch 00612: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.8794e-05 - mean_absolute_error: 0.0104 - val_loss: 0.0132 - val_mean_absolute_error: 0.1509\n",
      "Epoch 613/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.2827e-05 - mean_absolute_error: 0.0101\n",
      "Epoch 00613: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.3068e-05 - mean_absolute_error: 0.0101 - val_loss: 0.0151 - val_mean_absolute_error: 0.1625\n",
      "Epoch 614/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0177e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00614: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 1.0166e-04 - mean_absolute_error: 0.0105 - val_loss: 0.0125 - val_mean_absolute_error: 0.1393\n",
      "Epoch 615/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.3279e-05 - mean_absolute_error: 0.0100\n",
      "Epoch 00615: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.3279e-05 - mean_absolute_error: 0.0100 - val_loss: 0.0140 - val_mean_absolute_error: 0.1509\n",
      "Epoch 616/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.6646e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00616: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.6650e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0070 - val_mean_absolute_error: 0.1013\n",
      "Epoch 617/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.7903e-05 - mean_absolute_error: 0.0101\n",
      "Epoch 00617: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.7587e-05 - mean_absolute_error: 0.0101 - val_loss: 0.0153 - val_mean_absolute_error: 0.1637\n",
      "Epoch 618/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.6498e-05 - mean_absolute_error: 0.0100\n",
      "Epoch 00618: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.6498e-05 - mean_absolute_error: 0.0100 - val_loss: 0.0113 - val_mean_absolute_error: 0.1377\n",
      "Epoch 619/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.6252e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00619: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.6252e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0133 - val_mean_absolute_error: 0.1520\n",
      "Epoch 620/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.7693e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00620: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.7397e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0104 - val_mean_absolute_error: 0.1319\n",
      "Epoch 621/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.0804e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00621: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.0804e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0137 - val_mean_absolute_error: 0.1536\n",
      "Epoch 622/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.7523e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00622: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.7523e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0106 - val_mean_absolute_error: 0.1337\n",
      "Epoch 623/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.8662e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00623: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.8662e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0138 - val_mean_absolute_error: 0.1566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 624/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.6392e-05 - mean_absolute_error: 0.0100\n",
      "Epoch 00624: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.6409e-05 - mean_absolute_error: 0.0100 - val_loss: 0.0143 - val_mean_absolute_error: 0.1583\n",
      "Epoch 625/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.4955e-05 - mean_absolute_error: 0.0101\n",
      "Epoch 00625: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.5114e-05 - mean_absolute_error: 0.0101 - val_loss: 0.0130 - val_mean_absolute_error: 0.1424\n",
      "Epoch 626/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.7711e-05 - mean_absolute_error: 0.0102\n",
      "Epoch 00626: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.7688e-05 - mean_absolute_error: 0.0102 - val_loss: 0.0109 - val_mean_absolute_error: 0.1307\n",
      "Epoch 627/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0062e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 00627: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0086e-04 - mean_absolute_error: 0.0101 - val_loss: 0.0093 - val_mean_absolute_error: 0.1201\n",
      "Epoch 628/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.3053e-05 - mean_absolute_error: 0.0100\n",
      "Epoch 00628: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.2358e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0125 - val_mean_absolute_error: 0.1451\n",
      "Epoch 629/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.0497e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00629: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.0513e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0156 - val_mean_absolute_error: 0.1627\n",
      "Epoch 630/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.9723e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00630: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.9802e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0108 - val_mean_absolute_error: 0.1303\n",
      "Epoch 631/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.4042e-05 - mean_absolute_error: 0.0100\n",
      "Epoch 00631: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.4298e-05 - mean_absolute_error: 0.0100 - val_loss: 0.0112 - val_mean_absolute_error: 0.1363\n",
      "Epoch 632/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.1662e-05 - mean_absolute_error: 0.0100\n",
      "Epoch 00632: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.1662e-05 - mean_absolute_error: 0.0100 - val_loss: 0.0110 - val_mean_absolute_error: 0.1347\n",
      "Epoch 633/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0641e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 00633: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 1.0630e-04 - mean_absolute_error: 0.0102 - val_loss: 0.0110 - val_mean_absolute_error: 0.1320\n",
      "Epoch 634/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.7987e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00634: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.7873e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0078 - val_mean_absolute_error: 0.1111\n",
      "Epoch 635/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.1175e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00635: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.1175e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0090 - val_mean_absolute_error: 0.1203\n",
      "Epoch 636/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.8786e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00636: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.8461e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0101 - val_mean_absolute_error: 0.1300\n",
      "Epoch 637/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.2608e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00637: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.2831e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0082 - val_mean_absolute_error: 0.1135\n",
      "Epoch 638/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.4689e-05 - mean_absolute_error: 0.0100\n",
      "Epoch 00638: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.4569e-05 - mean_absolute_error: 0.0100 - val_loss: 0.0092 - val_mean_absolute_error: 0.1214\n",
      "Epoch 639/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.4203e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00639: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.4128e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0072 - val_mean_absolute_error: 0.1040\n",
      "Epoch 640/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.6077e-05 - mean_absolute_error: 0.0100\n",
      "Epoch 00640: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.5988e-05 - mean_absolute_error: 0.0100 - val_loss: 0.0103 - val_mean_absolute_error: 0.1295\n",
      "Epoch 641/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.3210e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00641: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.3210e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0129 - val_mean_absolute_error: 0.1467\n",
      "Epoch 642/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.4425e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00642: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.4236e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0117 - val_mean_absolute_error: 0.1387\n",
      "Epoch 643/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.9500e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00643: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.9500e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0114 - val_mean_absolute_error: 0.1376\n",
      "Epoch 644/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.3045e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00644: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.3045e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0097 - val_mean_absolute_error: 0.1264\n",
      "Epoch 645/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.9768e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00645: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.0217e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0119 - val_mean_absolute_error: 0.1431\n",
      "Epoch 646/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.1450e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00646: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.1450e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0124 - val_mean_absolute_error: 0.1463\n",
      "Epoch 647/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.2252e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00647: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.2252e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0214 - val_mean_absolute_error: 0.2003\n",
      "Epoch 648/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.9609e-05 - mean_absolute_error: 0.0099- ETA: 1s - loss: 1.0289e-04 - mean_\n",
      "Epoch 00648: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.9846e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0133 - val_mean_absolute_error: 0.1515\n",
      "Epoch 649/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.4532e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00649: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.4532e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0158 - val_mean_absolute_error: 0.1699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 650/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.1640e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00650: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.1640e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0124 - val_mean_absolute_error: 0.1440\n",
      "Epoch 651/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.1669e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00651: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.1669e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0099 - val_mean_absolute_error: 0.1281\n",
      "Epoch 652/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.3231e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00652: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.3213e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0129 - val_mean_absolute_error: 0.1473\n",
      "Epoch 653/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.5804e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00653: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.5804e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0108 - val_mean_absolute_error: 0.1354\n",
      "Epoch 654/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.0483e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00654: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.0500e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0115 - val_mean_absolute_error: 0.1372\n",
      "Epoch 655/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.1596e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00655: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.1415e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0140 - val_mean_absolute_error: 0.1573\n",
      "Epoch 656/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.3537e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00656: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 9.3051e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0118 - val_mean_absolute_error: 0.1425\n",
      "Epoch 657/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.9146e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00657: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.9040e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0092 - val_mean_absolute_error: 0.1203\n",
      "Epoch 658/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.6958e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00658: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.6876e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0099 - val_mean_absolute_error: 0.1258\n",
      "Epoch 659/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.0537e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00659: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.0537e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0102 - val_mean_absolute_error: 0.1290\n",
      "Epoch 660/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.8013e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00660: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.7860e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0123 - val_mean_absolute_error: 0.1445\n",
      "Epoch 661/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.1319e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00661: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 9.1319e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0133 - val_mean_absolute_error: 0.1531\n",
      "Epoch 662/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.2844e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00662: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.2844e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0136 - val_mean_absolute_error: 0.1540\n",
      "Epoch 663/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.0900e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00663: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.1380e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0120 - val_mean_absolute_error: 0.1421\n",
      "Epoch 664/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.7375e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00664: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.7375e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0097 - val_mean_absolute_error: 0.1290\n",
      "Epoch 665/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.4221e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00665: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.4126e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0111 - val_mean_absolute_error: 0.1379\n",
      "Epoch 666/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.9915e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00666: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.9936e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0137 - val_mean_absolute_error: 0.1563\n",
      "Epoch 667/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.4344e-05 - mean_absolute_error: 0.0099\n",
      "Epoch 00667: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.4234e-05 - mean_absolute_error: 0.0099 - val_loss: 0.0115 - val_mean_absolute_error: 0.1390\n",
      "Epoch 668/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.3376e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00668: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.3376e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0167 - val_mean_absolute_error: 0.1727\n",
      "Epoch 669/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.0577e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00669: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.0634e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0076 - val_mean_absolute_error: 0.1097\n",
      "Epoch 670/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.2734e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00670: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.2327e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0118 - val_mean_absolute_error: 0.1421\n",
      "Epoch 671/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.3423e-05 - mean_absolute_error: 0.0100\n",
      "Epoch 00671: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.3371e-05 - mean_absolute_error: 0.0100 - val_loss: 0.0130 - val_mean_absolute_error: 0.1512\n",
      "Epoch 672/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.7398e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00672: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.7398e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0123 - val_mean_absolute_error: 0.1455\n",
      "Epoch 673/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.8004e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00673: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.8004e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0159 - val_mean_absolute_error: 0.1675\n",
      "Epoch 674/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.0802e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00674: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.0802e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0142 - val_mean_absolute_error: 0.1578\n",
      "Epoch 675/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.2101e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00675: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.2000e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0096 - val_mean_absolute_error: 0.1254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 676/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.7821e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00676: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.7821e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0154 - val_mean_absolute_error: 0.1660\n",
      "Epoch 677/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.9079e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00677: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.9079e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0134 - val_mean_absolute_error: 0.1508\n",
      "Epoch 678/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.8416e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00678: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.8416e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0169 - val_mean_absolute_error: 0.1736\n",
      "Epoch 679/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.0839e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00679: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.0839e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0109 - val_mean_absolute_error: 0.1357\n",
      "Epoch 680/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.6525e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00680: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.6280e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0156 - val_mean_absolute_error: 0.1611\n",
      "Epoch 681/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.7788e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00681: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.7698e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0099 - val_mean_absolute_error: 0.1277\n",
      "Epoch 682/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.7267e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00682: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.7299e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0114 - val_mean_absolute_error: 0.1361\n",
      "Epoch 683/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.3717e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00683: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.3645e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0137 - val_mean_absolute_error: 0.1547\n",
      "Epoch 684/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.8794e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00684: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.8794e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0110 - val_mean_absolute_error: 0.1348\n",
      "Epoch 685/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.3677e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00685: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.3376e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0090 - val_mean_absolute_error: 0.1190\n",
      "Epoch 686/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.3979e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00686: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.3724e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0115 - val_mean_absolute_error: 0.1384\n",
      "Epoch 687/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.9995e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00687: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.9440e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0146 - val_mean_absolute_error: 0.1596\n",
      "Epoch 688/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.7616e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00688: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.7519e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0121 - val_mean_absolute_error: 0.1425\n",
      "Epoch 689/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.1649e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00689: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.1572e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0137 - val_mean_absolute_error: 0.1525\n",
      "Epoch 690/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.0417e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00690: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.0821e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0156 - val_mean_absolute_error: 0.1630\n",
      "Epoch 691/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.8343e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00691: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.8256e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0146 - val_mean_absolute_error: 0.1594\n",
      "Epoch 692/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.2369e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00692: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.2388e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0159 - val_mean_absolute_error: 0.1666\n",
      "Epoch 693/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.5077e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00693: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.5564e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0152 - val_mean_absolute_error: 0.1626\n",
      "Epoch 694/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.9317e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00694: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.9190e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0141 - val_mean_absolute_error: 0.1582\n",
      "Epoch 695/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.7787e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00695: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.7440e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0142 - val_mean_absolute_error: 0.1586\n",
      "Epoch 696/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.1316e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00696: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.0939e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0105 - val_mean_absolute_error: 0.1302\n",
      "Epoch 697/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.8351e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00697: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.8270e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0151 - val_mean_absolute_error: 0.1621\n",
      "Epoch 698/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.4416e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00698: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.4443e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0127 - val_mean_absolute_error: 0.1470\n",
      "Epoch 699/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.7844e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00699: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 8.7861e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0114 - val_mean_absolute_error: 0.1351\n",
      "Epoch 700/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 9.1757e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00700: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.1662e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0115 - val_mean_absolute_error: 0.1371\n",
      "Epoch 701/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.5471e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00701: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 9.5471e-05 - mean_absolute_error: 0.0097 - val_loss: 0.0123 - val_mean_absolute_error: 0.1440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 702/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.6383e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00702: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.6383e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0105 - val_mean_absolute_error: 0.1302\n",
      "Epoch 703/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.7298e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00703: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.7298e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0151 - val_mean_absolute_error: 0.1622\n",
      "Epoch 704/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.7533e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00704: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.7533e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0097 - val_mean_absolute_error: 0.1241\n",
      "Epoch 705/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.5712e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00705: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.5632e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0104 - val_mean_absolute_error: 0.1304\n",
      "Epoch 706/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.2926e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00706: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.2926e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0130 - val_mean_absolute_error: 0.1486\n",
      "Epoch 707/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.7028e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00707: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.7513e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0097 - val_mean_absolute_error: 0.1255\n",
      "Epoch 708/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.3152e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00708: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.2924e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0080 - val_mean_absolute_error: 0.1095\n",
      "Epoch 709/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.3825e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00709: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.3802e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0065 - val_mean_absolute_error: 0.0973\n",
      "Epoch 710/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.5775e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00710: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.5281e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0086 - val_mean_absolute_error: 0.1167\n",
      "Epoch 711/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.4369e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00711: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.4369e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0111 - val_mean_absolute_error: 0.1388\n",
      "Epoch 712/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.1293e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00712: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.1221e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0077 - val_mean_absolute_error: 0.1105\n",
      "Epoch 713/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.7387e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00713: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.7431e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0121 - val_mean_absolute_error: 0.1425\n",
      "Epoch 714/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 9.2270e-05 - mean_absolute_error: 0.0097\n",
      "Epoch 00714: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 9.2954e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0126 - val_mean_absolute_error: 0.1474\n",
      "Epoch 715/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.6882e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00715: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.6639e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0105 - val_mean_absolute_error: 0.1327\n",
      "Epoch 716/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.9648e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00716: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.9648e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0108 - val_mean_absolute_error: 0.1348\n",
      "Epoch 717/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.5669e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00717: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.5483e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0080 - val_mean_absolute_error: 0.1142\n",
      "Epoch 718/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.3188e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00718: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.2733e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0084 - val_mean_absolute_error: 0.1152\n",
      "Epoch 719/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.3073e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00719: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.3172e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0079 - val_mean_absolute_error: 0.1115\n",
      "Epoch 720/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.5950e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00720: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.5424e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0121 - val_mean_absolute_error: 0.1445\n",
      "Epoch 721/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.1778e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00721: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.1776e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0090 - val_mean_absolute_error: 0.1226\n",
      "Epoch 722/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.1175e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00722: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 8.0902e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0123 - val_mean_absolute_error: 0.1434\n",
      "Epoch 723/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.4991e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00723: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 8.4879e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0106 - val_mean_absolute_error: 0.1315\n",
      "Epoch 724/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.0530e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00724: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 8.1405e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0121 - val_mean_absolute_error: 0.1423\n",
      "Epoch 725/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 8.1804e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00725: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 8.1319e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0126 - val_mean_absolute_error: 0.1488\n",
      "Epoch 726/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.2840e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00726: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.2840e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0133 - val_mean_absolute_error: 0.1514\n",
      "Epoch 727/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.2805e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00727: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.2922e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0113 - val_mean_absolute_error: 0.1352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.8193e-05 - mean_absolute_error: 0.0098\n",
      "Epoch 00728: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.8193e-05 - mean_absolute_error: 0.0098 - val_loss: 0.0131 - val_mean_absolute_error: 0.1488\n",
      "Epoch 729/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.4695e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00729: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.4669e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0120 - val_mean_absolute_error: 0.1417\n",
      "Epoch 730/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.7218e-05 - mean_absolute_error: 0.0096\n",
      "Epoch 00730: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.7218e-05 - mean_absolute_error: 0.0096 - val_loss: 0.0115 - val_mean_absolute_error: 0.1383\n",
      "Epoch 731/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.3894e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00731: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 8.3782e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0092 - val_mean_absolute_error: 0.1208\n",
      "Epoch 732/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.4241e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00732: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.4241e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0124 - val_mean_absolute_error: 0.1464\n",
      "Epoch 733/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.4280e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00733: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.4173e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0103 - val_mean_absolute_error: 0.1313\n",
      "Epoch 734/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.5405e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00734: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.5284e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0126 - val_mean_absolute_error: 0.1447\n",
      "Epoch 735/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.1534e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00735: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.1534e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0159 - val_mean_absolute_error: 0.1658\n",
      "Epoch 736/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.4716e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00736: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.4313e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0117 - val_mean_absolute_error: 0.1398\n",
      "Epoch 737/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.3645e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00737: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.3645e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0120 - val_mean_absolute_error: 0.1437\n",
      "Epoch 738/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.1012e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00738: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.1152e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0135 - val_mean_absolute_error: 0.1537\n",
      "Epoch 739/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.8132e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00739: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 7.8026e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0115 - val_mean_absolute_error: 0.1374\n",
      "Epoch 740/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.5633e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00740: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.5648e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0080 - val_mean_absolute_error: 0.1128\n",
      "Epoch 741/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.1279e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00741: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.1883e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0187 - val_mean_absolute_error: 0.1865\n",
      "Epoch 742/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.2475e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00742: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.2475e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0101 - val_mean_absolute_error: 0.1294\n",
      "Epoch 743/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.3743e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00743: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.3743e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0184 - val_mean_absolute_error: 0.1831\n",
      "Epoch 744/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.7185e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00744: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 8.7185e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0125 - val_mean_absolute_error: 0.1477\n",
      "Epoch 745/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.4548e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00745: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.4548e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0149 - val_mean_absolute_error: 0.1641\n",
      "Epoch 746/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.3220e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00746: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.3220e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0108 - val_mean_absolute_error: 0.1361\n",
      "Epoch 747/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.2601e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00747: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.2601e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0105 - val_mean_absolute_error: 0.1328\n",
      "Epoch 748/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.2420e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00748: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.2420e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0170 - val_mean_absolute_error: 0.1746\n",
      "Epoch 749/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.1789e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00749: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.1789e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0098 - val_mean_absolute_error: 0.1307\n",
      "Epoch 750/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.9005e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00750: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 7.9005e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0079 - val_mean_absolute_error: 0.1123\n",
      "Epoch 751/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8264e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00751: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 7.8264e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0125 - val_mean_absolute_error: 0.1487\n",
      "Epoch 752/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.1604e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00752: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 8.1605e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0099 - val_mean_absolute_error: 0.1267\n",
      "Epoch 753/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.2597e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00753: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.2299e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0131 - val_mean_absolute_error: 0.1467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 754/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 8.2441e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00754: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 8.2322e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0100 - val_mean_absolute_error: 0.1304\n",
      "Epoch 755/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.5704e-05 - mean_absolute_error: 0.0095\n",
      "Epoch 00755: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 8.5578e-05 - mean_absolute_error: 0.0095 - val_loss: 0.0080 - val_mean_absolute_error: 0.1124\n",
      "Epoch 756/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.5963e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00756: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 8.5848e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0093 - val_mean_absolute_error: 0.1229\n",
      "Epoch 757/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.7884e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00757: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 7.7847e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0090 - val_mean_absolute_error: 0.1211\n",
      "Epoch 758/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.4225e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00758: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.4225e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0139 - val_mean_absolute_error: 0.1571\n",
      "Epoch 759/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.1007e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00759: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.1023e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0116 - val_mean_absolute_error: 0.1404\n",
      "Epoch 760/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.2978e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00760: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.2978e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0077 - val_mean_absolute_error: 0.1105\n",
      "Epoch 761/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.0678e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00761: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.0574e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0095 - val_mean_absolute_error: 0.1266\n",
      "Epoch 762/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.2310e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00762: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.2310e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0111 - val_mean_absolute_error: 0.1377\n",
      "Epoch 763/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5689e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00763: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5689e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0112 - val_mean_absolute_error: 0.1379\n",
      "Epoch 764/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.5277e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00764: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.5277e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0159 - val_mean_absolute_error: 0.1701\n",
      "Epoch 765/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.8728e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00765: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.8772e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0079 - val_mean_absolute_error: 0.1122\n",
      "Epoch 766/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.0987e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00766: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.0987e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0099 - val_mean_absolute_error: 0.1294\n",
      "Epoch 767/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.9150e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00767: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.9085e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0080 - val_mean_absolute_error: 0.1129\n",
      "Epoch 768/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.8581e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00768: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8526e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0077 - val_mean_absolute_error: 0.1092\n",
      "Epoch 769/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.9951e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00769: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.0204e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0124 - val_mean_absolute_error: 0.1477\n",
      "Epoch 770/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.4270e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00770: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.4181e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0125 - val_mean_absolute_error: 0.1436\n",
      "Epoch 771/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.1753e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00771: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.1951e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0165 - val_mean_absolute_error: 0.1725\n",
      "Epoch 772/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.7757e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00772: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8411e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0077 - val_mean_absolute_error: 0.1068\n",
      "Epoch 773/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8874e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00773: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8874e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0075 - val_mean_absolute_error: 0.1077\n",
      "Epoch 774/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.3421e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00774: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.3156e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0090 - val_mean_absolute_error: 0.1200\n",
      "Epoch 775/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.6903e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00775: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.6903e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0150 - val_mean_absolute_error: 0.1615\n",
      "Epoch 776/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7627e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00776: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.7627e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0106 - val_mean_absolute_error: 0.1323\n",
      "Epoch 777/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.0204e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00777: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.0204e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0121 - val_mean_absolute_error: 0.1451\n",
      "Epoch 778/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.9843e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00778: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.9751e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0103 - val_mean_absolute_error: 0.1284\n",
      "Epoch 779/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.2008e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00779: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 8.2008e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0148 - val_mean_absolute_error: 0.1640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 9.0166e-05 - mean_absolute_error: 0.0094\n",
      "Epoch 00780: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 9.0166e-05 - mean_absolute_error: 0.0094 - val_loss: 0.0102 - val_mean_absolute_error: 0.1308\n",
      "Epoch 781/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.2799e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00781: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.2799e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0105 - val_mean_absolute_error: 0.1315\n",
      "Epoch 782/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8029e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00782: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8029e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0095 - val_mean_absolute_error: 0.1245\n",
      "Epoch 783/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.1657e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00783: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.1657e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0105 - val_mean_absolute_error: 0.1329\n",
      "Epoch 784/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.1396e-05 - mean_absolute_error: 0.0093\n",
      "Epoch 00784: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.1432e-05 - mean_absolute_error: 0.0093 - val_loss: 0.0123 - val_mean_absolute_error: 0.1437\n",
      "Epoch 785/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.2743e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00785: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.2743e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0113 - val_mean_absolute_error: 0.1406\n",
      "Epoch 786/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8764e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00786: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8764e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0129 - val_mean_absolute_error: 0.1485\n",
      "Epoch 787/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.0436e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00787: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.0436e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0109 - val_mean_absolute_error: 0.1369\n",
      "Epoch 788/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.0067e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00788: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.0067e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0091 - val_mean_absolute_error: 0.1185\n",
      "Epoch 789/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7757e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00789: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.7757e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0149 - val_mean_absolute_error: 0.1627\n",
      "Epoch 790/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.7685e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00790: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 7.7315e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0168 - val_mean_absolute_error: 0.1728\n",
      "Epoch 791/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.9069e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00791: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.9069e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0117 - val_mean_absolute_error: 0.1349\n",
      "Epoch 792/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8349e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00792: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8349e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0125 - val_mean_absolute_error: 0.1438\n",
      "Epoch 793/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8083e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00793: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8083e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0136 - val_mean_absolute_error: 0.1539\n",
      "Epoch 794/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8033e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00794: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8033e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0103 - val_mean_absolute_error: 0.1299\n",
      "Epoch 795/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2573e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00795: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2573e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0129 - val_mean_absolute_error: 0.1477\n",
      "Epoch 796/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.0028e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00796: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.0028e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0133 - val_mean_absolute_error: 0.1493\n",
      "Epoch 797/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7957e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00797: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.7957e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0127 - val_mean_absolute_error: 0.1470\n",
      "Epoch 798/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.9316e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00798: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.9253e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0105 - val_mean_absolute_error: 0.1293\n",
      "Epoch 799/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.8436e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00799: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.8381e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0105 - val_mean_absolute_error: 0.1313\n",
      "Epoch 800/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.0040e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00800: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.0040e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0080 - val_mean_absolute_error: 0.1107\n",
      "Epoch 801/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.9398e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00801: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.9375e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0100 - val_mean_absolute_error: 0.1263\n",
      "Epoch 802/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.4224e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00802: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.4224e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0118 - val_mean_absolute_error: 0.1403\n",
      "Epoch 803/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.8015e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00803: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8128e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0094 - val_mean_absolute_error: 0.1257\n",
      "Epoch 804/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.9710e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00804: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.9612e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0134 - val_mean_absolute_error: 0.1520\n",
      "Epoch 805/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6633e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00805: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.6633e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0140 - val_mean_absolute_error: 0.1565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 806/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.4839e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00806: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4839e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0140 - val_mean_absolute_error: 0.1550\n",
      "Epoch 807/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.7704e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00807: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.7680e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0100 - val_mean_absolute_error: 0.1280\n",
      "Epoch 808/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 8.1871e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00808: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.1765e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0133 - val_mean_absolute_error: 0.1507\n",
      "Epoch 809/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.1496e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00809: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.1496e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0095 - val_mean_absolute_error: 0.1245\n",
      "Epoch 810/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.7466e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00810: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.7574e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0066 - val_mean_absolute_error: 0.0975\n",
      "Epoch 811/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.3390e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00811: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.3939e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0127 - val_mean_absolute_error: 0.1471\n",
      "Epoch 812/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.9765e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00812: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.9765e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0143 - val_mean_absolute_error: 0.1543\n",
      "Epoch 813/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8567e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00813: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8567e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0107 - val_mean_absolute_error: 0.1295\n",
      "Epoch 814/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7505e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00814: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.7505e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0105 - val_mean_absolute_error: 0.1271\n",
      "Epoch 815/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.9331e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00815: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.9331e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0098 - val_mean_absolute_error: 0.1251\n",
      "Epoch 816/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.7548e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00816: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.7548e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0215 - val_mean_absolute_error: 0.1753\n",
      "Epoch 817/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6231e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00817: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.6231e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0212 - val_mean_absolute_error: 0.1830\n",
      "Epoch 818/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.9375e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00818: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.9375e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0181 - val_mean_absolute_error: 0.1542\n",
      "Epoch 819/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5958e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00819: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5958e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0151 - val_mean_absolute_error: 0.1539\n",
      "Epoch 820/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.7714e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00820: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.7437e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0128 - val_mean_absolute_error: 0.1469\n",
      "Epoch 821/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.3716e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00821: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.3751e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0157 - val_mean_absolute_error: 0.1600\n",
      "Epoch 822/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8010e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00822: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.8010e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0107 - val_mean_absolute_error: 0.1300\n",
      "Epoch 823/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.9500e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00823: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.9500e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0109 - val_mean_absolute_error: 0.1308\n",
      "Epoch 824/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7608e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00824: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.7608e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0157 - val_mean_absolute_error: 0.1658\n",
      "Epoch 825/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7550e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00825: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.7550e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0111 - val_mean_absolute_error: 0.1327\n",
      "Epoch 826/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.9240e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00826: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.9240e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0087 - val_mean_absolute_error: 0.1184\n",
      "Epoch 827/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8457e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00827: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.8457e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0126 - val_mean_absolute_error: 0.1478\n",
      "Epoch 828/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8222e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00828: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.8222e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0103 - val_mean_absolute_error: 0.1329\n",
      "Epoch 829/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8621e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00829: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8621e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0123 - val_mean_absolute_error: 0.1362\n",
      "Epoch 830/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7707e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00830: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.7707e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0093 - val_mean_absolute_error: 0.1240\n",
      "Epoch 831/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8570e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00831: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.8570e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0133 - val_mean_absolute_error: 0.1514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 832/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.4019e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 00832: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.4019e-05 - mean_absolute_error: 0.0092 - val_loss: 0.0164 - val_mean_absolute_error: 0.1609\n",
      "Epoch 833/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.9744e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00833: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.9744e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0134 - val_mean_absolute_error: 0.1506\n",
      "Epoch 834/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3031e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00834: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.3031e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0106 - val_mean_absolute_error: 0.1332\n",
      "Epoch 835/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.8792e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00835: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8775e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0095 - val_mean_absolute_error: 0.1231\n",
      "Epoch 836/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.0518e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00836: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.0518e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0127 - val_mean_absolute_error: 0.1335\n",
      "Epoch 837/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.6672e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00837: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.6478e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0095 - val_mean_absolute_error: 0.1255\n",
      "Epoch 838/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6420e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00838: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.6420e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0125 - val_mean_absolute_error: 0.1414\n",
      "Epoch 839/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.4428e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00839: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4336e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0183 - val_mean_absolute_error: 0.1572\n",
      "Epoch 840/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.4277e-05 - mean_absolute_error: 0.0088- ETA: 1s - loss: 7.7919e-05 - me\n",
      "Epoch 00840: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.4277e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0079 - val_mean_absolute_error: 0.1098\n",
      "Epoch 841/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6672e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00841: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.6672e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0148 - val_mean_absolute_error: 0.1617\n",
      "Epoch 842/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5870e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00842: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.5870e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0120 - val_mean_absolute_error: 0.1450\n",
      "Epoch 843/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.3515e-05 - mean_absolute_error: 0.0091\n",
      "Epoch 00843: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 8.3515e-05 - mean_absolute_error: 0.0091 - val_loss: 0.0140 - val_mean_absolute_error: 0.1562\n",
      "Epoch 844/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6802e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00844: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.6802e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0133 - val_mean_absolute_error: 0.1510\n",
      "Epoch 845/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.9318e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00845: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.9318e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0099 - val_mean_absolute_error: 0.1271\n",
      "Epoch 846/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.7705e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00846: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.7287e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0144 - val_mean_absolute_error: 0.1604\n",
      "Epoch 847/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8445e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00847: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8445e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0158 - val_mean_absolute_error: 0.1684\n",
      "Epoch 848/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7243e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00848: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.7243e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0133 - val_mean_absolute_error: 0.1469\n",
      "Epoch 849/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.8299e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00849: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8189e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0118 - val_mean_absolute_error: 0.1301\n",
      "Epoch 850/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.4357e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00850: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4357e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0113 - val_mean_absolute_error: 0.1374\n",
      "Epoch 851/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.4321e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00851: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4321e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0102 - val_mean_absolute_error: 0.1280\n",
      "Epoch 852/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6603e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00852: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.6603e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0129 - val_mean_absolute_error: 0.1502\n",
      "Epoch 853/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2752e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00853: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.2752e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0099 - val_mean_absolute_error: 0.1260\n",
      "Epoch 854/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7409e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00854: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.7409e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0123 - val_mean_absolute_error: 0.1454\n",
      "Epoch 855/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5754e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00855: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5754e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0119 - val_mean_absolute_error: 0.1407\n",
      "Epoch 856/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5583e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00856: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5583e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0137 - val_mean_absolute_error: 0.1529\n",
      "Epoch 857/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7997e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00857: val_loss did not improve from 0.00023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 21ms/step - loss: 7.7997e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0140 - val_mean_absolute_error: 0.1568\n",
      "Epoch 858/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3087e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00858: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 7.3087e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0172 - val_mean_absolute_error: 0.1633\n",
      "Epoch 859/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3719e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00859: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.3719e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0108 - val_mean_absolute_error: 0.1341\n",
      "Epoch 860/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.4157e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00860: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4141e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0129 - val_mean_absolute_error: 0.1416\n",
      "Epoch 861/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.3626e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00861: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.3587e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0075 - val_mean_absolute_error: 0.1036\n",
      "Epoch 862/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6523e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00862: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.6523e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0136 - val_mean_absolute_error: 0.1541\n",
      "Epoch 863/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7791e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00863: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.7791e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0096 - val_mean_absolute_error: 0.1262\n",
      "Epoch 864/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7368e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00864: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.7368e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0109 - val_mean_absolute_error: 0.1349\n",
      "Epoch 865/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5284e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00865: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.5284e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0134 - val_mean_absolute_error: 0.1479\n",
      "Epoch 866/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.5187e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00866: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4688e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0170 - val_mean_absolute_error: 0.1539\n",
      "Epoch 867/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.3436e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00867: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3538e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0129 - val_mean_absolute_error: 0.1357\n",
      "Epoch 868/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8032e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00868: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8032e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0225 - val_mean_absolute_error: 0.1813\n",
      "Epoch 869/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2252e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00869: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2252e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0104 - val_mean_absolute_error: 0.1247\n",
      "Epoch 870/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6798e-05 - mean_absolute_error: 0.0090\n",
      "Epoch 00870: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.6798e-05 - mean_absolute_error: 0.0090 - val_loss: 0.0119 - val_mean_absolute_error: 0.1402\n",
      "Epoch 871/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3406e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00871: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3406e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0100 - val_mean_absolute_error: 0.1248\n",
      "Epoch 872/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 8.1519e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00872: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.1309e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0111 - val_mean_absolute_error: 0.1357\n",
      "Epoch 873/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7211e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00873: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.7211e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0097 - val_mean_absolute_error: 0.1271\n",
      "Epoch 874/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3377e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00874: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3377e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0167 - val_mean_absolute_error: 0.1391\n",
      "Epoch 875/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 8.2571e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00875: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 8.2571e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0140 - val_mean_absolute_error: 0.1512\n",
      "Epoch 876/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.7233e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00876: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.7125e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0160 - val_mean_absolute_error: 0.1514\n",
      "Epoch 877/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 7.3830e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00877: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4429e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0199 - val_mean_absolute_error: 0.1658\n",
      "Epoch 878/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.4916e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00878: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.4916e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0237 - val_mean_absolute_error: 0.1905\n",
      "Epoch 879/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2797e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00879: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.2797e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0137 - val_mean_absolute_error: 0.1356\n",
      "Epoch 880/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.5039e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00880: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.5132e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0099 - val_mean_absolute_error: 0.1215\n",
      "Epoch 881/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1589e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00881: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1589e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0089 - val_mean_absolute_error: 0.1199\n",
      "Epoch 882/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.4651e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00882: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4548e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0163 - val_mean_absolute_error: 0.1588\n",
      "Epoch 883/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.7408e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00883: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.7408e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0122 - val_mean_absolute_error: 0.1346\n",
      "Epoch 884/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.4261e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00884: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4568e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0137 - val_mean_absolute_error: 0.1502\n",
      "Epoch 885/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1075e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00885: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1075e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0171 - val_mean_absolute_error: 0.1615\n",
      "Epoch 886/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6999e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00886: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.6999e-05 - mean_absolute_error: 0.0089 - val_loss: 0.0156 - val_mean_absolute_error: 0.1354\n",
      "Epoch 887/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1112e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00887: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.1112e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0094 - val_mean_absolute_error: 0.1180\n",
      "Epoch 888/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2290e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00888: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2290e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0122 - val_mean_absolute_error: 0.1396\n",
      "Epoch 889/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.4303e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00889: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4296e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0111 - val_mean_absolute_error: 0.1299\n",
      "Epoch 890/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3588e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00890: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3588e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0097 - val_mean_absolute_error: 0.1248\n",
      "Epoch 891/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.4493e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00891: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4493e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0099 - val_mean_absolute_error: 0.1268\n",
      "Epoch 892/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5186e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00892: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5186e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0134 - val_mean_absolute_error: 0.1405\n",
      "Epoch 893/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2282e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00893: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.2282e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0123 - val_mean_absolute_error: 0.1303\n",
      "Epoch 894/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2800e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00894: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.2800e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0126 - val_mean_absolute_error: 0.1452\n",
      "Epoch 895/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3967e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00895: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3967e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0165 - val_mean_absolute_error: 0.1490\n",
      "Epoch 896/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6543e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00896: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.6543e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0136 - val_mean_absolute_error: 0.1364\n",
      "Epoch 897/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.4556e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00897: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.4525e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0156 - val_mean_absolute_error: 0.1349\n",
      "Epoch 898/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2953e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00898: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2953e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0127 - val_mean_absolute_error: 0.1280\n",
      "Epoch 899/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1825e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00899: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1825e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0117 - val_mean_absolute_error: 0.1390\n",
      "Epoch 900/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1950e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00900: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1950e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0166 - val_mean_absolute_error: 0.1559\n",
      "Epoch 901/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5087e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00901: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5087e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0130 - val_mean_absolute_error: 0.1427\n",
      "Epoch 902/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.9484e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00902: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.9428e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0174 - val_mean_absolute_error: 0.1611\n",
      "Epoch 903/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0790e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00903: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0790e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0204 - val_mean_absolute_error: 0.1749\n",
      "Epoch 904/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5074e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00904: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5074e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0141 - val_mean_absolute_error: 0.1417\n",
      "Epoch 905/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.5412e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 00905: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5247e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0196 - val_mean_absolute_error: 0.1646\n",
      "Epoch 906/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.4491e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00906: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4491e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0120 - val_mean_absolute_error: 0.1407\n",
      "Epoch 907/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8670e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00907: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8670e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0155 - val_mean_absolute_error: 0.1449\n",
      "Epoch 908/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2407e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00908: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2407e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0155 - val_mean_absolute_error: 0.1425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 909/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.5705e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00909: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.5489e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0170 - val_mean_absolute_error: 0.1563\n",
      "Epoch 910/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5099e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00910: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.5099e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0164 - val_mean_absolute_error: 0.1496\n",
      "Epoch 911/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0790e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00911: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.0790e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0181 - val_mean_absolute_error: 0.1571\n",
      "Epoch 912/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.9505e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00912: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.9403e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0229 - val_mean_absolute_error: 0.1748\n",
      "Epoch 913/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3455e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00913: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3455e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0162 - val_mean_absolute_error: 0.1715\n",
      "Epoch 914/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.4442e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00914: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4504e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0187 - val_mean_absolute_error: 0.1563\n",
      "Epoch 915/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.4931e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00915: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4931e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0124 - val_mean_absolute_error: 0.1402\n",
      "Epoch 916/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.1630e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00916: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.1755e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0141 - val_mean_absolute_error: 0.1586\n",
      "Epoch 917/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0140e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00917: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.0140e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0089 - val_mean_absolute_error: 0.1120\n",
      "Epoch 918/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5444e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00918: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5444e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0148 - val_mean_absolute_error: 0.1482\n",
      "Epoch 919/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.9913e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00919: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9981e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0101 - val_mean_absolute_error: 0.1247\n",
      "Epoch 920/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.7372e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00920: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7288e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0114 - val_mean_absolute_error: 0.1376\n",
      "Epoch 921/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8346e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00921: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8346e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0152 - val_mean_absolute_error: 0.1625\n",
      "Epoch 922/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9236e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00922: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.9236e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0168 - val_mean_absolute_error: 0.1525\n",
      "Epoch 923/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3684e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00923: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3684e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0099 - val_mean_absolute_error: 0.1254\n",
      "Epoch 924/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6846e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00924: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.6846e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0090 - val_mean_absolute_error: 0.1093\n",
      "Epoch 925/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.4465e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00925: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4465e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0124 - val_mean_absolute_error: 0.1373\n",
      "Epoch 926/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1384e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00926: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1384e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0146 - val_mean_absolute_error: 0.1516\n",
      "Epoch 927/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.2066e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00927: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 7.2245e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0119 - val_mean_absolute_error: 0.1416\n",
      "Epoch 928/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.3516e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00928: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3551e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0152 - val_mean_absolute_error: 0.1636\n",
      "Epoch 929/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.1024e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00929: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1245e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0097 - val_mean_absolute_error: 0.1243\n",
      "Epoch 930/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1073e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00930: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1073e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0145 - val_mean_absolute_error: 0.1583\n",
      "Epoch 931/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.4595e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00931: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.4595e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0082 - val_mean_absolute_error: 0.1144\n",
      "Epoch 932/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2214e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00932: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.2214e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0124 - val_mean_absolute_error: 0.1449\n",
      "Epoch 933/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.5242e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00933: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5156e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0177 - val_mean_absolute_error: 0.1547\n",
      "Epoch 934/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.0250e-05 - mean_absolute_error: 0.0085- ETA: 1s - loss: 7.5481e-05 - mean_abso\n",
      "Epoch 00934: val_loss did not improve from 0.00023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0258e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0116 - val_mean_absolute_error: 0.1396\n",
      "Epoch 935/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3823e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00935: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.3823e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0126 - val_mean_absolute_error: 0.1456\n",
      "Epoch 936/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2505e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00936: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2505e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0121 - val_mean_absolute_error: 0.1413\n",
      "Epoch 937/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.8243e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00937: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8259e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0121 - val_mean_absolute_error: 0.1447\n",
      "Epoch 938/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 6.9260e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00938: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9133e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0105 - val_mean_absolute_error: 0.1315\n",
      "Epoch 939/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.8522e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00939: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8443e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0131 - val_mean_absolute_error: 0.1495\n",
      "Epoch 940/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1920e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00940: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1920e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0090 - val_mean_absolute_error: 0.1204\n",
      "Epoch 941/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3121e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00941: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3121e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0111 - val_mean_absolute_error: 0.1374\n",
      "Epoch 942/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.4154e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00942: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4154e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0138 - val_mean_absolute_error: 0.1556\n",
      "Epoch 943/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1063e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00943: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.1063e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0128 - val_mean_absolute_error: 0.1493\n",
      "Epoch 944/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2791e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00944: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2791e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0083 - val_mean_absolute_error: 0.1137\n",
      "Epoch 945/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.8669e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00945: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8668e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0154 - val_mean_absolute_error: 0.1663\n",
      "Epoch 946/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2800e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00946: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2800e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0073 - val_mean_absolute_error: 0.1066\n",
      "Epoch 947/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1776e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00947: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.1776e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0108 - val_mean_absolute_error: 0.1303\n",
      "Epoch 948/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.9292e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00948: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.9365e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0129 - val_mean_absolute_error: 0.1514\n",
      "Epoch 949/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.4651e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00949: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.4629e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0111 - val_mean_absolute_error: 0.1341\n",
      "Epoch 950/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2200e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00950: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2200e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0166 - val_mean_absolute_error: 0.1732\n",
      "Epoch 951/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0711e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00951: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0711e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0156 - val_mean_absolute_error: 0.1677\n",
      "Epoch 952/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5038e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00952: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5038e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0114 - val_mean_absolute_error: 0.1404\n",
      "Epoch 953/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3251e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00953: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3251e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0149 - val_mean_absolute_error: 0.1633\n",
      "Epoch 954/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.6117e-05 - mean_absolute_error: 0.0088\n",
      "Epoch 00954: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.6117e-05 - mean_absolute_error: 0.0088 - val_loss: 0.0114 - val_mean_absolute_error: 0.1388\n",
      "Epoch 955/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3055e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00955: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3055e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0105 - val_mean_absolute_error: 0.1317\n",
      "Epoch 956/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1111e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00956: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1111e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0092 - val_mean_absolute_error: 0.1228\n",
      "Epoch 957/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1743e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00957: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1743e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0101 - val_mean_absolute_error: 0.1293\n",
      "Epoch 958/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1661e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00958: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1661e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0074 - val_mean_absolute_error: 0.1079\n",
      "Epoch 959/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0138e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00959: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0138e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0091 - val_mean_absolute_error: 0.1243\n",
      "Epoch 960/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.9366e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00960: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9916e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0211 - val_mean_absolute_error: 0.1791\n",
      "Epoch 961/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1900e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00961: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.1900e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0084 - val_mean_absolute_error: 0.1172\n",
      "Epoch 962/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2223e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00962: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.2223e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0101 - val_mean_absolute_error: 0.1305\n",
      "Epoch 963/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0129e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00963: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0129e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0164 - val_mean_absolute_error: 0.1464\n",
      "Epoch 964/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.0243e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00964: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.0047e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0114 - val_mean_absolute_error: 0.1403\n",
      "Epoch 965/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2817e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00965: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2817e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0152 - val_mean_absolute_error: 0.1531\n",
      "Epoch 966/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.3681e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00966: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.3681e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0098 - val_mean_absolute_error: 0.1114\n",
      "Epoch 967/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9397e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00967: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9397e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0151 - val_mean_absolute_error: 0.1525\n",
      "Epoch 968/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0230e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00968: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0230e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0136 - val_mean_absolute_error: 0.1440\n",
      "Epoch 969/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9839e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00969: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9839e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0161 - val_mean_absolute_error: 0.1403\n",
      "Epoch 970/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.8349e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00970: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8273e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0162 - val_mean_absolute_error: 0.1448\n",
      "Epoch 971/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1449e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00971: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1449e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0158 - val_mean_absolute_error: 0.1666\n",
      "Epoch 972/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9036e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00972: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9036e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0114 - val_mean_absolute_error: 0.1345\n",
      "Epoch 973/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7501e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 00973: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7501e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0172 - val_mean_absolute_error: 0.1756\n",
      "Epoch 974/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0589e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00974: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0589e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0129 - val_mean_absolute_error: 0.1484\n",
      "Epoch 975/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 7.1060e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00975: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.1172e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0167 - val_mean_absolute_error: 0.1387\n",
      "Epoch 976/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7697e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00976: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.7697e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0207 - val_mean_absolute_error: 0.1689\n",
      "Epoch 977/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5626e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 00977: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5626e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0187 - val_mean_absolute_error: 0.1584\n",
      "Epoch 978/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8707e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00978: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8707e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0129 - val_mean_absolute_error: 0.1352\n",
      "Epoch 979/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8891e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00979: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8891e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0177 - val_mean_absolute_error: 0.1557\n",
      "Epoch 980/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1085e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00980: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.1085e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0231 - val_mean_absolute_error: 0.1865\n",
      "Epoch 981/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1199e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00981: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1199e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0151 - val_mean_absolute_error: 0.1457\n",
      "Epoch 982/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8624e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00982: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8624e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0136 - val_mean_absolute_error: 0.1446\n",
      "Epoch 983/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.0839e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00983: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.0835e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0159 - val_mean_absolute_error: 0.1461\n",
      "Epoch 984/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5439e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 00984: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.5439e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0126 - val_mean_absolute_error: 0.1425\n",
      "Epoch 985/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4163e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 00985: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4163e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0097 - val_mean_absolute_error: 0.1256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 986/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0512e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00986: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.0512e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0102 - val_mean_absolute_error: 0.1299\n",
      "Epoch 987/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.6804e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 00987: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6597e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0132 - val_mean_absolute_error: 0.1449\n",
      "Epoch 988/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.7793e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00988: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.7849e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0149 - val_mean_absolute_error: 0.1607\n",
      "Epoch 989/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1615e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00989: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1615e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0101 - val_mean_absolute_error: 0.1298\n",
      "Epoch 990/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.2354e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00990: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2415e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0095 - val_mean_absolute_error: 0.1135\n",
      "Epoch 991/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9407e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00991: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9407e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0114 - val_mean_absolute_error: 0.1385\n",
      "Epoch 992/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8202e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00992: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8202e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0105 - val_mean_absolute_error: 0.1319\n",
      "Epoch 993/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1859e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00993: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1859e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0116 - val_mean_absolute_error: 0.1409\n",
      "Epoch 994/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2241e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00994: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 7.2241e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0133 - val_mean_absolute_error: 0.1530\n",
      "Epoch 995/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1806e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00995: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1806e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0101 - val_mean_absolute_error: 0.1246\n",
      "Epoch 996/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.9847e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00996: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 6.9776e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0151 - val_mean_absolute_error: 0.1526\n",
      "Epoch 997/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.0102e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00997: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.0225e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0222 - val_mean_absolute_error: 0.1879\n",
      "Epoch 998/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1237e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 00998: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1237e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0223 - val_mean_absolute_error: 0.1895\n",
      "Epoch 999/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.6093e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 00999: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.5996e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0162 - val_mean_absolute_error: 0.1481\n",
      "Epoch 1000/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.9450e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01000: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9351e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0190 - val_mean_absolute_error: 0.1591\n",
      "Epoch 1001/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8266e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01001: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8266e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0101 - val_mean_absolute_error: 0.1220\n",
      "Epoch 1002/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1391e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 01002: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.1391e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0116 - val_mean_absolute_error: 0.1257\n",
      "Epoch 1003/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0838e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 01003: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.0838e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0132 - val_mean_absolute_error: 0.1533\n",
      "Epoch 1004/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6765e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01004: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6765e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0175 - val_mean_absolute_error: 0.1637\n",
      "Epoch 1005/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9257e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01005: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9257e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0148 - val_mean_absolute_error: 0.1634\n",
      "Epoch 1006/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0408e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01006: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0408e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0129 - val_mean_absolute_error: 0.1494\n",
      "Epoch 1007/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.8923e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 01007: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.8923e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0162 - val_mean_absolute_error: 0.1427\n",
      "Epoch 1008/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9086e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01008: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9086e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0173 - val_mean_absolute_error: 0.1439\n",
      "Epoch 1009/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8765e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01009: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8765e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0225 - val_mean_absolute_error: 0.1769\n",
      "Epoch 1010/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9497e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01010: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9497e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0171 - val_mean_absolute_error: 0.1557\n",
      "Epoch 1011/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.7932e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01011: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7683e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0104 - val_mean_absolute_error: 0.1305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1012/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8778e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 01012: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8778e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0230 - val_mean_absolute_error: 0.1801\n",
      "Epoch 1013/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.0434e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 01013: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.0379e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0086 - val_mean_absolute_error: 0.1173\n",
      "Epoch 1014/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8425e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01014: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8425e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0102 - val_mean_absolute_error: 0.1319\n",
      "Epoch 1015/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5742e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01015: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5742e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0107 - val_mean_absolute_error: 0.1342\n",
      "Epoch 1016/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.5648e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01016: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5693e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0118 - val_mean_absolute_error: 0.1443\n",
      "Epoch 1017/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6778e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01017: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6778e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0101 - val_mean_absolute_error: 0.1275\n",
      "Epoch 1018/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8881e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01018: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8881e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0133 - val_mean_absolute_error: 0.1321\n",
      "Epoch 1019/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2643e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 01019: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2643e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0084 - val_mean_absolute_error: 0.1184\n",
      "Epoch 1020/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.8460e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01020: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8113e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0092 - val_mean_absolute_error: 0.1226\n",
      "Epoch 1021/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.6599e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01021: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6555e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0128 - val_mean_absolute_error: 0.1507\n",
      "Epoch 1022/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.7813e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01022: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8167e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0104 - val_mean_absolute_error: 0.1099\n",
      "Epoch 1023/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6689e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01023: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6689e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0116 - val_mean_absolute_error: 0.1398\n",
      "Epoch 1024/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5374e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01024: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5374e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0130 - val_mean_absolute_error: 0.1391\n",
      "Epoch 1025/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9711e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01025: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.9711e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0082 - val_mean_absolute_error: 0.1139\n",
      "Epoch 1026/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7852e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01026: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7852e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0133 - val_mean_absolute_error: 0.1528\n",
      "Epoch 1027/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.7910e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01027: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.7814e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0078 - val_mean_absolute_error: 0.1094\n",
      "Epoch 1028/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8976e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01028: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8976e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0099 - val_mean_absolute_error: 0.1264\n",
      "Epoch 1029/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.6576e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01029: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6471e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0082 - val_mean_absolute_error: 0.1132\n",
      "Epoch 1030/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6643e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01030: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6643e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0105 - val_mean_absolute_error: 0.1328\n",
      "Epoch 1031/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.9722e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01031: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.9718e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0124 - val_mean_absolute_error: 0.1442\n",
      "Epoch 1032/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8489e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01032: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8489e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0112 - val_mean_absolute_error: 0.1359\n",
      "Epoch 1033/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5659e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01033: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5659e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0104 - val_mean_absolute_error: 0.1312\n",
      "Epoch 1034/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.8469e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01034: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8239e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0093 - val_mean_absolute_error: 0.1238\n",
      "Epoch 1035/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9173e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01035: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9173e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0110 - val_mean_absolute_error: 0.1358\n",
      "Epoch 1036/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.1849e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 01036: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.1839e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0108 - val_mean_absolute_error: 0.1382\n",
      "Epoch 1037/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.9132e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01037: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.9138e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0138 - val_mean_absolute_error: 0.1563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1038/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.0227e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01038: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0179e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0145 - val_mean_absolute_error: 0.1613\n",
      "Epoch 1039/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8511e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01039: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8511e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0144 - val_mean_absolute_error: 0.1525\n",
      "Epoch 1040/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9800e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01040: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9800e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0131 - val_mean_absolute_error: 0.1512\n",
      "Epoch 1041/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7273e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01041: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7273e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0120 - val_mean_absolute_error: 0.1452\n",
      "Epoch 1042/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7144e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01042: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7144e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0092 - val_mean_absolute_error: 0.1234\n",
      "Epoch 1043/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0245e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 01043: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0245e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0098 - val_mean_absolute_error: 0.1271\n",
      "Epoch 1044/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.0243e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01044: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0063e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0142 - val_mean_absolute_error: 0.1585\n",
      "Epoch 1045/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.1815e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 01045: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.1738e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0146 - val_mean_absolute_error: 0.1621\n",
      "Epoch 1046/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8737e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01046: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8737e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0125 - val_mean_absolute_error: 0.1486\n",
      "Epoch 1047/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.5408e-05 - mean_absolute_error: 0.0087\n",
      "Epoch 01047: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.5408e-05 - mean_absolute_error: 0.0087 - val_loss: 0.0103 - val_mean_absolute_error: 0.1309\n",
      "Epoch 1048/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6876e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01048: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6876e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0123 - val_mean_absolute_error: 0.1492\n",
      "Epoch 1049/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8501e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01049: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8501e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0108 - val_mean_absolute_error: 0.1391\n",
      "Epoch 1050/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8430e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01050: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8430e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0100 - val_mean_absolute_error: 0.1307\n",
      "Epoch 1051/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.4584e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01051: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4473e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0089 - val_mean_absolute_error: 0.1225\n",
      "Epoch 1052/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.7855e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01052: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.7668e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0108 - val_mean_absolute_error: 0.1354\n",
      "Epoch 1053/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.5038e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01053: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5192e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0083 - val_mean_absolute_error: 0.1157\n",
      "Epoch 1054/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4915e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01054: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4915e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0162 - val_mean_absolute_error: 0.1636\n",
      "Epoch 1055/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9482e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01055: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9482e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0087 - val_mean_absolute_error: 0.1204\n",
      "Epoch 1056/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6139e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01056: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6139e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0091 - val_mean_absolute_error: 0.1234\n",
      "Epoch 1057/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5568e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01057: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5568e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0080 - val_mean_absolute_error: 0.1113\n",
      "Epoch 1058/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.0237e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01058: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0450e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0075 - val_mean_absolute_error: 0.1073\n",
      "Epoch 1059/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7008e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01059: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.7008e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0108 - val_mean_absolute_error: 0.1353\n",
      "Epoch 1060/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0182e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01060: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0182e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0155 - val_mean_absolute_error: 0.1676\n",
      "Epoch 1061/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6556e-05 - mean_absolute_error: 0.0082- ETA: 0s - loss: 6.7297e-05 - mean_absolute_error:\n",
      "Epoch 01061: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6556e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0114 - val_mean_absolute_error: 0.1397\n",
      "Epoch 1062/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9712e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01062: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.9712e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0138 - val_mean_absolute_error: 0.1565\n",
      "Epoch 1063/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 6.8926e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01063: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8480e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0105 - val_mean_absolute_error: 0.1342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1064/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5112e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01064: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 6.5112e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0120 - val_mean_absolute_error: 0.1456\n",
      "Epoch 1065/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6899e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01065: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6899e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0116 - val_mean_absolute_error: 0.1361\n",
      "Epoch 1066/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 7.2325e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 01066: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2278e-05 - mean_absolute_error: 0.0086 - val_loss: 0.0100 - val_mean_absolute_error: 0.1286\n",
      "Epoch 1067/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2283e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 01067: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.2283e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0085 - val_mean_absolute_error: 0.1170\n",
      "Epoch 1068/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8455e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01068: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8455e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0120 - val_mean_absolute_error: 0.1439\n",
      "Epoch 1069/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6004e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01069: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6004e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0082 - val_mean_absolute_error: 0.1162\n",
      "Epoch 1070/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1353e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01070: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.1353e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0101 - val_mean_absolute_error: 0.1302\n",
      "Epoch 1071/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.6089e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01071: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6048e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0113 - val_mean_absolute_error: 0.1380\n",
      "Epoch 1072/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4835e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01072: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4835e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0152 - val_mean_absolute_error: 0.1570\n",
      "Epoch 1073/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6176e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01073: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6176e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0125 - val_mean_absolute_error: 0.1382\n",
      "Epoch 1074/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0876e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01074: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.0876e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0113 - val_mean_absolute_error: 0.1407\n",
      "Epoch 1075/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.0469e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01075: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0407e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0118 - val_mean_absolute_error: 0.1430\n",
      "Epoch 1076/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.7652e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01076: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.7591e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0153 - val_mean_absolute_error: 0.1472\n",
      "Epoch 1077/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8072e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01077: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8072e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0067 - val_mean_absolute_error: 0.1016\n",
      "Epoch 1078/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.8594e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01078: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8285e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0112 - val_mean_absolute_error: 0.1408\n",
      "Epoch 1079/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.1273e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 01079: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.1273e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0106 - val_mean_absolute_error: 0.1283\n",
      "Epoch 1080/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7118e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01080: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7118e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0111 - val_mean_absolute_error: 0.1394\n",
      "Epoch 1081/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5948e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01081: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5948e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0118 - val_mean_absolute_error: 0.1448\n",
      "Epoch 1082/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.6813e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01082: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6742e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0112 - val_mean_absolute_error: 0.1370\n",
      "Epoch 1083/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8043e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01083: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8043e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0130 - val_mean_absolute_error: 0.1514\n",
      "Epoch 1084/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.8318e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01084: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8251e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0109 - val_mean_absolute_error: 0.1371\n",
      "Epoch 1085/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5891e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01085: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5891e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0112 - val_mean_absolute_error: 0.1381\n",
      "Epoch 1086/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4888e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01086: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4888e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0099 - val_mean_absolute_error: 0.1285\n",
      "Epoch 1087/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3326e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01087: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3326e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0115 - val_mean_absolute_error: 0.1428\n",
      "Epoch 1088/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5257e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01088: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5257e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0100 - val_mean_absolute_error: 0.1301\n",
      "Epoch 1089/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6715e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01089: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6715e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0126 - val_mean_absolute_error: 0.1474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1090/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8062e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01090: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8062e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0107 - val_mean_absolute_error: 0.1352\n",
      "Epoch 1091/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5901e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01091: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5901e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0052 - val_mean_absolute_error: 0.0866\n",
      "Epoch 1092/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.8644e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01092: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8657e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0108 - val_mean_absolute_error: 0.1319\n",
      "Epoch 1093/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5575e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01093: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5575e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0101 - val_mean_absolute_error: 0.1271\n",
      "Epoch 1094/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8363e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01094: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8363e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0135 - val_mean_absolute_error: 0.1512\n",
      "Epoch 1095/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.8646e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01095: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8750e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0134 - val_mean_absolute_error: 0.1518\n",
      "Epoch 1096/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2464e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01096: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2464e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0078 - val_mean_absolute_error: 0.1082\n",
      "Epoch 1097/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.9896e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01097: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9719e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0139 - val_mean_absolute_error: 0.1559\n",
      "Epoch 1098/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7360e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01098: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.7360e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0161 - val_mean_absolute_error: 0.1717\n",
      "Epoch 1099/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6123e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01099: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6123e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0139 - val_mean_absolute_error: 0.1573\n",
      "Epoch 1100/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1847e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01100: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1847e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0124 - val_mean_absolute_error: 0.1458\n",
      "Epoch 1101/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6371e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01101: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6371e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0115 - val_mean_absolute_error: 0.1417\n",
      "Epoch 1102/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7623e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01102: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.7623e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0100 - val_mean_absolute_error: 0.1280\n",
      "Epoch 1103/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8279e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01103: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8279e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0122 - val_mean_absolute_error: 0.1440\n",
      "Epoch 1104/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8345e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01104: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8345e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0104 - val_mean_absolute_error: 0.1320\n",
      "Epoch 1105/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 7.0589e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01105: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 7.0208e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0143 - val_mean_absolute_error: 0.1571\n",
      "Epoch 1106/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.8891e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01106: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8856e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0122 - val_mean_absolute_error: 0.1400\n",
      "Epoch 1107/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7617e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01107: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.7617e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0156 - val_mean_absolute_error: 0.1669\n",
      "Epoch 1108/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.7522e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01108: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7317e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0099 - val_mean_absolute_error: 0.1277\n",
      "Epoch 1109/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6230e-05 - mean_absolute_error: 0.0083- ETA: 0s - loss: 6.7793e-05 - mean_absolute\n",
      "Epoch 01109: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6230e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0088 - val_mean_absolute_error: 0.1213\n",
      "Epoch 1110/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.5962e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01110: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6002e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0127 - val_mean_absolute_error: 0.1491\n",
      "Epoch 1111/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4247e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01111: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4247e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0143 - val_mean_absolute_error: 0.1613\n",
      "Epoch 1112/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.9051e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01112: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.8754e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0130 - val_mean_absolute_error: 0.1534\n",
      "Epoch 1113/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7815e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01113: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7815e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0116 - val_mean_absolute_error: 0.1435\n",
      "Epoch 1114/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.5072e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01114: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4734e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0126 - val_mean_absolute_error: 0.1494\n",
      "Epoch 1115/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2643e-05 - mean_absolute_error: 0.0085\n",
      "Epoch 01115: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.2643e-05 - mean_absolute_error: 0.0085 - val_loss: 0.0114 - val_mean_absolute_error: 0.1422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1116/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3779e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01116: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3779e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0091 - val_mean_absolute_error: 0.1198\n",
      "Epoch 1117/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7848e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01117: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7848e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0091 - val_mean_absolute_error: 0.1211\n",
      "Epoch 1118/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5979e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01118: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5979e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0077 - val_mean_absolute_error: 0.1096\n",
      "Epoch 1119/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.4644e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01119: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4883e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0116 - val_mean_absolute_error: 0.1421\n",
      "Epoch 1120/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6722e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01120: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6722e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0128 - val_mean_absolute_error: 0.1494\n",
      "Epoch 1121/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5106e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01121: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5106e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0087 - val_mean_absolute_error: 0.1191\n",
      "Epoch 1122/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.2065e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01122: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.2065e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0080 - val_mean_absolute_error: 0.1127\n",
      "Epoch 1123/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0864e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01123: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0864e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0080 - val_mean_absolute_error: 0.1130\n",
      "Epoch 1124/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.6584e-05 - mean_absolute_error: 0.0082- ETA: 0s - loss: 6.4486e-05 - mean_absolute_error\n",
      "Epoch 01124: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6658e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0079 - val_mean_absolute_error: 0.1119\n",
      "Epoch 1125/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5644e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01125: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5644e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0105 - val_mean_absolute_error: 0.1343\n",
      "Epoch 1126/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.5565e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01126: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5537e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0086 - val_mean_absolute_error: 0.1188\n",
      "Epoch 1127/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.8670e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01127: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8598e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0122 - val_mean_absolute_error: 0.1459\n",
      "Epoch 1128/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6408e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01128: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6408e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0111 - val_mean_absolute_error: 0.1322\n",
      "Epoch 1129/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4497e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01129: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4497e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0086 - val_mean_absolute_error: 0.1170\n",
      "Epoch 1130/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7827e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01130: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7827e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0095 - val_mean_absolute_error: 0.1208\n",
      "Epoch 1131/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 6.5021e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01131: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 6.4594e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0118 - val_mean_absolute_error: 0.1436\n",
      "Epoch 1132/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.6726e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01132: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.6373e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0111 - val_mean_absolute_error: 0.1372\n",
      "Epoch 1133/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5449e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01133: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5449e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0104 - val_mean_absolute_error: 0.1301\n",
      "Epoch 1134/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.7279e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01134: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.7208e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0108 - val_mean_absolute_error: 0.1331\n",
      "Epoch 1135/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6537e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01135: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6537e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0091 - val_mean_absolute_error: 0.1230\n",
      "Epoch 1136/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.0267e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01136: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 5.9871e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0098 - val_mean_absolute_error: 0.1286\n",
      "Epoch 1137/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5035e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01137: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5035e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0192 - val_mean_absolute_error: 0.1626\n",
      "Epoch 1138/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8799e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01138: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8799e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0116 - val_mean_absolute_error: 0.1271\n",
      "Epoch 1139/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.5311e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01139: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5304e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0115 - val_mean_absolute_error: 0.1404\n",
      "Epoch 1140/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.8797e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01140: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8916e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0088 - val_mean_absolute_error: 0.1197\n",
      "Epoch 1141/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.7508e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01141: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7419e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0110 - val_mean_absolute_error: 0.1359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1142/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1614e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01142: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1614e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0099 - val_mean_absolute_error: 0.1250\n",
      "Epoch 1143/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3215e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01143: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3215e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0106 - val_mean_absolute_error: 0.1314\n",
      "Epoch 1144/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9112e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01144: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9112e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0090 - val_mean_absolute_error: 0.1205\n",
      "Epoch 1145/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6547e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01145: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6547e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0128 - val_mean_absolute_error: 0.1491\n",
      "Epoch 1146/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.9106e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01146: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8893e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0103 - val_mean_absolute_error: 0.1206\n",
      "Epoch 1147/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.5325e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01147: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5406e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0110 - val_mean_absolute_error: 0.1355\n",
      "Epoch 1148/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9065e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01148: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.9065e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0194 - val_mean_absolute_error: 0.1648\n",
      "Epoch 1149/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.5011e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01149: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4843e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0154 - val_mean_absolute_error: 0.1657\n",
      "Epoch 1150/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6712e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01150: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6712e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0139 - val_mean_absolute_error: 0.1550\n",
      "Epoch 1151/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 7.0771e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01151: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 7.0771e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0116 - val_mean_absolute_error: 0.1415\n",
      "Epoch 1152/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9695e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01152: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.9695e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0102 - val_mean_absolute_error: 0.1317\n",
      "Epoch 1153/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5416e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01153: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5416e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0122 - val_mean_absolute_error: 0.1440\n",
      "Epoch 1154/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6108e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01154: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6108e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0133 - val_mean_absolute_error: 0.1514\n",
      "Epoch 1155/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2415e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01155: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2415e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0126 - val_mean_absolute_error: 0.1460\n",
      "Epoch 1156/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.9965e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 01156: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.9965e-05 - mean_absolute_error: 0.0084 - val_loss: 0.0101 - val_mean_absolute_error: 0.1300\n",
      "Epoch 1157/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3952e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01157: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3952e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0098 - val_mean_absolute_error: 0.1253\n",
      "Epoch 1158/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5159e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01158: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5159e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0159 - val_mean_absolute_error: 0.1560\n",
      "Epoch 1159/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7152e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01159: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.7152e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0109 - val_mean_absolute_error: 0.1367\n",
      "Epoch 1160/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5407e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01160: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5407e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0124 - val_mean_absolute_error: 0.1451\n",
      "Epoch 1161/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4235e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01161: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4235e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0146 - val_mean_absolute_error: 0.1577\n",
      "Epoch 1162/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.7850e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01162: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.7850e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0164 - val_mean_absolute_error: 0.1590\n",
      "Epoch 1163/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.2341e-05 - mean_absolute_error: 0.0080- ETA: 1s - loss: 6.1815e-05 - mean_absol\n",
      "Epoch 01163: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2401e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0097 - val_mean_absolute_error: 0.1274\n",
      "Epoch 1164/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.6579e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01164: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6742e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0146 - val_mean_absolute_error: 0.1614\n",
      "Epoch 1165/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2738e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01165: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2738e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0103 - val_mean_absolute_error: 0.1278\n",
      "Epoch 1166/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5754e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01166: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5754e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0124 - val_mean_absolute_error: 0.1465\n",
      "Epoch 1167/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.4509e-05 - mean_absolute_error: 0.0081- ETA: 0s - loss: 6.5142e-05 - mean_absolute_error: 0.008\n",
      "Epoch 01167: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4488e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0106 - val_mean_absolute_error: 0.1341\n",
      "Epoch 1168/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8998e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01168: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8998e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0178 - val_mean_absolute_error: 0.1791\n",
      "Epoch 1169/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.6171e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01169: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6225e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0119 - val_mean_absolute_error: 0.1434\n",
      "Epoch 1170/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6017e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01170: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6017e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0158 - val_mean_absolute_error: 0.1696\n",
      "Epoch 1171/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5666e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01171: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5666e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0129 - val_mean_absolute_error: 0.1496\n",
      "Epoch 1172/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5516e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01172: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5516e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0119 - val_mean_absolute_error: 0.1402\n",
      "Epoch 1173/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8292e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01173: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.8292e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0123 - val_mean_absolute_error: 0.1432\n",
      "Epoch 1174/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.2888e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01174: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2855e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0115 - val_mean_absolute_error: 0.1394\n",
      "Epoch 1175/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.6231e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01175: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6529e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0146 - val_mean_absolute_error: 0.1617\n",
      "Epoch 1176/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.5722e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01176: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6001e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0139 - val_mean_absolute_error: 0.1566\n",
      "Epoch 1177/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4831e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01177: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4831e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0116 - val_mean_absolute_error: 0.1417\n",
      "Epoch 1178/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8018e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01178: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8018e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0077 - val_mean_absolute_error: 0.1116\n",
      "Epoch 1179/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.6174e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01179: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5869e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0095 - val_mean_absolute_error: 0.1247\n",
      "Epoch 1180/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.6036e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01180: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5983e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0123 - val_mean_absolute_error: 0.1463\n",
      "Epoch 1181/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.4585e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01181: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4240e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0157 - val_mean_absolute_error: 0.1680\n",
      "Epoch 1182/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.4980e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01182: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4890e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0106 - val_mean_absolute_error: 0.1342\n",
      "Epoch 1183/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3175e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01183: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3175e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0104 - val_mean_absolute_error: 0.1345\n",
      "Epoch 1184/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.4768e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01184: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4773e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0127 - val_mean_absolute_error: 0.1457\n",
      "Epoch 1185/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8285e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01185: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8285e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0105 - val_mean_absolute_error: 0.1287\n",
      "Epoch 1186/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.2840e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01186: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2785e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0123 - val_mean_absolute_error: 0.1439\n",
      "Epoch 1187/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5664e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01187: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5664e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0090 - val_mean_absolute_error: 0.1191\n",
      "Epoch 1188/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.3982e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01188: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.4448e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0110 - val_mean_absolute_error: 0.1380\n",
      "Epoch 1189/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2548e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01189: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2548e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0118 - val_mean_absolute_error: 0.1440\n",
      "Epoch 1190/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4573e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01190: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4573e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0159 - val_mean_absolute_error: 0.1700\n",
      "Epoch 1191/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3155e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01191: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3155e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0144 - val_mean_absolute_error: 0.1575\n",
      "Epoch 1192/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.5141e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01192: val_loss did not improve from 0.00023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5195e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0120 - val_mean_absolute_error: 0.1428\n",
      "Epoch 1193/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6679e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01193: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6679e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0087 - val_mean_absolute_error: 0.1173\n",
      "Epoch 1194/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2283e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01194: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2283e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0113 - val_mean_absolute_error: 0.1361\n",
      "Epoch 1195/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3035e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01195: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3035e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0091 - val_mean_absolute_error: 0.1192\n",
      "Epoch 1196/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.4004e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01196: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3582e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0122 - val_mean_absolute_error: 0.1447\n",
      "Epoch 1197/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3465e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01197: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3465e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0153 - val_mean_absolute_error: 0.1651\n",
      "Epoch 1198/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4152e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01198: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.4152e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0125 - val_mean_absolute_error: 0.1460\n",
      "Epoch 1199/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4247e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01199: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.4247e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0103 - val_mean_absolute_error: 0.1309\n",
      "Epoch 1200/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.6513e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01200: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 6.6457e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0107 - val_mean_absolute_error: 0.1339\n",
      "Epoch 1201/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.3450e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01201: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3109e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0114 - val_mean_absolute_error: 0.1399\n",
      "Epoch 1202/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4203e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01202: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4203e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0087 - val_mean_absolute_error: 0.1188\n",
      "Epoch 1203/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5327e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01203: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5327e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0110 - val_mean_absolute_error: 0.1374\n",
      "Epoch 1204/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8031e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01204: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8031e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0119 - val_mean_absolute_error: 0.1429\n",
      "Epoch 1205/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4191e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01205: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4191e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0119 - val_mean_absolute_error: 0.1425\n",
      "Epoch 1206/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1440e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01206: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1440e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0105 - val_mean_absolute_error: 0.1333\n",
      "Epoch 1207/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5707e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01207: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5707e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0096 - val_mean_absolute_error: 0.1271\n",
      "Epoch 1208/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.5884e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01208: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5836e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0099 - val_mean_absolute_error: 0.1295\n",
      "Epoch 1209/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.5792e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01209: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5750e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0117 - val_mean_absolute_error: 0.1393\n",
      "Epoch 1210/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.2908e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01210: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3010e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0138 - val_mean_absolute_error: 0.1565\n",
      "Epoch 1211/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.8450e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 01211: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.8450e-05 - mean_absolute_error: 0.0083 - val_loss: 0.0092 - val_mean_absolute_error: 0.1230\n",
      "Epoch 1212/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.6089e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01212: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5993e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0131 - val_mean_absolute_error: 0.1519\n",
      "Epoch 1213/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2345e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01213: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2345e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0150 - val_mean_absolute_error: 0.1647\n",
      "Epoch 1214/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.3956e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01214: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3522e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0115 - val_mean_absolute_error: 0.1414\n",
      "Epoch 1215/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4574e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01215: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4574e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0100 - val_mean_absolute_error: 0.1305\n",
      "Epoch 1216/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4487e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01216: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4487e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0101 - val_mean_absolute_error: 0.1306\n",
      "Epoch 1217/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5323e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01217: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5323e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0128 - val_mean_absolute_error: 0.1500\n",
      "Epoch 1218/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - ETA: 0s - loss: 6.0188e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01218: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0188e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0099 - val_mean_absolute_error: 0.1286\n",
      "Epoch 1219/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6547e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01219: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6547e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0096 - val_mean_absolute_error: 0.1276\n",
      "Epoch 1220/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4921e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01220: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4921e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0123 - val_mean_absolute_error: 0.1450\n",
      "Epoch 1221/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4418e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01221: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.4418e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0144 - val_mean_absolute_error: 0.1602\n",
      "Epoch 1222/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5885e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01222: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5885e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0105 - val_mean_absolute_error: 0.1334\n",
      "Epoch 1223/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.3455e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01223: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3619e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0104 - val_mean_absolute_error: 0.1351\n",
      "Epoch 1224/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3997e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01224: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3997e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0092 - val_mean_absolute_error: 0.1235\n",
      "Epoch 1225/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.3699e-05 - mean_absolute_error: 0.0079- ETA: 0s - loss: 6.4530e-05 - mean_absolute_error: 0\n",
      "Epoch 01225: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3563e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0116 - val_mean_absolute_error: 0.1408\n",
      "Epoch 1226/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5484e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01226: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.5484e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0088 - val_mean_absolute_error: 0.1197\n",
      "Epoch 1227/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.8374e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01227: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.8336e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0108 - val_mean_absolute_error: 0.1372\n",
      "Epoch 1228/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3706e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01228: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.3706e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0117 - val_mean_absolute_error: 0.1419\n",
      "Epoch 1229/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.5590e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01229: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5538e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0124 - val_mean_absolute_error: 0.1467\n",
      "Epoch 1230/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2912e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01230: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2912e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0129 - val_mean_absolute_error: 0.1503\n",
      "Epoch 1231/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.4556e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01231: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.4497e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0110 - val_mean_absolute_error: 0.1376\n",
      "Epoch 1232/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2920e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01232: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.2920e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0115 - val_mean_absolute_error: 0.1404\n",
      "Epoch 1233/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.6425e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01233: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.6228e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0117 - val_mean_absolute_error: 0.1413\n",
      "Epoch 1234/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4351e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01234: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.4351e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0098 - val_mean_absolute_error: 0.1268\n",
      "Epoch 1235/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.4950e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01235: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.4899e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0106 - val_mean_absolute_error: 0.1335\n",
      "Epoch 1236/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1596e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01236: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.1596e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0126 - val_mean_absolute_error: 0.1478\n",
      "Epoch 1237/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3392e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01237: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3392e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0114 - val_mean_absolute_error: 0.1402\n",
      "Epoch 1238/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.7072e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01238: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.7060e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0155 - val_mean_absolute_error: 0.1642\n",
      "Epoch 1239/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0645e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01239: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 6.0645e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0107 - val_mean_absolute_error: 0.1338\n",
      "Epoch 1240/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1803e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01240: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1803e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0119 - val_mean_absolute_error: 0.1424\n",
      "Epoch 1241/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5548e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01241: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5548e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0139 - val_mean_absolute_error: 0.1551\n",
      "Epoch 1242/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1754e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01242: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.1754e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0102 - val_mean_absolute_error: 0.1300\n",
      "Epoch 1243/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.2798e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01243: val_loss did not improve from 0.00023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2699e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0126 - val_mean_absolute_error: 0.1490\n",
      "Epoch 1244/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.2342e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01244: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 6.2355e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0135 - val_mean_absolute_error: 0.1543\n",
      "Epoch 1245/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9556e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01245: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9556e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0113 - val_mean_absolute_error: 0.1390\n",
      "Epoch 1246/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3376e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01246: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.3376e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0119 - val_mean_absolute_error: 0.1427\n",
      "Epoch 1247/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.6136e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01247: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.6069e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0193 - val_mean_absolute_error: 0.1703\n",
      "Epoch 1248/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4670e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01248: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4670e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0112 - val_mean_absolute_error: 0.1375\n",
      "Epoch 1249/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.4390e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01249: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.3990e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0120 - val_mean_absolute_error: 0.1438\n",
      "Epoch 1250/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2924e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01250: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.2924e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0114 - val_mean_absolute_error: 0.1392\n",
      "Epoch 1251/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4766e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01251: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.4766e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0161 - val_mean_absolute_error: 0.1681\n",
      "Epoch 1252/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5366e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01252: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5366e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0134 - val_mean_absolute_error: 0.1508\n",
      "Epoch 1253/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6427e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01253: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6427e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0126 - val_mean_absolute_error: 0.1490\n",
      "Epoch 1254/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2656e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01254: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2656e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0149 - val_mean_absolute_error: 0.1625\n",
      "Epoch 1255/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.2366e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01255: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2278e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0160 - val_mean_absolute_error: 0.1706\n",
      "Epoch 1256/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.6563e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01256: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6306e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0093 - val_mean_absolute_error: 0.1244\n",
      "Epoch 1257/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6599e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01257: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6599e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0138 - val_mean_absolute_error: 0.1570\n",
      "Epoch 1258/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.2837e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01258: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.2556e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0124 - val_mean_absolute_error: 0.1489\n",
      "Epoch 1259/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2340e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01259: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2340e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0119 - val_mean_absolute_error: 0.1415\n",
      "Epoch 1260/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5362e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01260: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5362e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0096 - val_mean_absolute_error: 0.1251\n",
      "Epoch 1261/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1526e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01261: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1526e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0153 - val_mean_absolute_error: 0.1653\n",
      "Epoch 1262/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0143e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01262: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0143e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0137 - val_mean_absolute_error: 0.1548\n",
      "Epoch 1263/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2458e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01263: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2458e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0106 - val_mean_absolute_error: 0.1337\n",
      "Epoch 1264/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6798e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01264: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6798e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0099 - val_mean_absolute_error: 0.1276\n",
      "Epoch 1265/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2772e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01265: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2772e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0117 - val_mean_absolute_error: 0.1425\n",
      "Epoch 1266/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1622e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01266: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1622e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0107 - val_mean_absolute_error: 0.1380\n",
      "Epoch 1267/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5064e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01267: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5064e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0123 - val_mean_absolute_error: 0.1453\n",
      "Epoch 1268/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5711e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 01268: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5711e-05 - mean_absolute_error: 0.0082 - val_loss: 0.0131 - val_mean_absolute_error: 0.1501\n",
      "Epoch 1269/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/79 [============================>.] - ETA: 0s - loss: 6.4144e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01269: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 6.4142e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0112 - val_mean_absolute_error: 0.1386\n",
      "Epoch 1270/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3645e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01270: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3645e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0115 - val_mean_absolute_error: 0.1394\n",
      "Epoch 1271/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9697e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01271: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9697e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0096 - val_mean_absolute_error: 0.1249\n",
      "Epoch 1272/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.0633e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01272: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.0894e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0122 - val_mean_absolute_error: 0.1460\n",
      "Epoch 1273/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3253e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01273: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3253e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0104 - val_mean_absolute_error: 0.1322\n",
      "Epoch 1274/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2044e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01274: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2044e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0126 - val_mean_absolute_error: 0.1488\n",
      "Epoch 1275/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1462e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01275: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1462e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0134 - val_mean_absolute_error: 0.1534\n",
      "Epoch 1276/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4590e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01276: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4590e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0099 - val_mean_absolute_error: 0.1276\n",
      "Epoch 1277/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2688e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01277: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2688e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0143 - val_mean_absolute_error: 0.1593\n",
      "Epoch 1278/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6723e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01278: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6723e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0098 - val_mean_absolute_error: 0.1290\n",
      "Epoch 1279/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.3034e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01279: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2858e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0092 - val_mean_absolute_error: 0.1231\n",
      "Epoch 1280/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2356e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01280: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2356e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0117 - val_mean_absolute_error: 0.1390\n",
      "Epoch 1281/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2594e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01281: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2594e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0125 - val_mean_absolute_error: 0.1487\n",
      "Epoch 1282/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2950e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01282: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2950e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0129 - val_mean_absolute_error: 0.1506\n",
      "Epoch 1283/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2509e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01283: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2509e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0089 - val_mean_absolute_error: 0.1208\n",
      "Epoch 1284/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1915e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01284: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1915e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0091 - val_mean_absolute_error: 0.1214\n",
      "Epoch 1285/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.2339e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01285: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.2255e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0119 - val_mean_absolute_error: 0.1412\n",
      "Epoch 1286/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1846e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01286: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1846e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0104 - val_mean_absolute_error: 0.1330\n",
      "Epoch 1287/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2918e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01287: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2918e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0126 - val_mean_absolute_error: 0.1484\n",
      "Epoch 1288/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3947e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01288: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3947e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0106 - val_mean_absolute_error: 0.1343\n",
      "Epoch 1289/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.1242e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01289: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1173e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0123 - val_mean_absolute_error: 0.1452\n",
      "Epoch 1290/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2162e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01290: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2162e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0092 - val_mean_absolute_error: 0.1207\n",
      "Epoch 1291/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2034e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01291: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2034e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0147 - val_mean_absolute_error: 0.1618\n",
      "Epoch 1292/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0969e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01292: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0969e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0120 - val_mean_absolute_error: 0.1437\n",
      "Epoch 1293/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1936e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01293: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1936e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0130 - val_mean_absolute_error: 0.1510\n",
      "Epoch 1294/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0816e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01294: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.0816e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0133 - val_mean_absolute_error: 0.1525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1295/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.1847e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01295: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2038e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0123 - val_mean_absolute_error: 0.1469\n",
      "Epoch 1296/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.2271e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01296: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2298e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0098 - val_mean_absolute_error: 0.1277\n",
      "Epoch 1297/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.6602e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01297: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.6602e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0118 - val_mean_absolute_error: 0.1444\n",
      "Epoch 1298/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5935e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01298: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5935e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0103 - val_mean_absolute_error: 0.1330\n",
      "Epoch 1299/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2863e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01299: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2863e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0120 - val_mean_absolute_error: 0.1419\n",
      "Epoch 1300/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3831e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01300: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3831e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0100 - val_mean_absolute_error: 0.1297\n",
      "Epoch 1301/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1673e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01301: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1673e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0096 - val_mean_absolute_error: 0.1265\n",
      "Epoch 1302/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.4097e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01302: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4299e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0131 - val_mean_absolute_error: 0.1522\n",
      "Epoch 1303/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1984e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01303: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1984e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0126 - val_mean_absolute_error: 0.1483\n",
      "Epoch 1304/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4545e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01304: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4545e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0116 - val_mean_absolute_error: 0.1428\n",
      "Epoch 1305/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2166e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01305: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2166e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0102 - val_mean_absolute_error: 0.1325\n",
      "Epoch 1306/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1108e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01306: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1108e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0118 - val_mean_absolute_error: 0.1428\n",
      "Epoch 1307/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.6495e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01307: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.6472e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0088 - val_mean_absolute_error: 0.1193\n",
      "Epoch 1308/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1006e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01308: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1006e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0084 - val_mean_absolute_error: 0.1165\n",
      "Epoch 1309/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9046e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01309: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.9046e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0124 - val_mean_absolute_error: 0.1469\n",
      "Epoch 1310/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.9388e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01310: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.9660e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0077 - val_mean_absolute_error: 0.1109\n",
      "Epoch 1311/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9844e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01311: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9844e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0105 - val_mean_absolute_error: 0.1351\n",
      "Epoch 1312/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5169e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01312: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.5169e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0143 - val_mean_absolute_error: 0.1596\n",
      "Epoch 1313/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1179e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01313: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.1179e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0098 - val_mean_absolute_error: 0.1271\n",
      "Epoch 1314/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9480e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01314: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9480e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0094 - val_mean_absolute_error: 0.1237\n",
      "Epoch 1315/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2438e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01315: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2438e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0126 - val_mean_absolute_error: 0.1494\n",
      "Epoch 1316/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1674e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01316: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1674e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0122 - val_mean_absolute_error: 0.1449\n",
      "Epoch 1317/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2614e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01317: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2614e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0154 - val_mean_absolute_error: 0.1641\n",
      "Epoch 1318/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.1513e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01318: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.2068e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0126 - val_mean_absolute_error: 0.1474\n",
      "Epoch 1319/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5163e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01319: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.5163e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0123 - val_mean_absolute_error: 0.1452\n",
      "Epoch 1320/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.1121e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01320: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1362e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0147 - val_mean_absolute_error: 0.1612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1321/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9435e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01321: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9435e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0175 - val_mean_absolute_error: 0.1769\n",
      "Epoch 1322/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3038e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01322: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3038e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0115 - val_mean_absolute_error: 0.1387\n",
      "Epoch 1323/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.1655e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01323: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1372e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0124 - val_mean_absolute_error: 0.1471\n",
      "Epoch 1324/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.2708e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01324: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2665e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0129 - val_mean_absolute_error: 0.1511\n",
      "Epoch 1325/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.1828e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01325: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2533e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0133 - val_mean_absolute_error: 0.1506\n",
      "Epoch 1326/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.1719e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01326: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.1727e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0098 - val_mean_absolute_error: 0.1260\n",
      "Epoch 1327/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4550e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01327: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4550e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0112 - val_mean_absolute_error: 0.1364\n",
      "Epoch 1328/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.0988e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01328: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1470e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0118 - val_mean_absolute_error: 0.1408\n",
      "Epoch 1329/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3445e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01329: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3445e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0123 - val_mean_absolute_error: 0.1461\n",
      "Epoch 1330/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4796e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01330: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4796e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0144 - val_mean_absolute_error: 0.1581\n",
      "Epoch 1331/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5018e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01331: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.5018e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0107 - val_mean_absolute_error: 0.1346\n",
      "Epoch 1332/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.5802e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01332: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5802e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0070 - val_mean_absolute_error: 0.1057\n",
      "Epoch 1333/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.4077e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01333: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4030e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0092 - val_mean_absolute_error: 0.1247\n",
      "Epoch 1334/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.3175e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01334: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3105e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0100 - val_mean_absolute_error: 0.1302\n",
      "Epoch 1335/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.1360e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01335: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1338e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0079 - val_mean_absolute_error: 0.1142\n",
      "Epoch 1336/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0094e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01336: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.0094e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0128 - val_mean_absolute_error: 0.1516\n",
      "Epoch 1337/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 6.0274e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01337: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.0083e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0135 - val_mean_absolute_error: 0.1542\n",
      "Epoch 1338/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2696e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01338: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2696e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0104 - val_mean_absolute_error: 0.1315\n",
      "Epoch 1339/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.0779e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01339: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.0787e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0117 - val_mean_absolute_error: 0.1402\n",
      "Epoch 1340/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8876e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01340: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.8876e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0119 - val_mean_absolute_error: 0.1422\n",
      "Epoch 1341/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2966e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01341: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2966e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0118 - val_mean_absolute_error: 0.1423\n",
      "Epoch 1342/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4309e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01342: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4309e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0126 - val_mean_absolute_error: 0.1464\n",
      "Epoch 1343/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2653e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01343: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2653e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0108 - val_mean_absolute_error: 0.1344\n",
      "Epoch 1344/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0300e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01344: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.0300e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0113 - val_mean_absolute_error: 0.1362\n",
      "Epoch 1345/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.0677e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01345: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0945e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0123 - val_mean_absolute_error: 0.1452\n",
      "Epoch 1346/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4494e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01346: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4494e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0107 - val_mean_absolute_error: 0.1327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1347/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.9147e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01347: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9834e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0116 - val_mean_absolute_error: 0.1420\n",
      "Epoch 1348/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9326e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01348: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9326e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0117 - val_mean_absolute_error: 0.1420\n",
      "Epoch 1349/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3649e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01349: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3649e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0108 - val_mean_absolute_error: 0.1355\n",
      "Epoch 1350/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2659e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01350: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2659e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0097 - val_mean_absolute_error: 0.1267\n",
      "Epoch 1351/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4854e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01351: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4854e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0118 - val_mean_absolute_error: 0.1428\n",
      "Epoch 1352/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.0047e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01352: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.9974e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0106 - val_mean_absolute_error: 0.1341\n",
      "Epoch 1353/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2123e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01353: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2123e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0085 - val_mean_absolute_error: 0.1150\n",
      "Epoch 1354/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2616e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01354: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2616e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0123 - val_mean_absolute_error: 0.1429\n",
      "Epoch 1355/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2416e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01355: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2416e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0125 - val_mean_absolute_error: 0.1470\n",
      "Epoch 1356/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1026e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01356: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1026e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0135 - val_mean_absolute_error: 0.1537\n",
      "Epoch 1357/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2753e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01357: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2753e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0117 - val_mean_absolute_error: 0.1407\n",
      "Epoch 1358/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.1213e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01358: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2231e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0098 - val_mean_absolute_error: 0.1279\n",
      "Epoch 1359/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4182e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01359: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4182e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0137 - val_mean_absolute_error: 0.1544\n",
      "Epoch 1360/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2479e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01360: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2479e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0107 - val_mean_absolute_error: 0.1337\n",
      "Epoch 1361/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.8926e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01361: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.8698e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0159 - val_mean_absolute_error: 0.1685\n",
      "Epoch 1362/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8824e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01362: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8824e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0137 - val_mean_absolute_error: 0.1553\n",
      "Epoch 1363/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.8948e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01363: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.8903e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0115 - val_mean_absolute_error: 0.1405\n",
      "Epoch 1364/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9025e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01364: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.9025e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0117 - val_mean_absolute_error: 0.1406\n",
      "Epoch 1365/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.2687e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01365: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2631e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0125 - val_mean_absolute_error: 0.1469\n",
      "Epoch 1366/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9461e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01366: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9461e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0122 - val_mean_absolute_error: 0.1438\n",
      "Epoch 1367/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0023e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01367: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.0023e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0094 - val_mean_absolute_error: 0.1243\n",
      "Epoch 1368/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0869e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01368: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.0869e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0111 - val_mean_absolute_error: 0.1361\n",
      "Epoch 1369/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.6583e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01369: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.6535e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0095 - val_mean_absolute_error: 0.1262\n",
      "Epoch 1370/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2939e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01370: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2939e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0124 - val_mean_absolute_error: 0.1479\n",
      "Epoch 1371/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3748e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01371: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3748e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0136 - val_mean_absolute_error: 0.1545\n",
      "Epoch 1372/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.9163e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01372: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9074e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0144 - val_mean_absolute_error: 0.1610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1373/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0874e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01373: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.0874e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0106 - val_mean_absolute_error: 0.1325\n",
      "Epoch 1374/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.6416e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 01374: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.6416e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0093 - val_mean_absolute_error: 0.1240\n",
      "Epoch 1375/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3416e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01375: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3416e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0153 - val_mean_absolute_error: 0.1665\n",
      "Epoch 1376/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.5774e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01376: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.5796e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0119 - val_mean_absolute_error: 0.1433\n",
      "Epoch 1377/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1068e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01377: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1068e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0125 - val_mean_absolute_error: 0.1488\n",
      "Epoch 1378/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9312e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01378: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.9312e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0115 - val_mean_absolute_error: 0.1417\n",
      "Epoch 1379/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.5545e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01379: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5513e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0082 - val_mean_absolute_error: 0.1154\n",
      "Epoch 1380/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8062e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01380: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8062e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0135 - val_mean_absolute_error: 0.1500\n",
      "Epoch 1381/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8827e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01381: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8827e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0102 - val_mean_absolute_error: 0.1318\n",
      "Epoch 1382/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.1300e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01382: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1524e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0122 - val_mean_absolute_error: 0.1449\n",
      "Epoch 1383/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1750e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01383: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1750e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0090 - val_mean_absolute_error: 0.1217\n",
      "Epoch 1384/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.1252e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01384: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1233e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0101 - val_mean_absolute_error: 0.1310\n",
      "Epoch 1385/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4268e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01385: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4268e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0128 - val_mean_absolute_error: 0.1498\n",
      "Epoch 1386/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2452e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01386: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2452e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0092 - val_mean_absolute_error: 0.1238\n",
      "Epoch 1387/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8520e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01387: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8520e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0110 - val_mean_absolute_error: 0.1387\n",
      "Epoch 1388/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2772e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01388: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2772e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0086 - val_mean_absolute_error: 0.1201\n",
      "Epoch 1389/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.5588e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 01389: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.5848e-05 - mean_absolute_error: 0.0081 - val_loss: 0.0104 - val_mean_absolute_error: 0.1342\n",
      "Epoch 1390/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0364e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01390: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0364e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0115 - val_mean_absolute_error: 0.1401\n",
      "Epoch 1391/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.7876e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01391: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.7876e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0107 - val_mean_absolute_error: 0.1354\n",
      "Epoch 1392/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0835e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01392: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0835e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0139 - val_mean_absolute_error: 0.1571\n",
      "Epoch 1393/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.1119e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01393: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1040e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0115 - val_mean_absolute_error: 0.1414\n",
      "Epoch 1394/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9787e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01394: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 5.9787e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0108 - val_mean_absolute_error: 0.1358\n",
      "Epoch 1395/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 6.0738e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01395: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1342e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0095 - val_mean_absolute_error: 0.1253\n",
      "Epoch 1396/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.7186e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 01396: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.7186e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0107 - val_mean_absolute_error: 0.1337\n",
      "Epoch 1397/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.3639e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01397: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3577e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0108 - val_mean_absolute_error: 0.1339\n",
      "Epoch 1398/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9562e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01398: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9562e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0168 - val_mean_absolute_error: 0.1730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1399/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1637e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01399: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1637e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0149 - val_mean_absolute_error: 0.1628\n",
      "Epoch 1400/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9254e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01400: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9254e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0096 - val_mean_absolute_error: 0.1271\n",
      "Epoch 1401/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.9471e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01401: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.9594e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0146 - val_mean_absolute_error: 0.1599\n",
      "Epoch 1402/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2517e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01402: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2517e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0149 - val_mean_absolute_error: 0.1626\n",
      "Epoch 1403/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9003e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01403: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9003e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0125 - val_mean_absolute_error: 0.1480\n",
      "Epoch 1404/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0577e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01404: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0577e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0099 - val_mean_absolute_error: 0.1283\n",
      "Epoch 1405/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.0734e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01405: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.0674e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0137 - val_mean_absolute_error: 0.1562\n",
      "Epoch 1406/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.9269e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01406: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 5.9386e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0107 - val_mean_absolute_error: 0.1351\n",
      "Epoch 1407/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0412e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01407: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0412e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0114 - val_mean_absolute_error: 0.1390\n",
      "Epoch 1408/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3139e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01408: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3139e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0121 - val_mean_absolute_error: 0.1465\n",
      "Epoch 1409/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3632e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01409: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 6.3632e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0094 - val_mean_absolute_error: 0.1244\n",
      "Epoch 1410/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9898e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01410: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9898e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0114 - val_mean_absolute_error: 0.1400\n",
      "Epoch 1411/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9936e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01411: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 5.9936e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0129 - val_mean_absolute_error: 0.1503\n",
      "Epoch 1412/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0130e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01412: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0130e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0128 - val_mean_absolute_error: 0.1479\n",
      "Epoch 1413/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1026e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01413: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1026e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0088 - val_mean_absolute_error: 0.1183\n",
      "Epoch 1414/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.9455e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01414: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9387e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0128 - val_mean_absolute_error: 0.1481\n",
      "Epoch 1415/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3235e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01415: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3235e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0110 - val_mean_absolute_error: 0.1355\n",
      "Epoch 1416/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 6.0399e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01416: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0071e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0131 - val_mean_absolute_error: 0.1499\n",
      "Epoch 1417/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.8286e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01417: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 5.8424e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0101 - val_mean_absolute_error: 0.1299\n",
      "Epoch 1418/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8128e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01418: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8128e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0093 - val_mean_absolute_error: 0.1242\n",
      "Epoch 1419/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9200e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01419: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9200e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0115 - val_mean_absolute_error: 0.1415\n",
      "Epoch 1420/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9181e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01420: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9181e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0121 - val_mean_absolute_error: 0.1454\n",
      "Epoch 1421/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4670e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01421: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.4670e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0144 - val_mean_absolute_error: 0.1599\n",
      "Epoch 1422/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4183e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01422: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.4183e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0097 - val_mean_absolute_error: 0.1286\n",
      "Epoch 1423/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0867e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01423: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0867e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0121 - val_mean_absolute_error: 0.1465\n",
      "Epoch 1424/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2694e-05 - mean_absolute_error: 0.0078- ETA: 0s - loss: 6.1534e-05 - mean_absolute_error: 0.00\n",
      "Epoch 01424: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2694e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0095 - val_mean_absolute_error: 0.1281\n",
      "Epoch 1425/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8800e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01425: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8800e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0115 - val_mean_absolute_error: 0.1397\n",
      "Epoch 1426/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1088e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01426: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1088e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0123 - val_mean_absolute_error: 0.1459\n",
      "Epoch 1427/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2117e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01427: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2117e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0136 - val_mean_absolute_error: 0.1543\n",
      "Epoch 1428/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9580e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01428: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9580e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0144 - val_mean_absolute_error: 0.1605\n",
      "Epoch 1429/1500\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 6.2627e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01429: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2880e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0093 - val_mean_absolute_error: 0.1229\n",
      "Epoch 1430/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.2428e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01430: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2394e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0120 - val_mean_absolute_error: 0.1448\n",
      "Epoch 1431/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2784e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01431: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2784e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0086 - val_mean_absolute_error: 0.1182\n",
      "Epoch 1432/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9790e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01432: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9790e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0151 - val_mean_absolute_error: 0.1662\n",
      "Epoch 1433/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.3374e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01433: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3610e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0167 - val_mean_absolute_error: 0.1740\n",
      "Epoch 1434/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.9695e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01434: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9941e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0160 - val_mean_absolute_error: 0.1705\n",
      "Epoch 1435/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2950e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01435: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2950e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0119 - val_mean_absolute_error: 0.1431\n",
      "Epoch 1436/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.9402e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01436: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.9341e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0114 - val_mean_absolute_error: 0.1400\n",
      "Epoch 1437/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1321e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01437: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1321e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0118 - val_mean_absolute_error: 0.1427\n",
      "Epoch 1438/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3901e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01438: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3901e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0125 - val_mean_absolute_error: 0.1486\n",
      "Epoch 1439/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 6.3047e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01439: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3754e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0108 - val_mean_absolute_error: 0.1370\n",
      "Epoch 1440/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9735e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01440: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9735e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0128 - val_mean_absolute_error: 0.1502\n",
      "Epoch 1441/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9442e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01441: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9442e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0098 - val_mean_absolute_error: 0.1283\n",
      "Epoch 1442/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1073e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01442: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1073e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0115 - val_mean_absolute_error: 0.1403\n",
      "Epoch 1443/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.8776e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01443: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.9152e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0121 - val_mean_absolute_error: 0.1451\n",
      "Epoch 1444/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.9676e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01444: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9644e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0098 - val_mean_absolute_error: 0.1290\n",
      "Epoch 1445/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.0157e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01445: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0078e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0088 - val_mean_absolute_error: 0.1210\n",
      "Epoch 1446/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1550e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01446: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1550e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0106 - val_mean_absolute_error: 0.1374\n",
      "Epoch 1447/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8701e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 01447: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8701e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0140 - val_mean_absolute_error: 0.1595\n",
      "Epoch 1448/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2116e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01448: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2116e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0117 - val_mean_absolute_error: 0.1427\n",
      "Epoch 1449/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1478e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01449: val_loss did not improve from 0.00023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1478e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0111 - val_mean_absolute_error: 0.1403\n",
      "Epoch 1450/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.9420e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01450: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9080e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0110 - val_mean_absolute_error: 0.1391\n",
      "Epoch 1451/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.9608e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01451: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9399e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0098 - val_mean_absolute_error: 0.1293\n",
      "Epoch 1452/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2602e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01452: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2602e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0124 - val_mean_absolute_error: 0.1482\n",
      "Epoch 1453/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9402e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01453: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 5.9402e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0113 - val_mean_absolute_error: 0.1401\n",
      "Epoch 1454/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3061e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01454: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.3061e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0097 - val_mean_absolute_error: 0.1285\n",
      "Epoch 1455/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1159e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01455: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1159e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0115 - val_mean_absolute_error: 0.1423\n",
      "Epoch 1456/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2948e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01456: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2948e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0115 - val_mean_absolute_error: 0.1419\n",
      "Epoch 1457/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9767e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01457: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 5.9767e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0144 - val_mean_absolute_error: 0.1618\n",
      "Epoch 1458/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1032e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01458: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.1032e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0115 - val_mean_absolute_error: 0.1429\n",
      "Epoch 1459/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.1609e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01459: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1609e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0108 - val_mean_absolute_error: 0.1387\n",
      "Epoch 1460/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2822e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01460: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2822e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0099 - val_mean_absolute_error: 0.1307\n",
      "Epoch 1461/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.7053e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01461: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.7053e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0100 - val_mean_absolute_error: 0.1324\n",
      "Epoch 1462/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.5486e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 01462: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.5486e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0084 - val_mean_absolute_error: 0.1166\n",
      "Epoch 1463/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.1743e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01463: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 6.1799e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0109 - val_mean_absolute_error: 0.1386\n",
      "Epoch 1464/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.8747e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01464: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.8739e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0127 - val_mean_absolute_error: 0.1517\n",
      "Epoch 1465/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4284e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 01465: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4284e-05 - mean_absolute_error: 0.0080 - val_loss: 0.0098 - val_mean_absolute_error: 0.1278\n",
      "Epoch 1466/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.7235e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 01466: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.7235e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0097 - val_mean_absolute_error: 0.1270\n",
      "Epoch 1467/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9075e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01467: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9075e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0119 - val_mean_absolute_error: 0.1447\n",
      "Epoch 1468/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.1373e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01468: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1344e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0107 - val_mean_absolute_error: 0.1353\n",
      "Epoch 1469/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8801e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01469: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8801e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0105 - val_mean_absolute_error: 0.1349\n",
      "Epoch 1470/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.9890e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01470: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9890e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0092 - val_mean_absolute_error: 0.1239\n",
      "Epoch 1471/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0703e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01471: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0703e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0077 - val_mean_absolute_error: 0.1127\n",
      "Epoch 1472/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.4743e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 01472: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.4743e-05 - mean_absolute_error: 0.0075 - val_loss: 0.0085 - val_mean_absolute_error: 0.1179\n",
      "Epoch 1473/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0483e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01473: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0483e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0095 - val_mean_absolute_error: 0.1266\n",
      "Epoch 1474/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8353e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01474: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 5.8353e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0092 - val_mean_absolute_error: 0.1228\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/79 [============================>.] - ETA: 0s - loss: 6.1416e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01475: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 6.1411e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0135 - val_mean_absolute_error: 0.1535\n",
      "Epoch 1476/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8277e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01476: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.8277e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0114 - val_mean_absolute_error: 0.1429\n",
      "Epoch 1477/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 6.1318e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01477: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.1279e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0101 - val_mean_absolute_error: 0.1317\n",
      "Epoch 1478/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2491e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01478: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2491e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0121 - val_mean_absolute_error: 0.1472\n",
      "Epoch 1479/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.6734e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 01479: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.6734e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0107 - val_mean_absolute_error: 0.1362\n",
      "Epoch 1480/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8908e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01480: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 5.8908e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0095 - val_mean_absolute_error: 0.1234\n",
      "Epoch 1481/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0649e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01481: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.0649e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0100 - val_mean_absolute_error: 0.1306\n",
      "Epoch 1482/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0592e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01482: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0592e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0105 - val_mean_absolute_error: 0.1338\n",
      "Epoch 1483/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0095e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01483: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.0095e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0123 - val_mean_absolute_error: 0.1481\n",
      "Epoch 1484/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8597e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01484: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8597e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0104 - val_mean_absolute_error: 0.1331\n",
      "Epoch 1485/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.9963e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01485: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9906e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0113 - val_mean_absolute_error: 0.1406\n",
      "Epoch 1486/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2502e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01486: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.2502e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0111 - val_mean_absolute_error: 0.1389\n",
      "Epoch 1487/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.2073e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01487: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.2073e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0106 - val_mean_absolute_error: 0.1343\n",
      "Epoch 1488/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.3325e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 01488: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.3325e-05 - mean_absolute_error: 0.0079 - val_loss: 0.0111 - val_mean_absolute_error: 0.1383\n",
      "Epoch 1489/1500\n",
      "77/79 [============================>.] - ETA: 0s - loss: 5.9097e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 01489: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8885e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0108 - val_mean_absolute_error: 0.1356\n",
      "Epoch 1490/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.0664e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01490: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 6.0664e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0112 - val_mean_absolute_error: 0.1398\n",
      "Epoch 1491/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8321e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01491: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8321e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0128 - val_mean_absolute_error: 0.1477\n",
      "Epoch 1492/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8346e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 01492: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8346e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0146 - val_mean_absolute_error: 0.1621\n",
      "Epoch 1493/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8804e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 01493: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8804e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0097 - val_mean_absolute_error: 0.1275\n",
      "Epoch 1494/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 6.4991e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 01494: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 6.4991e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0078 - val_mean_absolute_error: 0.1115\n",
      "Epoch 1495/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8567e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01495: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8567e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0099 - val_mean_absolute_error: 0.1275\n",
      "Epoch 1496/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.8251e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 01496: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.8256e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0106 - val_mean_absolute_error: 0.1335\n",
      "Epoch 1497/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.9702e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 01497: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 5.9665e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0109 - val_mean_absolute_error: 0.1363\n",
      "Epoch 1498/1500\n",
      "78/79 [============================>.] - ETA: 0s - loss: 5.9482e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01498: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.9417e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0126 - val_mean_absolute_error: 0.1411\n",
      "Epoch 1499/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.7507e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01499: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.7507e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0098 - val_mean_absolute_error: 0.1232\n",
      "Epoch 1500/1500\n",
      "79/79 [==============================] - ETA: 0s - loss: 5.8270e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 01500: val_loss did not improve from 0.00023\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 5.8270e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0123 - val_mean_absolute_error: 0.1391\n"
     ]
    }
   ],
   "source": [
    "# def fit_model():\n",
    "if not collab and os.path.exists(os.path.join(new_results + \"/results\", model_name + \".h5\")):\n",
    "    print(\"Модель уже просчитана, загружаем модель\")\n",
    "else:\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print(\"Создаем новую модель\" + new_results)\n",
    "        # some tensorflow callbacks\n",
    "        checkpointer = ModelCheckpoint(os.path.join(new_results + \"/results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "        tensorboard = TensorBoard(log_dir=os.path.join(new_results + \"/logs\", model_name))\n",
    "        # train the model and save the weights whenever we see\n",
    "        # a new optimal model using ModelCheckpoint\n",
    "        history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          epochs=EPOCHS,\n",
    "                          validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                          callbacks=[checkpointer, tensorboard],\n",
    "                          verbose=1)\n",
    "    else:\n",
    "        print(\"GPU не подключен\")\n",
    "        copy_tree(data_path + \"/results\",  new_results + \"/results\" )\n",
    "        copy_tree(data_path + \"/logs\",  new_results + \"/logs\")\n",
    "        copy_tree(data_path + \"/data\", new_results + \"/data\")\n",
    "        copy_tree(data_path + \"/test-results\", new_results + \"/test-results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 10\n",
    "# delete_folders([f\"del__2000_test2021_close_ep{EPOCHS}\",f\"del__2000_test2021_close_body_ep{EPOCHS}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile_model()\n",
    "# fit_model()\n",
    "# load_params()\n",
    "# EPOCHS = 10\n",
    "# new_results = f\"del__2000_test2021_close_ep{EPOCHS}\"\n",
    "# FEATURE_COLUMNS = [\"close\"]\n",
    "# compile_model()\n",
    "# fit_model()\n",
    "\n",
    "# load_params()\n",
    "# EPOCHS = 10\n",
    "# new_results = f\"del__2000_test2021_close_body_ep{EPOCHS}\"\n",
    "# FEATURE_COLUMNS = [\"close\",\"body\"]\n",
    "# compile_model()\n",
    "# fit_model()\n",
    "\n",
    "\n",
    "\n",
    "# new_results = \"2000_test2021_close_body_abs\"\n",
    "# FEATURE_COLUMNS = [\"close\",\"body_abs\"]\n",
    "# load_params()\n",
    "# fit_model()\n",
    "\n",
    "# new_results = \"2000_test2021_candles\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# load_params()\n",
    "# fit_model()\n",
    "\n",
    "# new_results = \"2000_test2021_ema100\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "# load_params()\n",
    "# fit_model()\n",
    "\n",
    "# new_results = \"1976_test2021_ema100\"\n",
    "# FEATURE_COLUMNS = [\"close\", \"volume\", \"open\", \"high\", \"low\",\"ma7\",\"ma21\",\"ma100\",\"ma50\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\"] \n",
    "# load_params()\n",
    "# fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1638183343694,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "jZLCykmNp4kN"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_close_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'close_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1638183343694,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "l3p5ydmzp4kN"
   },
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"close\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"close\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"close_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_close_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"close\"],\n",
    "                                    final_df[f\"close_{LOOKUP_STEP}\"],\n",
    "                                    final_df[f\"true_close_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"close\"],\n",
    "                                    final_df[f\"close_{LOOKUP_STEP}\"],\n",
    "                                    final_df[f\"true_close_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1638183343694,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "3F86VAfyp4kN"
   },
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"close\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1638183343695,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "hHljZFoSp4kO"
   },
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(new_results + \"/results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1638183344442,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "X-4aAmgSp4kO"
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"close\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {
    "executionInfo": {
     "elapsed": 1306,
     "status": "ok",
     "timestamp": 1638183345745,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "zNzvlBbFp4kO"
   },
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = pd.DataFrame()\n",
    "if not final_df.empty:\n",
    "    final_df = final_df.iloc[0:0]\n",
    "\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1638183345746,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "FrEBklEup4kO"
   },
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1638183345746,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "mlw-UgZPp4kO",
    "outputId": "b633c88c-c6d7-444b-af55-b244dc761a81",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4631.996"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1638183345746,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "5fhA5Djwp4kP"
   },
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1638183345747,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "bmGMNpBgp4kP",
    "outputId": "2e58096c-0348-4cb8-b167-e4d3d1504a66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000_test2021_ema100_ep300  ['close', 'volume', 'open', 'high', 'low', 'ma7', 'ma21', 'ma100', 'ma50', '26ema', '12ema', 'MACD', 'ema', 'momentum']\n",
      "\n",
      "Future price after 35 days is 4632.00$\n",
      "huber_loss loss: 0.00023025726841297\n",
      "Mean Absolute Error: 747.9382491651277\n",
      "Accuracy score: 0.9184549356223176\n",
      "Total buy profit: 33618.01953125\n",
      "Total sell profit: 9.16015625\n",
      "Total profit: 33627.1796875\n",
      "Profit per trade: 144.3226596030043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "f = open(os.path.join(new_results + \"/test-results\", \"result.txt\"), 'w')\n",
    "print(new_results + \"  \" + str(FEATURE_COLUMNS) ,file=f)\n",
    "print(\"\", file=f)\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\",file=f)\n",
    "print(f\"{LOSS} loss:\", loss,file=f)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error,file=f)\n",
    "print(\"Accuracy score:\", accuracy_score,file=f)\n",
    "print(\"Total buy profit:\", total_buy_profit,file=f)\n",
    "print(\"Total sell profit:\", total_sell_profit,file=f)\n",
    "print(\"Total profit:\", total_profit,file=f)\n",
    "print(\"Profit per trade:\", profit_per_trade,file=f)\n",
    "f.close()\n",
    "\n",
    "result_file = open(os.path.join(new_results + \"/test-results\", \"result.txt\"),\"r\")\n",
    "print(result_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1638183346361,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "lliJ8Ss8p4kP",
    "outputId": "37a1e6ee-f46b-47d5-cfda-e6ff28264004"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1638183346362,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "6b2_fk7up4kP",
    "outputId": "b69ee47e-8604-4727-e495-f4e87289f366"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>ma7</th>\n",
       "      <th>ma21</th>\n",
       "      <th>ma100</th>\n",
       "      <th>...</th>\n",
       "      <th>12ema</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ema</th>\n",
       "      <th>momentum</th>\n",
       "      <th>body</th>\n",
       "      <th>body_abs</th>\n",
       "      <th>close_35</th>\n",
       "      <th>true_close_35</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-11</th>\n",
       "      <td>3563.219971</td>\n",
       "      <td>3581.159912</td>\n",
       "      <td>3557.000000</td>\n",
       "      <td>3572.659912</td>\n",
       "      <td>3572.659912</td>\n",
       "      <td>4609970000</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>3500.168527</td>\n",
       "      <td>3434.974749</td>\n",
       "      <td>3339.201604</td>\n",
       "      <td>...</td>\n",
       "      <td>3471.200233</td>\n",
       "      <td>33.701984</td>\n",
       "      <td>3562.251938</td>\n",
       "      <td>3571.659912</td>\n",
       "      <td>9.439941</td>\n",
       "      <td>9.439941</td>\n",
       "      <td>3709.967285</td>\n",
       "      <td>3700.649902</td>\n",
       "      <td>127.989990</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-12</th>\n",
       "      <td>3562.669922</td>\n",
       "      <td>3569.020020</td>\n",
       "      <td>3518.580078</td>\n",
       "      <td>3537.010010</td>\n",
       "      <td>3537.010010</td>\n",
       "      <td>4890120000</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>3524.147112</td>\n",
       "      <td>3437.276658</td>\n",
       "      <td>3343.258804</td>\n",
       "      <td>...</td>\n",
       "      <td>3481.324814</td>\n",
       "      <td>36.455323</td>\n",
       "      <td>3545.423986</td>\n",
       "      <td>3536.010010</td>\n",
       "      <td>-25.659912</td>\n",
       "      <td>25.659912</td>\n",
       "      <td>3720.338867</td>\n",
       "      <td>3726.860107</td>\n",
       "      <td>189.850098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-13</th>\n",
       "      <td>3552.570068</td>\n",
       "      <td>3593.659912</td>\n",
       "      <td>3552.570068</td>\n",
       "      <td>3585.149902</td>\n",
       "      <td>3585.149902</td>\n",
       "      <td>4709670000</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>3544.391392</td>\n",
       "      <td>3442.124744</td>\n",
       "      <td>3348.607002</td>\n",
       "      <td>...</td>\n",
       "      <td>3497.297905</td>\n",
       "      <td>42.037272</td>\n",
       "      <td>3571.907930</td>\n",
       "      <td>3584.149902</td>\n",
       "      <td>32.579834</td>\n",
       "      <td>32.579834</td>\n",
       "      <td>3729.423584</td>\n",
       "      <td>3748.139893</td>\n",
       "      <td>162.989990</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-16</th>\n",
       "      <td>3600.159912</td>\n",
       "      <td>3628.510010</td>\n",
       "      <td>3600.159912</td>\n",
       "      <td>3626.909912</td>\n",
       "      <td>3626.909912</td>\n",
       "      <td>5281980000</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>3561.028530</td>\n",
       "      <td>3448.939023</td>\n",
       "      <td>3354.038501</td>\n",
       "      <td>...</td>\n",
       "      <td>3517.238214</td>\n",
       "      <td>49.262820</td>\n",
       "      <td>3608.575918</td>\n",
       "      <td>3625.909912</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>3739.258789</td>\n",
       "      <td>3803.790039</td>\n",
       "      <td>176.880127</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-17</th>\n",
       "      <td>3610.310059</td>\n",
       "      <td>3623.110107</td>\n",
       "      <td>3588.679932</td>\n",
       "      <td>3609.530029</td>\n",
       "      <td>3609.530029</td>\n",
       "      <td>4799570000</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>3575.327114</td>\n",
       "      <td>3457.634742</td>\n",
       "      <td>3360.043301</td>\n",
       "      <td>...</td>\n",
       "      <td>3531.436954</td>\n",
       "      <td>52.976032</td>\n",
       "      <td>3609.211992</td>\n",
       "      <td>3608.530029</td>\n",
       "      <td>-0.780029</td>\n",
       "      <td>0.780029</td>\n",
       "      <td>3747.995361</td>\n",
       "      <td>3824.679932</td>\n",
       "      <td>215.149902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18</th>\n",
       "      <td>3612.090088</td>\n",
       "      <td>3619.090088</td>\n",
       "      <td>3567.330078</td>\n",
       "      <td>3567.790039</td>\n",
       "      <td>3567.790039</td>\n",
       "      <td>5274450000</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>3577.797119</td>\n",
       "      <td>3463.571405</td>\n",
       "      <td>3365.188801</td>\n",
       "      <td>...</td>\n",
       "      <td>3537.029737</td>\n",
       "      <td>51.951843</td>\n",
       "      <td>3581.597357</td>\n",
       "      <td>3566.790039</td>\n",
       "      <td>-44.300049</td>\n",
       "      <td>44.300049</td>\n",
       "      <td>3751.927246</td>\n",
       "      <td>3799.610107</td>\n",
       "      <td>231.820068</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19</th>\n",
       "      <td>3559.409912</td>\n",
       "      <td>3585.219971</td>\n",
       "      <td>3543.840088</td>\n",
       "      <td>3581.870117</td>\n",
       "      <td>3581.870117</td>\n",
       "      <td>4347200000</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>3582.988560</td>\n",
       "      <td>3470.538551</td>\n",
       "      <td>3370.004602</td>\n",
       "      <td>...</td>\n",
       "      <td>3543.928257</td>\n",
       "      <td>51.680568</td>\n",
       "      <td>3581.779197</td>\n",
       "      <td>3580.870117</td>\n",
       "      <td>22.460205</td>\n",
       "      <td>22.460205</td>\n",
       "      <td>3753.699219</td>\n",
       "      <td>3801.189941</td>\n",
       "      <td>219.319824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-20</th>\n",
       "      <td>3579.310059</td>\n",
       "      <td>3581.229980</td>\n",
       "      <td>3556.850098</td>\n",
       "      <td>3557.540039</td>\n",
       "      <td>3557.540039</td>\n",
       "      <td>4218970000</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>3580.828578</td>\n",
       "      <td>3475.493315</td>\n",
       "      <td>3374.421401</td>\n",
       "      <td>...</td>\n",
       "      <td>3546.022377</td>\n",
       "      <td>48.938218</td>\n",
       "      <td>3565.619758</td>\n",
       "      <td>3556.540039</td>\n",
       "      <td>-21.770020</td>\n",
       "      <td>21.770020</td>\n",
       "      <td>3753.504639</td>\n",
       "      <td>3809.840088</td>\n",
       "      <td>252.300049</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-23</th>\n",
       "      <td>3566.820068</td>\n",
       "      <td>3589.810059</td>\n",
       "      <td>3552.770020</td>\n",
       "      <td>3577.590088</td>\n",
       "      <td>3577.590088</td>\n",
       "      <td>5036290000</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>3586.625732</td>\n",
       "      <td>3480.836182</td>\n",
       "      <td>3378.897202</td>\n",
       "      <td>...</td>\n",
       "      <td>3550.878948</td>\n",
       "      <td>47.831387</td>\n",
       "      <td>3573.599978</td>\n",
       "      <td>3576.590088</td>\n",
       "      <td>10.770020</td>\n",
       "      <td>10.770020</td>\n",
       "      <td>3752.406738</td>\n",
       "      <td>3795.540039</td>\n",
       "      <td>217.949951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-24</th>\n",
       "      <td>3594.520020</td>\n",
       "      <td>3642.310059</td>\n",
       "      <td>3594.520020</td>\n",
       "      <td>3635.409912</td>\n",
       "      <td>3635.409912</td>\n",
       "      <td>6267570000</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>3593.805734</td>\n",
       "      <td>3491.999988</td>\n",
       "      <td>3383.454102</td>\n",
       "      <td>...</td>\n",
       "      <td>3563.883712</td>\n",
       "      <td>51.031532</td>\n",
       "      <td>3614.806601</td>\n",
       "      <td>3634.409912</td>\n",
       "      <td>40.889893</td>\n",
       "      <td>40.889893</td>\n",
       "      <td>3754.453125</td>\n",
       "      <td>3768.250000</td>\n",
       "      <td>132.840088</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   open         high          low        close     adjclose  \\\n",
       "2020-11-11  3563.219971  3581.159912  3557.000000  3572.659912  3572.659912   \n",
       "2020-11-12  3562.669922  3569.020020  3518.580078  3537.010010  3537.010010   \n",
       "2020-11-13  3552.570068  3593.659912  3552.570068  3585.149902  3585.149902   \n",
       "2020-11-16  3600.159912  3628.510010  3600.159912  3626.909912  3626.909912   \n",
       "2020-11-17  3610.310059  3623.110107  3588.679932  3609.530029  3609.530029   \n",
       "2020-11-18  3612.090088  3619.090088  3567.330078  3567.790039  3567.790039   \n",
       "2020-11-19  3559.409912  3585.219971  3543.840088  3581.870117  3581.870117   \n",
       "2020-11-20  3579.310059  3581.229980  3556.850098  3557.540039  3557.540039   \n",
       "2020-11-23  3566.820068  3589.810059  3552.770020  3577.590088  3577.590088   \n",
       "2020-11-24  3594.520020  3642.310059  3594.520020  3635.409912  3635.409912   \n",
       "\n",
       "                volume ticker          ma7         ma21        ma100  ...  \\\n",
       "2020-11-11  4609970000  ^GSPC  3500.168527  3434.974749  3339.201604  ...   \n",
       "2020-11-12  4890120000  ^GSPC  3524.147112  3437.276658  3343.258804  ...   \n",
       "2020-11-13  4709670000  ^GSPC  3544.391392  3442.124744  3348.607002  ...   \n",
       "2020-11-16  5281980000  ^GSPC  3561.028530  3448.939023  3354.038501  ...   \n",
       "2020-11-17  4799570000  ^GSPC  3575.327114  3457.634742  3360.043301  ...   \n",
       "2020-11-18  5274450000  ^GSPC  3577.797119  3463.571405  3365.188801  ...   \n",
       "2020-11-19  4347200000  ^GSPC  3582.988560  3470.538551  3370.004602  ...   \n",
       "2020-11-20  4218970000  ^GSPC  3580.828578  3475.493315  3374.421401  ...   \n",
       "2020-11-23  5036290000  ^GSPC  3586.625732  3480.836182  3378.897202  ...   \n",
       "2020-11-24  6267570000  ^GSPC  3593.805734  3491.999988  3383.454102  ...   \n",
       "\n",
       "                  12ema       MACD          ema     momentum       body  \\\n",
       "2020-11-11  3471.200233  33.701984  3562.251938  3571.659912   9.439941   \n",
       "2020-11-12  3481.324814  36.455323  3545.423986  3536.010010 -25.659912   \n",
       "2020-11-13  3497.297905  42.037272  3571.907930  3584.149902  32.579834   \n",
       "2020-11-16  3517.238214  49.262820  3608.575918  3625.909912  26.750000   \n",
       "2020-11-17  3531.436954  52.976032  3609.211992  3608.530029  -0.780029   \n",
       "2020-11-18  3537.029737  51.951843  3581.597357  3566.790039 -44.300049   \n",
       "2020-11-19  3543.928257  51.680568  3581.779197  3580.870117  22.460205   \n",
       "2020-11-20  3546.022377  48.938218  3565.619758  3556.540039 -21.770020   \n",
       "2020-11-23  3550.878948  47.831387  3573.599978  3576.590088  10.770020   \n",
       "2020-11-24  3563.883712  51.031532  3614.806601  3634.409912  40.889893   \n",
       "\n",
       "             body_abs     close_35  true_close_35  buy_profit  sell_profit  \n",
       "2020-11-11   9.439941  3709.967285    3700.649902  127.989990          0.0  \n",
       "2020-11-12  25.659912  3720.338867    3726.860107  189.850098          0.0  \n",
       "2020-11-13  32.579834  3729.423584    3748.139893  162.989990          0.0  \n",
       "2020-11-16  26.750000  3739.258789    3803.790039  176.880127          0.0  \n",
       "2020-11-17   0.780029  3747.995361    3824.679932  215.149902          0.0  \n",
       "2020-11-18  44.300049  3751.927246    3799.610107  231.820068          0.0  \n",
       "2020-11-19  22.460205  3753.699219    3801.189941  219.319824          0.0  \n",
       "2020-11-20  21.770020  3753.504639    3809.840088  252.300049          0.0  \n",
       "2020-11-23  10.770020  3752.406738    3795.540039  217.949951          0.0  \n",
       "2020-11-24  40.889893  3754.453125    3768.250000  132.840088          0.0  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1638183346859,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "4FyFT9Eip4kP",
    "outputId": "aa0df2da-7256-4002-9de6-cc512f478f34"
   },
   "outputs": [],
   "source": [
    "# final_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1638183346860,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "3-cxuOzBp4kP"
   },
   "outputs": [],
   "source": [
    "# save the final dataframe to csv-results folder\n",
    "# csv_filename = os.path.join(\"test_results\", model_name + \".csv\")\n",
    "final_df.to_csv(os.path.join(new_results + \"/test-results\", model_name + \".csv\"))\n",
    "# xls_filename = os.path.join(\"test_results\", model_name + \".xlsx\")\n",
    "final_df.to_excel(os.path.join(new_results + \"/test-results\", model_name + \".xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1638183346860,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "ZLNZwZ8fp4kQ"
   },
   "outputs": [],
   "source": [
    "candles = final_df\n",
    "import datetime\n",
    "candles.rename(columns={f'close_{LOOKUP_STEP}':'predict',f'true_close_{LOOKUP_STEP}':'test'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/11 long 3573\n",
      "2021/08/30 short 4529 Profit: 956\n",
      "2021/08/31 long 4523 Profit: 6\n",
      "\n",
      "2021/10/14 4523 4438  -=-=-= Close long\n",
      "\n",
      "Trade: long Poz: 4523\n",
      "Profit: 878 25 %\n",
      "233\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "poz = 0\n",
    "trade = \"\" \n",
    "profit = 0\n",
    "year = ''\n",
    "# typeTrade = 'long'\n",
    "# typeTrade = 'short'\n",
    "typeTrade = 'short_long'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "profit_y = pd.DataFrame\n",
    "for index, row in final_df.iterrows():\n",
    "    i = i + 1\n",
    "    \n",
    "    if i == 1:\n",
    "        openPrice = row['close']\n",
    "        \n",
    "    closePrice = row['close']\n",
    "    \n",
    "    if (typeTrade == 'long' or typeTrade == 'short_long') and poz == 0 and row['close'] < row['predict']:\n",
    "        poz = row['close']\n",
    "        trade = \"long\"\n",
    "        print(index.strftime(\"%Y/%m/%d\"), trade, round(poz))\n",
    "        year =  index.year\n",
    "        continue\n",
    "    \n",
    "    if (typeTrade == 'short' or typeTrade == 'short_long') and poz == 0 and row['close'] > row['predict']:\n",
    "        poz = row['close']\n",
    "        trade = \"short\"\n",
    "        print(index.strftime(\"%Y/%m/%d\"), trade, round(poz))\n",
    "        year =  index.year\n",
    "        continue    \n",
    "    \n",
    "    if  (typeTrade == 'long'  or typeTrade == 'short_long') and trade == 'long' and row['close'] > row['predict']:\n",
    "        trade = \"short\"\n",
    "        profit = profit + row['close'] - poz\n",
    "#         print(index.strftime(\"%Y/%m/%d\"), trade, round(row['close']) , \"Profit:\", round(row['close'] - poz))\n",
    "        if typeTrade == 'short_long':            \n",
    "            print(index.strftime(\"%Y/%m/%d\"), trade, round(row['close']) , \"Profit:\", round(row['close'] - poz))\n",
    "            poz = row['close']\n",
    "        if typeTrade == 'long':\n",
    "            print(index.strftime(\"%Y/%m/%d\"), 'Close', round(row['close']) , \"Profit:\", round(row['close'] - poz))\n",
    "            poz = 0\n",
    "        continue  \n",
    "        \n",
    "        \n",
    "    if  (typeTrade == 'short' or typeTrade == 'short_long') and trade == 'short' and row['close'] < row['predict']:\n",
    "        trade = \"long\"\n",
    "        profit = profit + poz - row['close']\n",
    "        \n",
    "#         poz = row['close']\n",
    "        if (typeTrade == 'short_long'):            \n",
    "            print(index.strftime(\"%Y/%m/%d\"), trade, round(row['close']) , \"Profit:\", round(poz - row['close']))\n",
    "            poz = row['close']\n",
    "        if typeTrade == 'short':            \n",
    "            print(index.strftime(\"%Y/%m/%d\"), 'Close', round(row['close']) , \"Profit:\", round(poz - row['close']))\n",
    "            poz = 0\n",
    "        continue  \n",
    "        \n",
    "#     if trade == 'long' and row['close'] > row['predict']:\n",
    "#         trade = \"short\"\n",
    "#         profit = profit + row['close'] - poz\n",
    "#         print(index.strftime(\"%Y/%m/%d\"), trade, round(row['close']) , \"Profit:\", round(row['close'] - poz))\n",
    "#         #poz = row['close']\n",
    "#         if (typeTrade == 'short' or typeTrade == 'short_long'):\n",
    "#             poz = row['close']\n",
    "#         else:\n",
    "#             poz = 0\n",
    "#             trade = \"short\"\n",
    "#         continue  \n",
    "            \n",
    "                \n",
    "    \n",
    "    \n",
    "#     if year != index.year:\n",
    "#         profit_y.year = profit\n",
    "        \n",
    "    \n",
    "\n",
    "print()\n",
    "\n",
    "if trade == 'long' :\n",
    "    profit = profit + closePrice - poz\n",
    "\n",
    "if trade == 'short':\n",
    "    profit = profit + poz - closePrice\n",
    "\n",
    "print(index.strftime(\"%Y/%m/%d\"), round(poz) , round(closePrice), \" -=-=-= Close\",trade)       \n",
    "print()\n",
    "print('Trade:',trade,'Poz:',round(poz))        \n",
    "print('Profit:', round(profit),round(profit/openPrice*100),\"%\")   \n",
    "\n",
    "# pprofit_y\n",
    "# for py in profit_y:\n",
    "#     print(py)\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1638183462504,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "BPeAa2uIp4kQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Рисует основной график\n",
    "def draw_candles(candles):\n",
    "    # Добавим на график несколько ЕМА-средних\n",
    "    # candles['ema100'] = pd.Series.ewm(candles['close'], span=100).mean()\n",
    "    # candles['ema50'] = pd.Series.ewm(candles['close'], span=50).mean()\n",
    "    # candles['ema20'] = pd.Series.ewm(candles['close'], span=20).mean()\n",
    "    # candles['26ema'] = pd.Series.ewm(candles['close'], span=26).mean()\n",
    "    # candles['12ema'] = pd.Series.ewm(candles['close'], span=12).mean()\n",
    "    # candles['MACD'] = (candles['12ema']-candles['26ema'])\n",
    "    plt.style.use('ggplot')  # 'seaborn-paper'\n",
    "    # Отображаем график по цене закрытия свечей и ЕМА-шки\n",
    "    fig = candles.plot(y=['test', 'predict','close'], figsize=(25, 16))\n",
    "    # Добавляем заголовок\n",
    "    fig.set_title('График ' + ticker)\n",
    "    # Рисуем шкалу с датами\n",
    "    PlotDatesX(fig, candles)\n",
    "\n",
    "# Определяет начальную и конечную позицию Х (по индексу свечей) для заданной даты. Пригодится при отрисовке ценовых уровней\n",
    "def DateX(date, candles):\n",
    "    # Цикл по датам в свечах, результат - список X-координат, соответствующих заданной дате\n",
    "    xpositions = [index for index, row in candles.iterrows() if row['date'].date() == date]\n",
    "    # Возвращает список - пару начальная координата Х и конечная координата Х для заданной даты на графике\n",
    "    if xpositions == []:\n",
    "        return [len(candles) - 1, len(candles)]  # На случай если за текущую дату нет еще свечей\n",
    "    return [xpositions[0], xpositions[-1]]\n",
    "\n",
    "\n",
    "# Рисует метки дат на оси Х\n",
    "def PlotDatesX(fig, candles):\n",
    "    # Составляем список дат (только уникальные даты) из столбца DT. Они будут метками на оси Х. Сортировка по датам\n",
    "    # обязательна, т.к. при создании множества(set) даже из отсортированного списка, множество может не сохранить порядок списка\n",
    "    dates = sorted(set(map(lambda dt: datetime.date(dt), candles['date'])))\n",
    "    # Создаем список координат Х для каждой метки (даты). Нам нужна только первая позиция - [0].\n",
    "    xlabel = [DateX(d, candles)[0] for d in dates]\n",
    "    # Рисуем ось Х, разделенную по датам\n",
    "    fig.set_xticklabels(dates)\n",
    "    fig.set_xticks(xlabel)\n",
    "    return dates, xlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1638183346862,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "lH67P0bOoaQr",
    "outputId": "a6742048-3e7f-43de-8019-00334a2fd488"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Temp\\\\Sem\\\\NewProject\\\\2000_test2021_ema100_ep300.zip'"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if collab:\n",
    "    copy_tree(new_results + \"/results\", data_path + \"/results\" )\n",
    "    copy_tree(new_results + \"/logs\", data_path + \"/logs\")\n",
    "    copy_tree(new_results + \"/data\", data_path + \"/data\")\n",
    "    copy_tree(new_results + \"/test-results\", data_path + \"/test-results\")\n",
    "# Arc folders with results\n",
    "shutil.make_archive(new_results, 'zip', new_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1454,
     "status": "error",
     "timestamp": 1638183467560,
     "user": {
      "displayName": "Сергей Мазеин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18218808834952086757"
     },
     "user_tz": -180
    },
    "id": "sRTeywM6p4kQ",
    "outputId": "689439a8-0b58-497d-ce28-41e9f4249d8d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\temp\\sem\\newproject\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\temp\\sem\\newproject\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32md:\\temp\\sem\\newproject\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_924/1378092226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdraw_candles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_924/1898546558.py\u001b[0m in \u001b[0;36mdraw_candles\u001b[1;34m(candles)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'График '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mticker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Рисуем шкалу с датами\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mPlotDatesX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Определяет начальную и конечную позицию Х (по индексу свечей) для заданной даты. Пригодится при отрисовке ценовых уровней\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_924/1898546558.py\u001b[0m in \u001b[0;36mPlotDatesX\u001b[1;34m(fig, candles)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Составляем список дат (только уникальные даты) из столбца DT. Они будут метками на оси Х. Сортировка по датам\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# обязательна, т.к. при создании множества(set) даже из отсортированного списка, множество может не сохранить порядок списка\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;31m# Создаем список координат Х для каждой метки (даты). Нам нужна только первая позиция - [0].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mxlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mDateX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\temp\\sem\\newproject\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\temp\\sem\\newproject\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_candles(candles.tail(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "stock_prediction_2_SP_work_GPU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
